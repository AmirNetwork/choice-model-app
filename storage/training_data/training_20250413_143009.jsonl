{"instruction": "Title: A new flexible and partially monotonic discrete choice model\nPaper:\nTransportation Research Part B 183 (2024) 102947\r\nAvailable online 20 April 2024\r\n0191-2615/\u00a9 2024 Elsevier Ltd. All rights reserved.\r\nA new flexible and partially monotonic discrete choice model\r\nEui-Jin Kim a\r\n, Prateek Bansal b,c,*\r\na Department of Transportation Systems Engineering, Ajou University, Suwon 16499, the Republic of Korea b Department of Civil and Environmental Engineering, National University of Singapore, Singapore c Singapore-ETH Centre, Future Cities Lab Global Programme, Singapore Hub, CREATE campus, 1 CREATE Way, #06-01 CREATE Tower, 138602,\r\nSingapore\r\nARTICLE INFO\r\nKeywords:\r\nDiscrete choice models\r\nLattice networks\r\nInterpretability\r\nTrustworthiness\r\nDeep neural networks\r\nMonotonicity\r\nABSTRACT\r\nThe poor predictability and the misspecification arising from hand-crafted utility functions are\r\ncommon issues in theory-driven discrete choice models (DCMs). Data-driven DCMs improve\r\npredictability through flexible utility specifications, but they do not address the misspecification\r\nissue and provide untrustworthy behavioral interpretations (e.g., biased willingness to pay estimates). Improving interpretability at the minimum loss of flexibility/predictability is the main\r\nchallenge in the data-driven DCM. To this end, this study proposes a flexible and partially\r\nmonotonic DCM by specifying the systematic utility using the Lattice networks (i.e., DCM-LN).\r\nDCM-LN ensures the monotonicity of the utility function relative to the selected attributes\r\nwhile learning attribute-specific non-linear effects through piecewise linear functions and interaction effects using multilinear interpolations in a data-driven manner. Partial monotonicity\r\ncould be viewed as domain-knowledge-based regularization to prevent overfitting, consequently\r\navoiding incorrect signs of the attribute effects. The light architecture and an automated process\r\nto write monotonicity constraints make DCM-LN scalable and translatable to practice. The proposed DCM-LN is benchmarked against deep neural network-based DCM (i.e., DCM-DNN) and a\r\nDCM with a hand-crafted utility in a simulation study. While DCM-DNN marginally outperforms\r\nDCM-LN in predictability, DCM-LN highly outperforms all considered models in interpretability,\r\ni.e., recovering willingness to pay at individual and population levels. The empirical study verifies\r\nthe balanced interpretability and predictability of DCM-LN. With superior interpretability and\r\nhigh predictability, DCM-LN lays out new pathways to harmonize the theory-driven and datadriven paradigms.\r\n* Corresponding author at: Department of Civil and Environmental Engineering, National University of Singapore, Singapore.\r\nE-mail address: prateekb@nus.edu.sg (P. Bansal).\r\nContents lists available at ScienceDirect\r\nTransportation Research Part B\r\njournal homepage: www.elsevier.com/locate/trb\r\nhttps://doi.org/10.1016/j.trb.2024.102947\r\nReceived 28 April 2023; Received in revised form 15 February 2024; Accepted 11 April 2024\r\nTransportation Research Part B 183 (2024) 102947\r\n2\r\nAbbreviations\r\nAcronyms Definition\r\nDCM Discrete choice model\r\nLNs Lattice networks\r\nDNNs Deep neural networks\r\nMNL Multinomial logit model\r\nDCM-LN Lattice network-based discrete choice model\r\nDCM-DNN Deep neural network-based discrete choice model\r\nDCM-Linear Discrete choice model with linear utility specification\r\nASU-DNN Deep neural networks with alternative-specific utility\r\nRUM Random utility maximization\r\nWTP Willingness to pay\r\nGAM Generalized additive model\r\nDGP Data generating process\r\nBO Bayesian optimization\r\nGP Gaussian process\r\nIN Income\r\nFUL Full-time job\r\nFLX Flexible commuting\r\nTT Travel time\r\nWT Waiting time\r\nCR Crowding\r\nVOT Value-of-travel time\r\nVOWT Value-of-walking time\r\nRMSE Root mean squared error\r\nMAPE Mean absolute percentage error\r\nTR Train\r\nSM Swiss metro\r\n1. Introduction\r\nDiscrete choice models (DCMs) based on random utility maximization (RUM) theory are widely used to elicit individual-level\r\ndecisions across multiple disciplines, such as transportation, energy economics, and agricultural economics, among others (McFadden, 1973; Train, 2009). Correctly specifying the systematic component of the indirect utility is critical to achieving good predictability and policy-relevant estimates of elasticity and willingness to pay (WTP) at a population and an individual level. Considering\r\nthese criteria, an ideal systematic utility specification should be able to infer the four underlying effects \u2013 (i) non-linear effect of each\r\nalternative-specific attribute (e.g., WTP to reduce travel time in travel mode choice might increase exponentially due to decreasing\r\nmarginal utility to travel cost for long trip) (Daly et al., 2017; Rich and Mabit, 2016); (ii) interaction or joint effect of multiple\r\nalternative-specific attributes (e.g., WTP to reduce crowding in public transport might non-linearly increase with travel time) (Bansal\r\net al., 2022; Batarce et al., 2016); (iii) interaction effect of individual-specific and alternative-specific attributes to capture systematic\r\ntaste heterogeneity (e.g., WTP estimates might vary with the individuals\u2019 income) (Brownstone et al., 2003); and (iv) non-linear effect\r\nof each individual-specific attribute and their interaction effects (e.g., the effect of age on preference to use bicycle might decrease\r\nexponentially with age and the relationship could vary across gender) (Ji et al., 2022; Kim et al., 2021b). While accounting for these\r\ncomplex attribute-specific effects at an individual level, interpretability must be maintained to retrieve policy-relevant WTP and\r\nelasticity estimates. We discuss several notions of interpretability in Section 2.1, but ensuring partial monotonicity (i.e., monotonicity\r\nof the utility relative to a subset of alternative-specific attributes) is crucial to keep the theoretical foundation of DCMs intact. For\r\ninstance, the likelihood of choosing an alternative (i.e., utility) should monotonically decrease with the increase in cost in most\r\npractical situations.\r\nTo incorporate the abovementioned effects, traditional theory-driven DCMs rely on linear-in-parameter utility specifications, with\r\nhand-crafted interactions between attributes and non-linearities in attributes (e.g., quadratic or log transformations). Such models are\r\nappealing due to the ease of associating the meaning with parameter estimates. However, utility misspecification results in poor\r\nprediction accuracy, and monotonicity constraints are not inherently satisfied for some demographic groups, even in the case of linear\r\nutility functions.1 In the case of linear additive utility specification, sign constraints can be imposed on a combination of interactions\r\nand main effects of attributes in the likelihood-based estimation to achieve monotonicity (see Section 3.2.1 for mathematical details)\r\nbut searching for the appropriate parametric specification and handcrafting these constraints become practically infeasible as the\r\nnumber of attributes increases. This issue has been exacerbated lately as a higher number of attributes are becoming common in\r\npreference elicitation for emerging technologies such as mobility-as-a-service (e.g., subscription price and monthly trip frequency of\r\nmultiple travel modes) (Ho et al., 2020; Kim et al., 2021a) and electric vehicles (e.g., purchase price, operating cost, driving range,\r\n1 For example, in a travel mode choice situation, if the main effect of travel time on the utility is negative but the interaction effect of travel time\r\nwith different income level dummies is highly positive and negative, some travelers have negative WTP to save travel time, and others have positive\r\nWTP to reduce travel time. Thus, the linear hand-crafted utility specification does not ensure positive WTP to reduce travel time for all demographic\r\ngroups in the population.\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n3\r\nseveral attributes related to charging infrastructure density and operations, and several pro-electric-vehicle policies) (Bansal et al.,\r\n2021).\r\nTo address the poor predictability of DCMs with hand-crafted utility, two strands of studies have emerged for data-driven specification of the systematic utility. The first strand has relied upon econometrically grounded non-parametric specifications, such as\r\nspline (Friedman, 2001; Fukuda and Yai, 2010), kernel smoothing (Bansal et al., 2019), and Choquet Integral (Dubey et al., 2022). The\r\nsecond strand is emerging, where studies have adopted deep neural networks (DNNs) for flexible representation of the utility specification (DCM-DNN, henceforth) (see van Cranenburgh et al. (2022) for literature review). Both approaches improve the DCM\u2019s\r\npredictability by considering complex non-linear and interaction effects of attributes and extracting policy-relevant economic information (e.g., WTP and elasticity) through post hoc analysis (Wang et al., 2020b).\r\nWhile ensuring monotonicity requirements is challenging in both approaches, ignoring it might lead to abrupt or erratic changes in\r\nutility and counterintuitive behavioral interpretations (e.g., the positive marginal utility of cost in certain attribute domains) (Wang\r\net al., 2021, 2020a, 2020b). A handful of these studies have attempted to ensure monotonicity conditions. In the first strand, only\r\nDubey et al. (2022) could ensure monotonicity using the Choquet integral, but it does not scale well beyond six attributes. Since they\r\nseparately model attributes with monotonicity constraints and without constraints as two parts of the systematic utility, interactions\r\nbetween these two sets of attributes are ignored. Moreover, the utility specification of attributes without monotonicity constraints\r\ncould suffer from misspecification because it is hand-crafted by the researchers based on their subjective beliefs. In the second strand,\r\nonly Han et al. (2022) could incorporate monotonicity constraints by specifying systematic taste heterogeneity as DNNs but at the\r\nexpense of the inability to account for the non-linear and interaction effects of attributes. Specifically, they could ensure monotonicity\r\nby imposing constraints on the parameters\u2019 signs as they rely on linear-in-parameter utility specification where all alternative-specific\r\nFig. 1. Symbolic benchmarking of the proposed model against existing DCMs.\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n4\r\nattributes enter linearly in the utility, and interactions between them are ignored. In principle, the central purpose of DCM-DNN to\r\nlearn systematic utility in a data-driven manner is compromised by Han et al. (2022) to impose monotonicity constraints. A more\r\ndetailed review of DCM-DNN is provided in Section 2.2.\r\nThis study specifies the systematic utility of the DCM using lattice networks (LNs) to address the shortcomings of both strands of the\r\nliterature (DCM-LN, henceforth). This data-driven but theory-constrained DCM ensures monotonicity constraints while incorporating\r\nall possible non-linear and interaction effects of attributes. The mapping from input attributes to function value in the DCM-LN can be\r\nvisualized in two steps. First, a lattice layer segments the input space into grids or cells. Specifically, the input attribute vector is\r\ntransformed into a vector of interpolation weights (i.e., model parameters of the lattice layer) over the vertices of the cell that represent\r\nthe input space. Second, the function value at any point in the input space is obtained as a linear transformation of the interpolation\r\nweights (Gupta et al., 2016). While the linear transformation in the second step leads to easy-to-implement theoretical conditions for\r\nmonotonicity, the transformation of the input attribute vector in the first step captures the non-linear and interaction effects of attributes. We also add a calibration layer before and after the lattice layer to improve the ability of DCM-LN to capture non-linearities in\r\nattribute-specific effects without requiring a fine-grained lattice/grid that needs many more model parameters (see Section 3 for\r\nmethodological details). DCM-LN can thus simultaneously infer underlying non-linear effects of all (alternative- and\r\nindividual-specific) attributes and interactions between them (i.e., capturing systematic taste heterogeneity) while achieving the\r\nmonotonic effect of a subset or all alternative-specific attributes for every individual in a data-driven manner. Ensuring such\r\ntheory-driven monotonicity constraints at an individual level will naturally enforce them at the population level.\r\nFig. 1 symbolically benchmarks the systematic utility of the proposed DCM-LN against the traditional DCM with linear utility\r\nspecification without interactions (DCM-Linear) and DCM-DNN at a population and an individual level. Fig. 1a shows that the overly\r\ncomplex DCM-DNN model represents abrupt changes in marginal utility and even incorrect signs (i.e., local irregularity of utility\r\nfunction). Such behavioral irrationalities are even worse at an individual level, as indicated by potentially higher heterogeneity or\r\nvariance (see Fig. 1b). On the other hand, the overly simplified DCM-Linear causes serious bias in the marginal utility estimates. In\r\ncontrast to DCM-Linear and DCM-DNN, the DCM-LN can recover true marginal utilities over the domain of input space at an individual\r\nlevel while preserving theory-driven monotonicity constraints. The monotonicity constraints prevent the incorrect sign of the attribute\r\neffects at the individual level; thus, the population-level effect is naturally corrected. Thus, the monotonic constraints can be viewed as\r\ndomain-knowledge-based regularization to prevent the overfitting of overly complex DCM-DNN.\r\nIn summary, we customize the LNs and introduce their first application to the choice modeling to achieve a flexible utility specification while maintaining the interpretability of DCM by imposing theory-driven constraints at an individual level. We efficiently\r\nselect the hyperparameters of DCM-LN by applying the Bayesian optimization with validation accuracy as the objective function. The\r\nproposed DCM-LN is scalable in terms of the number of attributes and observations because its training relies on a structural risk (i.e.,\r\nempirical risk and model complexity) minimization framework, which is similar to that of DCM-DNN. We benchmark the performance\r\nof DCM-LN against DCM-DNN and a DCM with hand-crafted utility in a Monte Carlo study based on predictive accuracy and recovery\r\nof underlying marginal utility and individual-level WTP values. As expected, the DCM-LN has slightly lower predictive accuracy than\r\nthe DCM-DNN due to constraining the flexibility of utilities. However, DCM-LN outperforms all the considered models in capturing\r\nbehavioral realism, indicated by the better recovery of WTP estimates at an individual level. The results of the simulation study are\r\nsupported by an empirical study on an open-access and widely used Swissmetro dataset.\r\nThe remaining paper is organized as follows: Section 2 highlights the research gaps by reviewing the relevant literature on domainspecific definitions of interpretability, data-driven DCMs, and state-of-the-art machine learning methods to impose monotonicity\r\nconstraints. Section 3 explains the elements of DCM-LN, monotonicity conditions, and the estimation method. While Section 4 details\r\nthe Monte Carlo study, the empirical study is discussed in Section 5. Conclusions and avenues for future research are laid out in the\r\nfinal section.\r\n2. Background and literature review\r\nThe first section provides a general notion of interpretability, followed by discussing it in the context of travel behavior models. In\r\nthe subsequent section, we position the paper in the emerging deep-learning-based choice modeling literature by identifying the\r\nresearch gaps and emphasizing the contributions of the paper in preserving interpretability while maintaining flexibility. The final\r\nsection reviews the literature on achieving monotonicity, discusses the reasons behind choosing LNs to achieve interpretability in\r\nDCM, and highlights the LN-specific contributions of this study.\r\n2.1. Interpretability\r\nExisting flexible DCMs representing complex interactions and non-linear effects of attributes have limited policy-relevant applications because they sacrifice interpretability to enhance predictability. It is worth noting that the definition of interpretability is also\r\ndomain-dependent, i.e., interpretability constraints could be governed by the domain-specific theoretical foundation and prior\r\nknowledge (Gunning et al., 2019). Based on the discussions on the definition of interpretability in the literature, we divide interpretability into explainability and trustworthiness (Barredo Arrieta et al., 2020; Lipton, 2018; Miller, 2019). The explainable model can\r\nrepresent the cause of the model\u2019s decision by measuring the contribution/effect of each input attribute to the outcomes (e.g., marginal\r\neffects or WTP). If the cause of the decision obeys the domain-specific constraints, the model is trustworthy (e.g., monotonically\r\ndecreasing effect of travel time on travel mode preferences). In other words, trustworthiness is the capability to provide intuitive\r\nrelationships that users can trust. The trustworthiness can be controlled by inherent model structure (i.e., ante-hoc), and the explainable\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n5\r\nrelations can be derived by the post hoc analysis (Kim et al., 2020).\r\nThis framing is aligned with the recent discussion on interpretability in the transportation community. For instance, Alwosheel\r\net al. (2021) focus on the explainability aspect and propose a post hoc analysis tool to measure the attribute-specific effects. Han et al.\r\n(2022) frame that the interpretable model can provide \u2018trustworthy\u2019 or credible economic information at the disaggregated level (i.e., at\r\nindividual-level and across the entire attribute domain). Trustworthiness at a disaggregated level is particularly difficult to achieve\r\nusing DNN-based utility specifications. Specifically, Wang et al. (2020b) show that the DCM-DNN provides unreasonable\r\nattribute-specific effects for a specific domain of the attribute value and particular training run, which are further exacerbated at the\r\nindividual level. Although achieving trustworthiness at the disaggregate level is difficult, it is necessary for the DCMs because\r\ndecision-making generally requires answering \u201cwhat if\u201d questions (Han et al., 2022).\r\nThus, this study defines \u201cinterpretability\u201d as the capability to infer trustworthy and explainable economic information (e.g., WTP),\r\nobeying domain-specific constraints at an individual level and all levels of the attribute value. If we know true economic information, the\r\ninterpretability can be evaluated by the difference between the estimated and the true economic information. Since WTP estimates (e.\r\ng., value-of-travel time) are the most widely transferrable economic valuation metrics across different contexts in the choice modeling\r\nliterature, the ability to recover WTP estimates (i.e., interpretability) can also be viewed as a measure of \u201cgeneralizability.\u201d The\r\nproposed DCM-LN model outperforms state-of-the-art approaches in better recovery of WTP estimates at individual-level by imposing\r\ntheory-driven economic constraints in the estimation.\r\n2.2. Recent advancements in data-driven DCMs\r\nWith the increase in the number of attributes in emerging choice datasets, hand-crafting the utility specifications has become\r\nchallenging \u2013 compelling researchers to spend considerable time through trial and error. Two approaches have been developed to\r\nautomate (or assist) the utility specification by harmonizing the data-driven and theory-driven methods.\r\nThe first approach determines an optimal utility specification through an automated search process. This approach requires predetermining a list of potential attribute-specific effects and interaction effects, followed by selecting the optimal combination of\r\nthose effects using optimization-based approaches. Several methods have been proposed, including a multi-objective variable\r\nneighborhood search algorithm (i.e., combinatorial optimization) to produce sets of promising model specifications (Ortelli et al.,\r\n2021), a Bayesian framework to evaluate numerous model specifications based on their relevance in explaining the observed data\r\n(Rodrigues et al., 2022), and use of association rules and random forest to identify feasible model specification (Hernandez et al.,\r\n2023).\r\nUnlike the first approach that requires expert assistance in pre-determining a set of potential non-linear and interaction effects, the\r\nsecond approach is purely data-driven that improves predictive performance by providing flexible utility functions (Kim, 2021; Wang\r\net al., 2020b; Zhao et al., 2020). However, the flexibility comes at the cost of untrustworthy attribute-specific effects, violating the\r\ndomain-specific constraints. Several efforts have been made to balance the predictability and interpretability by integrating the\r\ntheory-driven and data-driven DCM in the DNN framework (Han et al., 2022; Sifringer et al., 2020; Wang et al., 2021, 2020a; Wong\r\nand Farooq, 2021; Arkoudi et al., 2023). We focus on the literature review on these hybrid DCMs based on DNN. Readers are referred to\r\nvan Cranenburgh et al. (2022) for an in-depth discussion on theory-driven and data-driven DCMs.\r\nThe hybrid DCM can be divided into two approaches: (a) DNNs supported by multinomial logit model (MNL) and (b) MNL supported by DNNs. The \u201cmain\u201d model generally constructs the baseline utility function, and the \u201csupporting\u201d model elaborates (when\r\nsupported by DNNs) or regularizes (when supported by MNL) this utility function. As the first approach, Wang et al. (2020a) introduce\r\nalternative-specific utility (ASU) in the DNN architecture, called the ASU-DNN model. Specifying the utility of an alternative based on\r\nonly its own attributes (instead of attributes of all alternatives) reduces the model complexity. The ASU-DNN exhibits better performance than DNNs despite its reduced model complexity, implying that the regularized model structure can enhance the generalized\r\nperformance. However, the ASU-DNN still represents untrustworthy effects at some attribute levels. Wang et al. (2021) subsequently\r\npropose a structure that can adjust the weight of the DNNs and MNL parts to control the trade-off between interpretability and\r\nTable 1\r\nComparison of methodological considerations of previous hybrid DCMs and the proposed method.\r\nConsiderations in ideal systematic utility specification\r\n(i) Non-linear effect of each alternative-specific attribute\r\n(ii) Interaction effects of multiple alternative-specific attributes\r\n(iii) Interaction effects of alternative- and individual-specific attributes\r\n(iv) Non-linear effect of each individual-specific attribute and their interaction effect\r\n(v) Population level trustworthiness of alternative-specific attributes\r\n(vi) Individual level trustworthiness of alternative-specific attributes\r\nType Authors (i) (ii) (iii) (iv) (v) (vi)\r\nDNNs supported by MNL Wang et al. (2020a) \u2713 \u2713 \u2713 \u2713\r\nWang et al. (2021) \u2713 \u2713 \u2713 \u2713\r\nWong and Farooq (2021) \u2713 \u2713 \u2713 \u2713\r\nMNL supported by DNNs Sifringer et al. (2020) \u2713 \u2713 \u2713\r\nHan et al. (2022) \u2713 \u2713 \u2713 \u2713\r\nProposed DCM-LN \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n6\r\npredictability. However, even in their optimal model, an untrustworthy attribute-specific effect occurs at some levels of an attribute\r\nvalue, which is exacerbated as the weights of DNNs increase. Also, calibrating the weights for DNNs and MNL requires the researcher\u2019s\r\nsubjective judgment for measuring the degree of trustworthiness, making it difficult to generalize. Wong and Farooq (2021) leverage\r\nthe DNNs to model the utility residuals, which helps relax the independent and identically distributed error assumptions. Their model\r\ncan capture the non-linear effect and interactions, but population-level and individual-level attribute effects are not strictly constrained to have trustworthiness.\r\nAs the second approach, Sifringer et al. (2020) divide the utility function into two parts but simultaneously estimate using a\r\nstandard DNN framework. One part represents the theory-driven MNL for some known attributes (e.g., travel time and travel cost),\r\nwhile the other part represents the DNNs for the remaining attributes. Since their model assumes the theory-driven part as an additive\r\nlinear utility specification similar to MNL, non-linear effects and interactions of those attributes with other attributes are not\r\nconsidered. Han et al. (2022) employ the DNNs to capture the individual taste heterogeneity of MNL. The DNNs directly output the\r\nnon-parametric distribution of the alternative-specific coefficient of the MNL by capturing the flexible interactions between\r\nindividual-specific attributes. To ensure monotonicity, they impose a sign constraint on the output of DNNs (i.e., individual-level\r\nalternative-specific coefficient). Their simulation study shows that the model accurately captures individual taste heterogeneity\r\nand provides a trustworthy attribute effect at the individual level. However, like Sifringer et al. (2020), this approach requires\r\nhand-crafted correct specification of the MNL\u2019s utility and does not consider the interactions and non-linear effects of\r\nalternative-specific attributes.\r\nTable 1 summarizes the methodological considerations of previous approaches. Whereas the first strand enhances the interpretability of DNNs without hand-crafting the utility function, trustworthiness is not ensured at individual-level and specific levels of the\r\nattribute value. The second set of approaches complements MNL with the DNN\u2019s flexibility to enhance predictability, but they achieve\r\ntrustworthiness at the expense of potential misspecifications in the hand-crafted parts of the utility function. In the backdrop of this\r\nreview, the main contribution of this study is to propose a novel DCM-LN that ensures interpretability (i.e., trustworthiness) at a\r\ndisaggregated level (i.e., individual-level and across the entire attribute domain) while preserving its capability to capture the nonlinear effects and interactions of all individual- and alternative-specific attributes. Thus, we show how the proposed DCM-LN improves interpretability without much compromise on predictability by imposing the monotonicity constraints and inferring underlying\r\nutility functions in a data-driven manner.\r\n2.3. Monotonicity constraints\r\nMonotonicity is the most intuitive and incontrovertible property in economic-related domains. The easiest way to impose the\r\nmonotonicity constraint is to assume the linear utility function and force the constant coefficient for an attribute as non-negative (or\r\nnon-positive). As mentioned earlier, Han et al. (2022) adopt this approach by designing the DNNs to output the constant coefficient for\r\nthe individual-level linear utility function of the target attribute. However, linear functions are generally not flexible enough to\r\nrepresent the systematic indirect utility in DCM. To ensure monotonic utility function without compromising flexibility, we review\r\napproaches from the machine learning community.\r\nArcher and Wang (1993) propose preprocessing the input data using a linear classifier to exclude the training data causing large\r\nfluctuations and violating the monotonicity conditions. Using the preprocessed data, they train the neural networks and skip the\r\nparameters violating the monotonicity constraints. However, this approach is ad hoc due to its reliance on the linear classifier for\r\npreprocessing. Qu and Hu (2011) devise a generalized constrained neural network that applies the linear inequality constraints to the\r\nleast square optimization for updating the weights of neural networks (i.e., constraining the derivative of weights). Their method\r\nachieves better predictive accuracy and ensures monotonic constraints but is not scalable due to high computational costs. Daniels and\r\nVelikova (2010) propose a neural network with two \"min-max\" hidden layers to ensure partial monotonicity (i.e., monotonicity\r\nconstraints for some attributes, not all) by extending Sill (1997)\u2019s model. The first layer clusters the input data into several groups, and\r\nthe first layer\u2019s weights are fixed as positive using the maximum of each group. Then, the second layer computes the minimum of each\r\ngroup. The outputs of these layers have the form of a piecewise linear function that can represent any arbitrary function. Their study\r\nshows that partial monotonicity can be achieved by revising the neural network architecture while maintaining the standard optimization process for training the neural network. Gupta et al. (2016) propose lattice networks (LNs) consisting of two layers: the\r\ncalibrator layer and the lattice layer. The calibration layer captures the attribute-specific non-linear effect, and the lattice layer\r\ncaptures the interactions of those non-linear effects. Also, the LNs can efficiently implement the linear inequalities for monotonicity\r\nconstraints in a standard risk minimization framework. Their case studies show that the LNs provide state-of-the-art predictive performance among approaches that ensure monotonicity. You et al. (2017) extend the LNs by incorporating ensemble learning and deep\r\nlearning. They design complex combinations of calibrators and lattices with deeper layers to enhance flexibility. Multiple lattices for a\r\nsubset of attributes are estimated and ensembled to improve predictability. Their deep lattice networks with six layers achieve\r\nstate-of-the-art predictive performance while ensuring monotonicity. Liu et al. (2020) propose a heuristic regularization to verify the\r\nmonotonicity in the neural network. They define the extent of monotonicity and measure it by solving mixed linear integer programming during neural network training, which is further incorporated as an additional loss function for regularization. Although\r\ntheir approach has marginally better predictive performance than the deep lattice networks, it has lower transferability to practice as it\r\nrelies on a complicated training process, deviating from the standard risk minimization framework.\r\nThe proposed DCM-LN adopts the state-of-the-art lattice network framework of Gupta et al. (2016) and You et al. (2017) to specify\r\nthe systematic part of the indirect utility but customizes it for RUM-based DCM. Specifically, we propose the best combination of\r\ncalibration layer and lattice layer specification such that the architecture is light enough to be estimable using standard state\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n7\r\npreference datasets and capture all possible interactions and non-linear effects of attributes while ensuring the monotonicity of\r\npreferences for differentiated products/services relative to the selected subset of attributes. DCM-LN is the first model to flexibly\r\ncapture systematic taste heterogeneity through interactions while maintaining preference monotonicity relative to an attribute at an\r\nindividual level. Also, by incorporating the post hoc analysis, we provide individual-level utility functions for each attribute and WTP\r\nestimates. The explainability and trustworthiness of the individual-level utility functions are evaluated using simulated and empirical\r\ndatasets.\r\nTable 2\r\nMathematical notations.\r\nRUM-based DCM Formulation\r\nUon The indirect utility of individual n \u2208 {1, \u2026, N} for alternative o \u2208 {1, \u2026, O}\r\nVon The systematic utility of individual n for alternative o\r\n\u03b5on The error term in the indirect utility of individual n for alternative o\r\nXon The vector of D input attributes, including alternative-specific attributes and individual-specific attributes\r\nXon[d] The dth attribute of Xon\r\nXM\r\non The vector of K \u2018monotonic attributes\u2019 among D input attributes\r\nXM\r\non[k] The kth attributes of XM\r\non\r\nXNM\r\non The vector of (D \u2212 K) \u2018non-monotonic attributes\u2019 among D input attributes\r\nFo(Xon; \u03b8) The alternative-specific utility functions with parameter \u03b8 taking Xon as input\r\nPon The choice probability of an individual n for the alternative o from a choice set with O alternatives\r\nPn The vector of choice probability of an individual n for O alternatives\r\nL The standard cross-entropy loss function\r\nyn The vector of observed choices of an individual n\r\nDCM-Linear\r\nFLi\r\no (Xon; \u03b8Li) The alternative-specific utility function that is represented by linear function with parameters \u03b8Li\r\n\u03b2 The constant attribute-specific effect in the linear utility function\r\nDCM-DNN\r\nFDNN\r\no (Xon; \u03b8DNN) The alternative-specific utility function that is represented by DNNs with parameters \u03b8DNN\r\nh The multiple neurons in the multiple hidden layers of DNNs\r\nhj The j\r\nth hidden layer among H number of hidden layers in the DNNs\r\nAH+1 o The last layer to make FDNN\r\no an alternative-specific utility function\r\nGeneralized additive model (GAM)\r\nFGAM\r\no The alternative-specific utility function having a form of GAM\r\ngd The attribute-specific function that captures the inherent non-linear effect in FGAM\r\no\r\nr1\r\nd,d\u2032 The first-order interaction between the non-linear effects of attributes d and d\u2032 (d \u2215= d\u2032)\r\nrD\r\nd,\u2026,d\u2032 The Dth order interaction effects\r\nDCM-LN\r\nFLN\r\no (Xon; \u03b8LN) The alternative-specific utility functions that is represented by LNs with parameters \u03b8LN\r\nCIN The attribute-specific input calibrators in the input calibration layer\r\n\u03b8LN\r\nINCal The parameters for CIN that is the slopes of the input calibrators\r\nL The lattice function in the lattice layer\r\n\u03b8LN\r\nLat The parameters for L that is the functional values at vertices\r\n\u03b8LN\r\nLat,i,j The functional value at (i, j) location of vertex\r\nSd The lattice size of L for dth attribute dimension\r\nXIN\r\non The input for the L, which is the output of CIN\r\nXIN\u2217 on The specific point in the lattice (i.e., any input point for the lattice layer)\r\nv The surrounding vertices of XIN\u2217 on\r\nv(i,j) The value at (i, j) location of surrounding vertices of XIN\u2217 on\r\nv(i,j)[d] The value for the dth attribute at (i, j) location of surrounding vertices of XIN\u2217 on\r\nminv(i,j)[d] The minimum value for the dth attribute within the surrounding vertices of XIN\u2217 on\r\nmaxv(i,j)[d] The maximum value for the dth attribute within the surrounding vertices of XIN\u2217 on\r\n\u03c8(XIN\u2217 on ) The vector of the multi-linear interpolation weights for XIN\u2217 on\r\nCOUT The alternative-specific output calibrators in the output calibration layers\r\n\u03b8LN\r\nOUTCal The parameters for COUT that is the slopes of the output calibrators\r\nR(\u03b8LN\r\ninCal) The wrinkle regularizer and Hessian regularizer to the input calibration layer\r\nA The matrix to represent inequality constraints for \u03b8LN\r\nLat\r\nB The matrix to represent inequality constraints for \u03b8LN\r\nINcal\r\nC The matrix to represent inequality constraints for \u03b8LN\r\nOUTcal\r\nPartial dependence (PD) and individual conditional expectation (ICE)\r\nXon[ \u2212 d] The remaining attributes of Xon except dth attribute\r\nPDo[d] The PD of dth attribute on the utility of alternative o,\r\nICEon[d] The ICE of dth attribute of individual n on the utility of alternative o\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n8\r\n3. Methods\r\nThis section has five sections. The first section discusses the general formulation of RUM-based DCM and different functional forms\r\nof the systematic utility under DCM-Linear and DCM-DNN. The second section formalizes the partial monotonicity conditions, sketches\r\nthe proposed architecture of DCM-LN, and details lattice and calibration layers in DCM-LN while identifying corresponding hyperparameters and estimable parameters. The third section describes the process of writing monotonicity constraints in the DCM-LN,\r\nregularizations, and training process under the structural risk minimization framework. While the penultimate section discusses the\r\nBayesian optimization procedure to select the optimal hyperparameters, the final section describes the metrics to evaluate the recovery\r\nof the underlying utility function at individual and population levels. We use consistent notations across all models in Section 3, which\r\nare summarized in Table 2.\r\n3.1. RUM-based DCM formulations\r\nThe RUM-based DCM hypothesizes that an individual chooses the alternative maximizing indirect utility (McFadden, 1973; Train,\r\n2009). The indirect utility of individual n \u2208 {1, \u2026, N} for alternative o \u2208 {1, \u2026, O} is a sum of systematic utility (Von) and error term\r\n(\u03b5on) as denoted in Eq. (1), where the Von is computed using alternative-specific utility functions Fo with parameter \u03b8:\r\nUon = Von + \u03b5on = Fo(Xon; \u03b8) + \u03b5on, (1)\r\nwhere Xon is a vector of D input attributes, that includes alternative-specific attributes and individual-specific attributes. If the \u03b5on is\r\nassumed to be identically and independently Gumbel-distributed, the probability of choosing the alternative o by an individual n from\r\na choice set with O alternatives, takes the form of the Softmax activation function shown in Eq. (2):\r\nPon = eFo (Xon;\u03b8)\r\n/\u2211O\r\nj=1\r\neFj(Xjn ;\u03b8). (2)\r\nBased on the Softmax activation form of choice probability, the RUM-based DCMs can be estimated by standard empirical risk\r\nminimization:\r\n\u03b8\u2217 = argmin\u03b8\r\n\u2211N\r\nn=1\r\nL (yn, Pn), (3)\r\nwhere L is the standard cross-entropy loss function, Pn is a vector of choice probability of an individual n for O alternatives, and yn is a\r\nvector of observed choices of an individual n. The DCM-Linear assumes the utility function Fo is a linear function FLi\r\no with \u03b8Li as a vector\r\nof coefficients for Xon. The \u03b8Li directly relates to the vector of attribute-specific effects \u03b2 as shown in Eq. (4).\r\nFLi\r\no\r\n(\r\nXon; \u03b8Li)\r\n= \u03b2Xon. (4)\r\nIn DCM-DNN, the DNN represents the utility function FDNN\r\no by multiple neurons in the multiple hidden layers (h):\r\nFDNN\r\no\r\n(\r\nXon; \u03b8DNN)\r\n= AH+1\r\non (\r\nhH \u2218 \u2026 \u2218 hj \u2218 \u2026 \u2218 h1\r\n)\r\n(Xon), (5)\r\nwhere H is the number of layers in the DNN, hj is j\r\nth hidden layer, and AH+1 o is the last layer before the Softmax activation function to\r\nmake FDNN\r\no an alternative-specific utility function. \u03b8DNN is a vector of the weights (i.e., parameters) connecting neurons of hidden\r\nlayers.\r\nSince the \u03b8Li directly indicates the constant attribute-specific effects (\u03b2) on the utility across the entire attribute domain, it can\r\nprovide good interpretability. In contrast, the FDNN\r\no captures the inherent non-linear effects and various interaction effects through a\r\nlarge number of parameters \u03b8DNN (i.e., the length of vector \u03b8DNN \u226b the length of vector \u03b8Li) (Cybenkot, 1989). However, empirical\r\nstudies have shown that FDNN\r\no minimizes the loss function with overly complex models (Wang et al., 2020b, 2020a), leading to the\r\noverestimated interactions between attributes.\r\nThe key component, the lattice layer, of the proposed DCM-LN is inspired by a generalized additive model (GAM)that have the\r\nfollowing flexible, yet interpretable, form of the utility function (Hastie and Tibshirani, 1987).\r\nFGAM\r\no (Xon) = \u2211D\r\nd=1\r\ngd(Xon[d]) +\u2211\r\nd\u2019\u2215=d\r\nr1\r\nd,d\u2019(gd(Xon[d]), gd\u2019(Xon[d\u2019\r\n])) + \u22ef +\u2211\r\nd\u2019\u2215=d\r\nrD\r\nd,\u22ef,d\u2019(gd(Xon[d]), \u22ef, gd\u2019(Xon[d\u2019\r\n])), (6)\r\nwhere gd denotes an attribute-specific function that captures the inherent non-linear effect and Xon[d] is dth attribute in Xon vector. The\r\nr1\r\nd,d\u2019 indicates the first-order interaction between the non-linear effects of dth and d\u2032\r\nth attributes (d \u2215= d\u2032), and the rD\r\nd,\u22ef,d\u2019 captures the Dth\r\norder interactions. Thus, the proposed flexible DCM-LN can capture all possible attribute effects to represent the complex choice\r\nbehavior: (i) non-linear effect of each alternative-specific attribute; (ii) interaction effect of multiple alternative-specific attributes; (iii)\r\ninteraction effects of individual-specific and alternative-specific attributes; and (iv) non-linear effect of each individual-specific\r\nattribute and their interaction effects. In contrast to traditional GAM, DCM-LN ensures trustworthiness by imposing domainE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n9\r\nspecific monotonicity constraints on some attributes that are expected to have monotonic effects on the utility. The details of all layers\r\nof DCM-LN and the connection of the lattice layer with Eq. (6) will be further detailed in the next section.\r\n3.2. Lattice network\r\n3.2.1. Partial monotonicity and DCM-LN framework\r\nThe key requirement for trustworthiness in the DCM is partial monotonicity, i.e., monotonicity of utility function or choice\r\nprobability relative to the selected subset of attributes. For example, we expect that increasing travel costs should result in the nonincreasing utility of travel mode, ceteris paribus, regardless of the attribute levels of travel cost and other individual attributes.\r\nHowever, imposing monotonicity is challenging in flexible models that capture complex non-linear and interaction effects of attributes\r\nFig. 2. An architecture of discrete-choice model with (a) lattice networks (DCM-LN) to estimate the partial monotonic utility function and (b) deep\r\nneural networks (DCM-DNN) to estimate the unconstrained one.\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n10\r\nbecause it must be ensured across the entire domain of attributes.\r\nWe now formalize the notion of partial monotonicity mathematically. To simplify the mathematical notation, we provide an\r\nexample in the case of a monotonically non-decreasing case (i.e., a partial derivative of Fo relative to an attribute is greater than or\r\nequal to zero). Also, to simplify the notation, we assume that the dataset only includes alternative-specific attributes, but without loss\r\nof generality, the following discussion is still valid for the case where the individual-specific attributes and non-increasing function are\r\nconsidered.\r\nThe input attributes can be redefined as Xon = (XM\r\non,XNM\r\non ) \u2208 RD, where XM\r\non \u2208 RK includes K \u2018monotonic attributes\u2019 that are expected\r\nto have monotonically non-decreasing effects on the utility function Fo, while XNM\r\non \u2208 RD\u2212 K includes (D \u2212 K) \u2018non-monotonic attributes\u2019\r\nthat have unconstrained effects. Such a utility function is called a \u2018partial monotonic function.\u2019 The individual-level non-decreasing\r\nmonotonicity exists for the monotonic attributes XM\r\non if \u2202Fo\r\n\u2202XM\r\non[1] \u22650,\u2026, \u2202Fo\r\n\u2202XM\r\non[k] \u22650, \u2026, \u2202Fo\r\n\u2202XM\r\non[K] \u22650 for any observation of Xon = (XM\r\non,XNM\r\non ),\r\nwhere XM\r\non[k] is kth attributes of XM\r\non.\r\nIf we assume the linear utility function, we can easily implement the monotonicity constraints by making the constant coefficient \u03b2\r\nnon-negative or non-positive, depending on the direction of the effect. However, such constraints become complex with the interaction\r\neffects. To illustrate this, Eq. (7) represents a simple utility function (FLi,1st o ) consisting of two monotonic attributes (XM\r\non[1],XM\r\non[2]) with\r\nfirst-order interactions.\r\nFLi,1st\r\no\r\n(\r\nXM\r\non[1], XM\r\non[2]\r\n)\r\n= \u03b20 + \u03b21XM\r\non[1] + \u03b22XM\r\non[2] + \u03b23XM\r\non[1]XM\r\non[2] (7)\r\nIf we want to ensure that the individual-level utility should be monotonically non-decreasing relative to XM\r\non[1] and XM\r\non[2], we need\r\nto impose two inequality constraints on parameters during the training, as shown in Eq. (8).\r\n\u03b21 + \u03b23XM\r\non[2] \u2265 0; \u03b22 + \u03b23XM\r\non[1] \u2265 0 for any observation (\r\nXM\r\non[1], XM\r\non[2]\r\n) (8)\r\nHand-crafting these partial monotonicity constraints becomes complex and impractical if the attribute-specific effects are nonlinear since the inequalities must be checked across all attribute levels. The number of constraints becomes unmanageable if\r\nhigher-order interactions of constrained attributes are considered with several other attributes.\r\nThe DCM-LN efficiently evaluates these inequality constraints while maintaining flexibility. Fig. 2a shows the DCM-LN framework\r\nto estimate the partial monotonic utility function for multi-alternative choice situation. In DCM-LN, the alternative-specific utility\r\nfunctions FLN\r\no (Xon; \u03b8LN) is represented by three sequentially connected components: the input calibration layer, the lattice layer, and the\r\noutput calibration layer, where the \u03b8LN is a set of parameters for these layers. The lattice layer is the key component, which captures the\r\nattribute-specific non-linear effect as segmented effects for each cell (i.e., piecewise linear) in the lattice and the interactions of these\r\nnon-linear effects using multilinear interpolation. The calibration layers before (input) and after (output) the lattice layer improve the\r\nability of DCM-LN to capture non-linearities in attribute-specific effects without requiring a fine-grained lattice (i.e., circumventing the\r\nneed for many model parameters). In other words, the input and output calibration layers make the lattice layer specification\r\nparsimonious by sharing the burden of capturing the complex non-linear effects. The novelty of DCM-LN stems from maintaining\r\nflexible utility specification while reducing the number of inequality constraints to ensure partial monotonicity requirements across\r\nthe entire domain of attributes. The process to write these constraints is also automated, which makes DCM-LN practice-ready.\r\nThe DCM-LN considers the alternative- and individual-specific attributes separately. The number of parameters \u03b8LN drastically\r\nincreases as the number of alternatives increases. In this regard, this study specifies each alternative\u2019s utility based on its attributes,\r\nFig. 3. Examples of attribute-wise non-linear transformation through the input calibration layer.\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n11\r\ninstead of all attributes, to enhance the regularity of the attribute-specific effects. As displayed in Fig. 2a, O \u00d7 D nodes in the input\r\ncalibration layer and O lattices in the lattice layer, followed by the output calibration layer, provide the utility for each alternative o.\r\nThe alternative-specific utility is passed through the Softmax activation to calculate the final choice probabilities. The blue box in the\r\nfigure represents the attribute-specific input calibrators for the first alternative, and the same structure is applied to other alternatives.\r\nThe individual-specific attributes are input to all lattices to capture the interaction between the individual- and alternative-specific\r\nattributes (i.e., systematic taste heterogeneity), in addition to their main effects. Fig. 2b shows the considered DCM-DNN architecture to benchmark against the proposed DCM-LN, which is also denoted in Eq. (5). DCM-DNN puts all alternative and individual\r\nattributes into a large fully-connected network. Then, it estimates the alternative-specific utility using a subsequent small fullyconnected network. We also tested the deep neural networks for alternative-specific utility (ASU-DNN) (Wang et al., 2020a) for\r\nDCM-DNN, which replaces the fully connected network in the shared layer with three fully connected networks for each alternative,\r\nbut it does not outperform the considered DCM-DNN in terms of both predictability and interpretability.\r\nWe describe the details of three layers in Sections 3.2.2\u20133.2.4. The training process will be discussed in Section 3.3.\r\n3.2.2. Input calibration layer\r\nThe input calibration layer in Fig. 2a implements the attribute-specific transformations to capture the attribute-specific non-linear\r\neffect before the lattice layer, using one-dimensional monotonic piecewise linear functions CIN, called input calibrators. Fig. 3 illustrates the examples of transformation function in the input calibrator. The only hyperparameter for a dth attribute input calibrator is the\r\nnumber of change points, and the change points are set as the equally distanced cells in each attribute domain. For example, if one\r\nattribute ranges from zero to one, and the number of change points is set as 11, the change points would be 0.0, 0.1, 0.2, \u2026, 1.0. The\r\nlarger the calibrated number of change points, the higher the extent of non-linearity of attribute-specific effect exists. The estimable\r\nparameters for the input calibration layer, \u03b8LN\r\nINCal, are the slopes of piecewise linear function in the attribute-specific calibrators, as\r\nshown in Fig. 3. For example, \u03b8LN\r\nINCal,4 indicates the slope between vertices 4 and 2 in Fig. 3a. The calibrated value of the input calibrator\r\nfor each attribute is normalized based on the corresponding lattice size of the following lattice layer. For example, as shown in Fig. 3a,\r\nthe calibrated value of travel cost ranges from 0 to 1 for the lattice size of 2, while the calibrated value of travel time ranges from 0 to 2\r\nfor the lattice size of 3, as shown in Fig. 3b.\r\n3.2.3. Lattice layer\r\nFor the input attributes, Xon = (XM\r\non,XNM\r\non ) \u2208 RD, we define the lattice size Sd for each attribute dimension, which is the number of\r\nvertices along the dth attribute dimension. Then, the lattice can be represented by S = S1 \u00d7 \u2026 \u00d7 Sd \u00d7 \u2026 \u00d7 SD parameters and spans the\r\n(S1 \u2212 1) \u00d7 \u2026 \u00d7 (Sd \u2212 1) \u00d7 \u2026 \u00d7 (SD \u2212 1) hyper-rectangle. The lattice size for each attribute is related to the extent of non-linearity in the\r\neffect of the attribute. Thus, the larger lattice size (i.e., fine-grained lattice) represents a more flexible utility function.\r\nIn Fig. 2a, the value of the lattice function L(CIN(Xon)) in the lattice layer is a weighted linear combination of the function values at\r\nsurrounding vertices, where function values at vertices are estimable parameters. The CIN(Xon) (denoted as XIN\r\non) is an output of input\r\ncalibration layer that is normalized according to the attribute-specific lattice size of lattice layer. At the same time, XIN\r\non is the input to\r\nFig. 4. Example of 3 \u00d7 2 lattice approximating the value of function by multi-linear interpolation.\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n12\r\nthe lattice layer.\r\nFig. 4 shows an illustrative example of lattice layer for two input attributes, XIN\r\non = (XIN\r\non[1], XIN\r\non[2]), such that S1 = 3, S2 = 2. The value\r\nof the lattice function L( \u22c5 ) at a specific point, XIN\u2217 on = (XIN\u2217 on [1], XIN\u2217 on [2]) is obtained by interpolating the value of the function at surrounding vertices v of XIN\u2217 on , which split the input space into S1 and S2 cells. The parameters of the lattice function are the functional\r\nvalues at vertices, which are denoted as \u03b8LN\r\nLat (e.g., \u03b8LN\r\nLat,1,1 = L(v1,1) in Fig. 4, where v1,1 is the value at (1,1) location of a surrounding\r\nvertex). For example, in Fig. 4, the values at vertices v1,1, v2,1, v1,2, and v2,2 are (0,0), (1,0), (0,1), and (1,1), respectively. Note that vi,j is\r\nnot necessarily 0 or 1 if the XIN\u2217 on is located around v3,1, or v3,2, whose values at vertices are (2,1) and (2,0), respectively. The grayscale\r\nvalue in the lattice in Fig. 4 indicates the estimated value of L(XIN\u2217 on [1],XIN\u2217 on [2]).\r\nSpecifically, in the illustrative example in Fig. 4, the value of lattice function at XIN\u2217 on can be computed by interpolating the function\r\nvalues at 4 surrounding vertices:\r\nL\r\n(\r\nXIN\u2217\r\non )\r\n= \u03b8LN\r\nLat \u22c5 \u03c8\r\n(\r\nXIN\u2217\r\non )\r\n= \u03b8LN\r\nLat,1,1\u03c81,1\r\n(\r\nXIN\u2217\r\non )\r\n+ \u03b8LN\r\nLat,2,1\u03c82,1\r\n(\r\nXIN\u2217\r\non )\r\n+ \u03b8LN\r\nLat,1,2\u03c81,2\r\n(\r\nXIN\u2217\r\non )\r\n+ \u03b8LN\r\nLat,2,2\u03c82,2\r\n(\r\nXIN\u2217\r\non )\r\n, (9)\r\nwhere \u03c8(XIN\u2217 on ) is a vector of the multi-linear interpolation weights for XIN\u2217 on , which is computed based on the values of surrounding\r\nvertices v as follows:\r\n\u03c8(i,j)\r\n(\r\nXIN\u2217\r\non )\r\n= \u220fD\r\nd=1\r\n(\r\nXIN\u2217\r\non [d] \u2212 minv(i,j)[d]\r\n)(v(i,j)[d]\u2212 minv(i,j)[d])(\r\nmaxv(i,j)[d] \u2212 XIN\u2217\r\non [d]\r\n)(maxv(i,j)[d]\u2212 v(i,j)[d]) (10)\r\nwhere v(i,j)[d] is the value for the dth attribute at (i, j) location of surrounding vertices of XIN\u2217 on . The minv(i,j)[d] and maxv(i,j)[d] are\r\nminimum and maximum values for the dth attribute within the surrounding vertices, respectively. For example, in the case of XIN\u2217 on in\r\nFig. 4, minv(i,j)[1] (i.e., the minimum of v1,1[1], v1,2[1], v2,1[1], v2,2[1]) is 0, minv(i,j)[2] is 0, maxv(i,j)[1] is 1, and maxv(i,j)[2] is 1. Since the\r\nsurrounding vertices always make a unit hypercube, (v(i,j)[d] \u2212 minv(i,j)[d]) and (maxv(i,j)[d] \u2212 v(i,j)[d]) are either 0 or 1. Using Eqs. (9) and\r\n(10), L(XIN\u2217 on ) in the Fig. 4 is calculated as in Eq. (11):\r\nL\r\n(\r\nXIN\u2217\r\non )\r\n= \u03b8LN\r\nLat,1,1\r\n(\r\n1 \u2212 XIN\u2217\r\non [1]\r\n)( 1 \u2212 XIN\u2217\r\non [2]\r\n)\r\n+ \u03b8LN\r\nLat,2,1XIN\u2217\r\non [1]\r\n(\r\n1 \u2212 XIN\u2217\r\non [2]\r\n)\r\n+ \u03b8LN\r\nLat,1,2\r\n(\r\n1 \u2212 XIN\u2217\r\non [1]\r\n)\r\nXIN\u2217\r\non [2] + \u03b8LN\r\nLat,2,2XIN\u2217\r\non [1]XIN\u2217\r\non [2] (11)\r\nAs discussed earlier, there are some similarities in the lattice function and the generalized additive model (GAM). We discuss some\r\ncorrespondence between Fig. 4 and Eq. (6). The attribute-specific non-linear effects g1(Xon[1]) and g2(Xon[2]) in Eq. (6) correspond to\r\nthe lattice function values on the axis of XIN\r\non[1] and XIN\r\non[2], respectively. The first-order interactions r1\r\n1,2(g1(Xon[1]), g2(Xon[2])) correspond to the functional values L(XIN\u2217\r\non ) on the lattice (i.e., gray scale value) that are calculated by interpolating the function values at\r\nvertices around XIN\u2217\r\non .\r\nWe illustrate in Section 3.3 that applying constraints on \u03b8LN\r\nLat is sufficient to ensure the partial monotonicity of L(XIN\u2217 on ) relative to a\r\nsubset of attributes with expected monotonic effects. The process of writing these constraints can be generalized and automated for any\r\nsize of the lattice.\r\n3.2.4. Output calibration layer\r\nThe output of the lattice layer is a vector of the same size as the number of alternatives. The output calibration layer transforms the\r\noutput of lattice layer to supplement the non-linearity before representing the final utility. The output calibrators (COUT) in this layer\r\nshare the same functional form as the input calibrator (i.e., one-dimensional monotonic piecewise linear function with a single\r\nhyperparameter, the number of changing points). Therefore, the estimable parameters for the output calibration layer, \u03b8LN\r\nOUTCal, are also\r\nthe slopes of piecewise linear functions. However, the input calibration layer has as many nodes as the number of attributes, while the\r\noutput calibration layer has as many nodes as the number of alternatives (i.e., alternative-specific calibrators).\r\nThe combination of input calibration layer, lattice layer, and output calibration layer achieves parsimonious model specification to\r\ncapture non-linear and interaction effects while efficiently ensuring partial monotonicity. Specifically, the input calibration layer and\r\nthe lattice layer capture the attribute-specific non-linear effect, but the latter additionally captures the interaction effects between\r\nthose attribute-specific effects. The output calibration layer further supplements the non-linearity of the final output. The lattice layer\r\nmainly determines the computational complexity because the number of required inequality conditions for monotonicity constraints\r\ndrastically increase as the lattice size increases. Therefore, if the input calibration layer can capture enough non-linearity of attributespecific effects and the output calibration layer can supplement the overall non-linearity, we can reduce the lattice size as capturing\r\ninteraction effects becomes the main job of the lattice layer.\r\nIn summary, the COUT(L(CIN(Xon)) in Fig. 2a estimates the alternative-specific utility function\r\nFLN\r\no (Xon; \u03b8LN) for multi-alternative choice. The parameter of DCM-LN, \u03b8LN, consists of (i) the slopes of piecewise linear function in\r\nthe attribute-specific input calibrators \u03b8LN\r\nINCal (ii) S = S1 \u00d7 \u2026 \u00d7 Sd \u00d7 \u2026 \u00d7 SD number of parameters representing the value of function in\r\nthe vertices \u03b8LN\r\nLat, and (iii) the slope of piecewise linear function in the alternative-specific output calibrators \u03b8LN\r\nOUTCal. The parameters for\r\nthese three different layers are jointly estimated in the training process. We discuss monotonicity constraints on these parameters in\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n13\r\nSection 3.3.\r\n3.3. Training the lattice networks\r\nFor the discrete choice datasets consisting of input attributes Xon and output choices yon, the objective of the training DCM-LN is to\r\nestimate the \u03b8LN = {\u03b8LN\r\nINCal, \u03b8LN\r\nLat, \u03b8LN\r\nOUTCal} while ensuring the monotonicity constraints for a subset of attributes. For the kth attribute\r\n(XM\r\non[k]) that monotonically increases the utility, the monotonicity is ensured in the lattice layer if \u03b8LN\r\nLat, s \u2265 \u03b8LN\r\nLat, r for all adjacent\r\nvertices s and r along the kth attribute dimension. The s and r indicate the location of the vertex in a generalized manner, regardless of\r\nthe dimension of the lattice. The examples of adjacent vertices s and r in Fig. 4 are (\u03b8LN\r\nLat, (1,1), \u03b8LN\r\nLat, (1,2)) or (\u03b8LN\r\nLat, (2,1),\u03b8LN\r\nLat, (3,1)). Therefore,\r\nthe number of inequality constraints to be checked for partial monotonicity depends on the number of monotonic (K) and nonmonotonic (D \u2212 K) attributes, and the lattice size S. For example, if all K attributes are monotonically constrained (K = D), and the\r\nlattice size consists of 2K vertices (i.e., the lattice sizes of all attributes is 2), it requires checking K \u00d7 2K \u2212 1 inequality constraints (i.e.,\r\nthe number of edges in the K-dimensional hypercube). If K out of D attributes are monotonically constrained with the lattice size 2, the\r\nrequired number of inequality constraints is K \u00d7 2D \u2212 1 (i.e., the number of edges related to K attributes in the D-dimensional hypercube). Similarly, monotonicity constraints are also imposed on the attribute-specific input calibrators and the alternative-specific\r\noutput calibrators.\r\nFor the parameters of input calibrator for kth monotonic attribute, \u03b8LN\r\nINCal[k] (i.e., the slopes of piecewise linear function between\r\nadjacent vertices), \u03b8LN\r\nINCal, s[k] \u2264 \u03b8LN\r\nINCal,r[k] should be maintained for all adjacent vertices s and r, to make the CIN(XM\r\non[k]) be a piecewise\r\nmonotonically increase linear function. The examples of adjacent vertices s and r in Fig. 3a are (\u03b8LN\r\nINCal, 2, \u03b8LN\r\nINCal,4) or (\u03b8LN\r\nINCal,4, \u03b8LN\r\nINCal,6).\r\nWith the similar constraints and functional form, the output calibrator is also estimated as a one-dimensional monotonic piecewise\r\nlinear function.\r\nWith these three types of inequality constraints, the DCM-LN is estimated based on a structural risk minimization (i.e., considering\r\nboth empirical risk and model complexity) using batched stochastic gradients and ADAM optimizer. The estimation of the \u03b8LN is\r\nformulated as shown in Eq. (12) through (14).\r\nFLN\r\no\r\n(\r\nXon; \u03b8LN)\r\n= COUT (\r\nL\r\n(\r\nCIN(\r\nXon; \u03b8LN\r\nINCal)\r\n; \u03b8LN\r\nLat)\r\n; \u03b8LN\r\nOUTCal) (12)\r\nPLN\r\non = eFLN\r\no (Xon;\u03b8LN )\r\n/\u2211O\r\nj=1\r\ne\r\nFLN\r\nj (Xjn;\u03b8LN ) (13)\r\nargmin\r\n\u03b8LN\r\n\u2211N\r\nn=1\r\nL (\r\nyn, PLN\r\non )\r\n+ R\r\n(\r\n\u03b8LN\r\nINCal)\r\ns.t A\u03b8LN\r\nLat \u2264 0, B\u03b8LN\r\nINCal \u2264 0, and C\u03b8LN\r\nOUTCal \u2264 0 (14)\r\nWe apply the wrinkle regularizer and Hessian regularizer (R(\u03b8LN\r\ninCal)) to the input calibration layer for each attribute. The wrinkle\r\nregularizer gives a penalty for the changes in the second derivative of the output of input calibration layer, while the Hessian regularizer penalizes for the change in slopes of subsequent piece-wise linear functions. These regularizers can also be applied to the output\r\ncalibration layer and the lattice layer, but we do not opt for that because the number of changing points in the output calibration layer\r\nand the lattice size in lattice layer are not that high compared to the changing points in the input calibration layer.\r\nThe monotonicity constraints are imposed by inequality constraints related to the matrix A, B, and C in Eq. (14). Only matrix A,\r\nthat imposes monotonicity constraints on the lattice layer with parameter \u03b8LN\r\nLat, is explained in detail by Eq. (15) because the calibration\r\nlayers with parameter \u03b8LN\r\nINCal or \u03b8LN\r\nOUTCal are equivalent to the one-dimensional lattice.\r\nFor example, in Fig. 4, to guarantee the monotonic increase in L( \u22c5 ) relative to XIN\r\non[1] and XIN\r\non[2], the following seven inequalities\r\nshould be satisfied (see Gupta et al. 2016):\r\n\u2022 \u03b8LN\r\nLat,1,1 \u2264 \u03b8LN\r\nLat,2,1, \u03b8LN\r\nLat,2,1 \u2264 \u03b8LN\r\nLat,3,1, \u03b8LN\r\nLat,1,2 \u2264 \u03b8LN\r\nLat,2,2, \u03b8LN\r\nLat,2,2 \u2264 \u03b8LN\r\nLat,3,2 for XIN\r\non[1]-axis (4 inequalities)\r\n\u2022 \u03b8LN\r\nLat,1,1 \u2264 \u03b8LN\r\nLat,1,2, \u03b8LN\r\nLat,2,1 \u2264 \u03b8LN\r\nLat,2,2, \u03b8LN\r\nLat,3,1 \u2264 \u03b8LN\r\nLat,3,2 for XIN\r\non[2]-axis (3 inequalities)\r\nSeven rows in Eq. (15) correspond to these seven inequalities. The number of inequalities is the number of edges related to the\r\nconstrained attributes in the hypercube (e.g., 2-dimensional hypercube in Fig. 4). If we want to impose the monotonicity constraint\r\nonly on XIN\r\non[1]-axis (i.e., partial monotonicity), we can ignore the inequalities related to the XIN\r\non[2]-axis.\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n14\r\nA\u03b8LN\r\nLat =\r\n\u239b\r\n\u239c\u239c\u239c\u239c\u239c\u239c\u239c\u239c\u239d\r\n1 \u2212 1 0 0 0 0\r\n0 0 1 \u2212 1 0 0\r\n0 0 0 0 1 \u2212 1\r\n1 0 \u2212 1 0 0 0\r\n0 0 1 0 \u2212 1 0\r\n0 1 0 \u2212 1 0 0\r\n0 0 0 1 0 \u2212 1\r\n\u239e\r\n\u239f\u239f\u239f\u239f\u239f\u239f\u239f\u239f\u23a0\r\n\u239b\r\n\u239c\u239c\u239c\u239c\u239c\u239c\u239c\u239c\u239c\u239c\u239c\u239c\u239c\u239d\r\n\u03b8LN\r\nLat,1,1\r\n\u03b8LN\r\nLat,1,2\r\n\u03b8LN\r\nLat,2,1\r\n\u03b8LN\r\nLat,2,2\r\n\u03b8LN\r\nLat,3,1\r\n\u03b8LN\r\nLat,3,2\r\n\u239e\r\n\u239f\u239f\u239f\u239f\u239f\u239f\u239f\u239f\u239f\u239f\u239f\u239f\u239f\u23a0\r\n(15)\r\nWith the similar concept, we impose the monotonicity constraints on input and output calibration layers for all attributes. For\r\nexample, in Fig. 3a, to ensure that the calibrated travel cost increases related to travel cost, we impose the following inequality\r\nconditions on the parameters for the input calibrator: \u03b8LN\r\nINCal,2 \u2264 \u03b8LN\r\nINCal,4, \u03b8LN\r\nINCal,4 \u2264 \u03b8LN\r\nINCal,6, \u2026, \u03b8LN\r\nINCal,8 \u2264 \u03b8LN\r\nINCal,10. The output calibration\r\nlayer imposes monotonicity constraints using the same process. Since we consistently impose the monotonicity constraints on a specific\r\nattribute from input calibration layer, lattice layer, to output calibration layer, the final systematic utility function is monotonic\r\nrelative to the attribute. If we do not want to impose monotonicity on any attribute, we exclude the inequalities related to that attribute\r\nin all layers.\r\nWe adopt efficient optimization strategies (Gupta et al., 2016), such as parallel computation, suboptimal projections of inequality\r\nconstraints, and alternate updating of the parameters of lattice and calibration layers with stochastic sub-gradient. The DCM-LN is\r\ntrained based on Eq. (14), which indicates a structural risk minimization with inequality conditions to incorporate partial monotonicity constraints. The batched stochastic gradients and ADAM optimizer are used to update the model parameters. In each\r\nmini-batch, sub-gradients are derived to update the parameter. When these sub-gradients update parameters, we apply projection on\r\nthe parameters to satisfy the monotonicity constraints. For the input and output calibrator, isotonic regression with total ordering is\r\nused for projection, which satisfy the B\u03b8LN\r\nINCal \u2264 0 and C\u03b8LN\r\nOUTCal \u2264 0. The isotonic regression fits input values to the values that are\r\nmonotonic and as close to the original values as possible. We solve it using a pool-adjacent-violator algorithm (Barlow et al., 1974)\r\nwhose complexity is linear in the number of changing points. For the lattice layer, isotonic regression with partial ordering is used for\r\nprojection, which requires additional linear inequality constraints as many as the number of edges of the hypercube (A\u03b8LN\r\nLat \u2264 0). These\r\nisotonic regression problems are jointly solved for the input calibration layer, lattice layer, and output calibration layer using Eq. (14).\r\nThe consensus-based optimization and alternating direction method of multipliers are used for solving these projection problems with\r\nparallel computation (You et al., 2017).\r\n3.4. Bayesian optimization for hyperparameter calibration\r\nThe proposed DCM-LN requires tuning numerous hyperparameters. We need to determine the number of change points in the input\r\ncalibration layer for each alternative-specific attributes across alternatives and individual-specific attributes, the number of change\r\npoints in the output calibration layer for each alternative, weights for regularizers, and lattice size for each attribute. The simplest way\r\nfor hyperparameter tuning is a grid search technique, i.e., considering all combinations of hyperparameters; however, it is infeasible to\r\nenumerate all hyperparameters due to the curse-of-dimensionality. To efficiently tune these high-dimensional hyperparameters, this\r\nstudy applies Bayesian optimization (BO). We provide the details on BO applied in this study in Appendix A.\r\n3.5. Partial dependence (PD) and individual conditional expectation (ICE)\r\nThe DCM-DNN tends to fit the data with an overly complex model considering excessive interactions between attributes. The\r\nmonotonicity constraints rather act as regularization to control such excessive interactions of data-driven DCM, leading to improvements in both interpretability and recovery of the underlying true utility function (i.e., identification of attribute-specific effect\r\non the utility). To evaluate these aspects, we need to estimate the individual-level utility function of each attribute.\r\nVarious post hoc analysis tools have emerged to explain the attribute-specific effect (i.e., utility function) of machine learning\r\nmodels, such as partial dependence (PD) (Friedman, 2001), individual conditional expectation (ICE) (Goldstein et al., 2015), local\r\ninterpretable model-agnostic explanations (LIME) (Ribeiro et al., 2016), and Shapley additive explanations (SHAP) (Lundberg et al.,\r\n2017). We adopt PD and ICE to estimate the attribute-specific utility function at population level and individual level, respectively.\r\nSpecifically, we estimate the PD of dth attribute on the utility of alternative o, PDo[d] and the ICE of dth attribute of individual n on the\r\nutility of alternative o, ICEon[d]. The PDo[d] is computed as follows:\r\nPDo[d] = 1\r\nN\r\n\u2211N\r\nn=1\r\nFo(Xon[d],Xon[\u2212 d]), (16)\r\nwhere Xon[d] is the target attribute to estimate the PD and Xon[ \u2212 d] are the remaining attributes in the utility function Fo. The effect of\r\nXon[d] on the Fo is calculated by marginalizing the Fo over the distribution of the other remaining attributes Xon[ \u2212 d] using Monte\r\nCarlo method. The ICE is individual-level PD, which is ICEon[d] = Fo(Xon[d],Xon[ \u2212 d]). In other words, the aggregated ICE indicates the\r\nPD (Goldstein et al., 2015). In the following section, we verify that the PD and ICE well estimate the true utility function of the\r\nsimulation data.\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n15\r\n4. Monte Carlo study\r\nWe conduct a Monte Carlo study to evaluate the interpretability and predictability of DCM-LN. Regarding interpretability, we\r\ncompare the DCM-LN\u2019s willingness-to-pay (WTP) estimates for alternative-specific attributes at a disaggregated level with those of the\r\ntrue data-generating process (DGP). We use the in-sample and out-of-sample choice prediction accuracy and Brier score as the predictability metrics. The DGP of the utility function in the Monte Carlo study is complex enough to include earlier-discussed commonly\r\nencountered behavioral mechanisms: (i) interactions between alternative-specific and individual-specific attributes (i.e., systematic\r\nindividual taste heterogeneity); (ii) interactions between multiple alternative-specific attributes; (iii) interactions between individualspecific attributes; and (iv) inherent non-linear effect of alternative-specific attributes. More details of the considered DGPs, evaluation\r\nmetrics, benchmarked models, hyperparameter tuning, and the results of the simulation study are provided in the upcoming sections.\r\n4.1. Data generating process\r\n4.1.1. DGP-New: interactions and non-linearity of alternative-specific attributes\r\nThe DGP-Base follows Han et al. (2022) to represent the systematic taste heterogeneity in the synthetic binary mode choice between train and metro. In the DGP-Base, the three individual attributes \u2013 income (IN), full-time job (FUL), and flexible commuting\r\n(FLX) create systematic taste heterogeneity for the effects of two alternative-specific attributes \u2013 travel time (TT) and waiting time\r\n(WT). The IN is a numeric variable, while the FUL and FLX are dummy variables. Since we are interested in the WTP estimates for\r\nalternative-specific attributes (i.e., the value-of-travel time (VOT) and the value-of-walking time (VOWT)), we set the parameter of\r\ntravel cost (TC) as \u20131. We assume that the train and metro share the parameters for TT and WT. Eq. (17) denotes the systematic utility\r\n(Von) of individual n and alternative o (train or metro) in the DGP-Base.\r\nFig. 5. Attribute-specific true utility functions of DGP represented by PD and ICE.\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n16\r\nVon = \u2212 0.1 \u2212 TCon+\r\n( \u2212 0.1 \u2212 0.5 \u00d7 INn \u2212 0.1 \u00d7 FULn + 0.05 \u00d7 FLXn\r\n\u2212 0.2 \u00d7 INn \u00d7 FULn + 0.05 \u00d7 INn \u00d7 FLXn + 0.1 \u00d7 FULn \u00d7 FLXn\r\n)\r\n\u00d7 TTon+\r\n( \u2212 0.2 \u2212 0.8 \u00d7 INn \u2212 0.3 \u00d7 FULn + 0.1 \u00d7 FLXn\r\n\u2212 0.3 \u00d7 INn \u00d7 FULn + 0.08 \u00d7 INn \u00d7 FLXn + 0.3 \u00d7 FULn \u00d7 FLXn\r\n)\r\n\u00d7 WTon\r\n(17)\r\nThe interaction terms in the parenthesis represent the systematic taste heterogeneity caused by the combined effects of individual\r\nattributes.\r\nThe interaction and inherent non-linearity of alternative-specific attributes are well-known behavioral mechanisms that are\r\nignored by DCM-Linear and the previous DCM-DNN relying on MNL (Han et al., 2022; Sifringer et al., 2020). To evaluate these aspects,\r\nwe define a DGP-New that modifies the DGP-Base as follows: (i) the crowding (CR) and its interaction with TT are added to the\r\ndeterministic utility; (ii) inherent non-linear utility (i.e., diminishing marginal utility) of TC replaces the linear utility of TC. Eq. (18)\r\ndenotes the systematic utility of DGP-New.\r\nVon = \u2212 0.1 \u2212 8 \u22c5 \u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305 TCon \u221a \u2212 2.0 \u00d7 CRon+\r\n( \u2212 0.02 \u00d7 CRon \u2212 0.1 \u2212 0.5 \u00d7 INn \u2212 0.1 \u00d7 FULn + 0.05 \u00d7 FLXn\r\n\u2212 0.2 \u00d7 INn \u00d7 FULn + 0.05 \u00d7 INn \u00d7 FLXn + 0.1 \u00d7 FULn \u00d7 FLXn\r\n)\r\n\u00d7 TTon+\r\n( \u2212 0.2 \u2212 0.8 \u00d7 INn \u2212 0.3 \u00d7 FULn + 0.1 \u00d7 FLXn\r\n\u2212 0.3 \u00d7 INn \u00d7 FULn + 0.08 \u00d7 INn \u00d7 FLXn + 0.3 \u00d7 FULn \u00d7 FLXn\r\n)\r\n\u00d7 WTon\r\n(18)\r\n4.1.2. Sampling from the DGP\r\nWe describe the sampling distribution of each attribute in DGP-Base and DGP-New in Appendix B. Based on the assumed distribution, we calculate the utility derived by an individual for each alternative using the DGP and assign the alternative with the highest\r\nutility as the chosen alternative by the individual. For each trial, 10,000 individuals are generated from DGP. 70 % of the generated\r\ndata are used for training, 15 % of the data for validation, and 15 % of the data for testing. Since the DGP generates slightly different\r\ndatasets due to random error term and uncertainty in attributes, we conduct analysis for 50 different synthetic datasets. Fig. 5 illustrates the utility functions of alternative-specific attributes in the DGP-New. The PD and ICE, by definition, represent the\r\npopulation-level and individual-level utility functions, respectively. Variations in individual-level utility (i.e., ICE \u2013 thin grey lines) of\r\nTT and WT indicate the individual taste heterogeneity explained by combined effects of individual-level attributes. Also, it represents\r\nthe inherent non-linear utility function of TC. The two-way PD at the bottom right of Fig. 5 shows the interactions among the TT and\r\nCR.\r\n4.2. Benchmarked models and evaluation metrics\r\nDCM-DNN and DCM-Linear models are considered as benchmark models while evaluating the recovery of WTP and predictive\r\nperformance. The DCM-Linear in this section considers the true first-order interactions between the alternative-specific and individualspecific attributes (e.g., FLXn \u00d7 TTon, FULn \u00d7 TTon) while ignoring second-order interactions (e.g., FULn \u00d7 FLXn \u00d7 TTon) because\r\nhandcrafted utility functions rarely consider such high-order interactions. Also, the DCM-Linear does not consider interactions between alternative-specific attributes (e.g., TTon \u00d7 CRon) and inherent non-linearity (e.g., 8 \u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305 TCon \u221a ). For the DCM-DNN and DCM-LN\r\nestimation, we do not provide any information related to the true DGP and input all the individual- and alternative-specific attributes. The DCM-LN only uses the prior knowledge in which the utility values at individual and population levels monotonically\r\ndecrease with the increase in TT, WT, CR, and TC.\r\nTo evaluate the interpretability, we compare the taste heterogeneity in WTP for alternative-specific attributes obtained from 50\r\nsynthetic datasets, which provide the most critical behavioral interpretation in transportation planning. Specifically, we define 40\r\n(=10 \u00d7 2 \u00d7 2) demographic groups based on three individual-specific attributes: IN (10 levels), FUL (2 levels), and FLX (2 levels), and\r\ncompare the true and estimated VOT and VOWT for these groups. VOT and VOWT could be easily computed through the ratio of the\r\nestimated coefficients in MNL. In DCM-DNN and DCM-LN, VOT and VOWT are calculated by aggregating ICE based on attribute levels\r\ncorresponding to each group, where the median value is used for aggregation. After examining the distribution of estimated VOT and\r\nVOWT at five quantile values: 1 %, 25 %, 50 % (median), 75 %, and 99 %, the accuracy of the estimated VOT and VOWT for 40\r\ndemographic groups is evaluated by comparing the root mean squared error (RMSE) and mean absolute percentage error (MAPE). To\r\nevaluate the predictability, we compare choice prediction accuracy and Brier score. Appendix C provides the formula and interpretation for these evaluation metrics.\r\n4.3. Hyperparameter tuning\r\nHyperparameter tuning is closely related to the model performance since it affects the quality of the training process. It is\r\nparticularly critical for the proposed DCM-LN because the attribute-specific hyperparameters in DCM-LN are generally more than the\r\nhyperparameters in DCM-DNN. As discussed earlier, we apply the Bayesian optimization approach that estimates the relationship\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n17\r\nbetween the set of hyperparameters and model performance to reduce the search space.\r\nAppendix D summarizes search space of hyperparameters for DCM-LN and DCM-DNN, training conditions (e.g., learning rate, the\r\nnumber of epochs, stopping criteria) and the tuned hyperparameters. We tune four hyperparameters of DCM-DNN: the number of\r\nlayers (i.e., layer depth), the number of neurons in each layer (i.e., layer width), the learning rate, and the dropout rate after each layer.\r\nFor DCM-LN, we tune the number of change points for each attribute in the input calibration layer, lattice size for all attributes, and the\r\nnumber of change points for the output calibration layer.\r\n4.4. Evaluation results for DGP-New\r\nWe evaluate the proposed DCM-LN for DGP-Base and DGP-New. An in-depth analysis of evaluation results for DGP-Base is provided\r\nin Appendix E, which discusses several insightful patterns and implications. In summary, DCM-LN outperforms the DCM-Linear\r\nregarding both interpretability and predictability. DCM-LN also outperforms DCM-DNN in terms of interpretability, but DCM-DNN\r\nhas a slight edge over DCM-LN in terms of predictive accuracy. Table 3 summarizes the evaluation results for interpretability and\r\npredictability for DGP-New. The DGP-New is more complex than DGP-Base because it additionally includes the inherent non-linear\r\neffect of TC and the interaction effect between two alternative-specific attributes (TT and CR). The nonlinearity in the marginal\r\nutility of TC also increases the difficulty in recovering the true VOT and VOWT distributions.\r\nThe evaluation results for DGP-New in Table 3 provide four noteworthy findings. First, the predictive performance of DCM-Linear\r\nis much lower than that of DCM-DNN and DCM-LN. The interpretability of DCM-linear also reduces significantly, indicating how the\r\nmisspecification of the utility function is more likely to occur in the case of complex DGPs and how it dramatically reduces the predictive performance and the trustworthiness of traditional DCMs with hand-crafted utility specifications. Second, DCM-DNN shows\r\nthe best predictability and the worst interpretability, indicating that the trade-off relationship still holds for more complex functions.\r\nThe interpretability of DCM-DNN remains much worse than that of DCM-Linear. These results imply that the overly complex function\r\nfitted by DCM-DNN cannot provide trustworthy behavioral information about the true DGP regardless of its complexity. Third, DCMLN highly outperforms DCM-Linear and DCM-DNN in terms of interpretability, i.e., it shows the best performance for all quantiles and\r\ndemographic group-level WTP estimates. The capability to approximate the non-linear function of TC could be a reason behind the\r\ndistinct interpretability of DCM-LN. In terms of predictive performance, the DCM-LN also highly outperforms the DCM-Linear while\r\nslightly underperforming the DCM-DNN. Considering the balanced performance based on interpretability and predictability, the DCMLN is the best model for DGP-New. Forth, unlike DCM-LN, DCM-Linear and DCM-DNN estimate the negative VOT and VOWT for some\r\nindividuals (see 1 % quantiles). This result suggests that the monotonicity constraints successfully regularize the DCM-LN toward the\r\ntrue DGP and make its WTP estimates trustworthy.\r\nWhile Figs. 6 and 7 support the findings derived from Table 3 and are consistent with those obtained for DGP-Base, they also reveal\r\nadditional insightful patterns. First, Fig. 7 shows that DCM-LN approximates the non-linear effect of TC much better than DCM-DNN at\r\nboth population and individual levels, resulting in much better recovery of WTP distribution. The estimated utility of TC by DCM-DNN\r\nhas a serious concern as it provides positive marginal utility at some levels of TC, leading to negative WTP estimates. In contrast, DCMLN prevents such misidentifications through theory-driven monotonicity constraints. Second, even though the DCM-Linear\u2019s estimated utility functions are far from the true DGP (as shown in Fig. 7), the estimated distribution patterns of VOT and VOWT are fairly\r\nclose to those of DCM-LN, as shown in Fig. 6. This result supports our old belief in the interpretability of DCM-Linear.\r\nTable 3\r\nInterpretability and predictability evaluation in DGP-New.\r\nParameter True DCM-Linear\r\n(50 trials)\r\nDCM-DNN\r\n(50 trials)\r\nDCM-LN\r\n(50 trials)\r\nMean Std. Mean Std. Mean Std. Mean Std.\r\nInterpretability: recovery of distribution VOT (Median) 0.284 0.014 0.126 0.019 0.075 0.105 0.188 0.080\r\nVOT (1 %) 0.142 0.010 \u2212 0.026 0.029 \u2212 0.012 0.281 0.093 0.063\r\nVOT (25 %) 0.216 0.013 0.066 0.021 0.040 0.085 0.135 0.072\r\nVOT (75 %) 0.404 0.024 0.200 0.013 0.123 0.172 0.257 0.089\r\nVOT (99 %) 0.675 0.027 0.372 0.024 0.222 0.214 0.456 0.105\r\nVOWT (Median) 0.480 0.019 0.258 0.148 0.146 0.210 0.322 0.134\r\nVOWT (1 %) 0.252 0.011 \u2212 0.068 0.124 \u2212 0.114 0.797 0.153 0.082\r\nVOWT (25 %) 0.372 0.017 0.118 0.141 0.086 0.159 0.244 0.127\r\nVOWT (75 %) 0.779 0.033 0.414 0.175 0.233 0.273 0.472 0.181\r\nVOWT (99 %) 1.236 0.049 0.719 0.288 0.402 0.560 0.892 0.263\r\nInterpretability: recovery of demographic groups\u2019 value VOT (MAPE) 0.630 0.044 0.802 0.329 0.351 0.103\r\nVOT (RMSE) 0.193 0.012 0.272 0.102 0.129 0.030\r\nVOWT (MAPE) 0.598 0.195 0.846 0.459 0.359 0.112\r\nVOWT (RMSE) 0.348 0.092 0.546 0.259 0.243 0.063\r\nPredictability: chosen alternative and probabilities Training accuracy 0.552 0.006 0.775 0.010 0.741 0.018\r\nTest accuracy 0.546 0.013 0.716 0.014 0.697 0.016\r\nTraining Brier score 0.491 0.002 0.311 0.012 0.349 0.020\r\nTest Brier score 0.493 0.003 0.371 0.014 0.395 0.015\r\nNote: Std. indicates the standard deviation from different datasets generated; The bold indicates the best performance among the benchmark models.\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n18\r\n5. Empirical application\r\nWe use the Swissmetro dataset (Bierlaire, 2018), an open source stated preference data that collect the preferences of 1192 respondents for a train (TR), Swiss metro (SM), and car (CAR) in 9 choice situations. The attribute levels of the choice experiment are\r\nsummarized in Table 4 (Bierlaire et al., 2001). We exclude individuals with unknown age, income, or purpose. The final sample includes 939 respondents who face 8451 choice situations. The travel cost for TR and SM modes is set to zero for respondents with an\r\nannual season pass. We split the data into 70 % training, 15 % validation, and 15 % test samples.\r\n5.1. Specifications of DCM-Linear, DCM-DNN, and DCM-LN models\r\nWe estimate three DCM-Linear models \u2013 DCM-Linear-A, DCM-Linear-B, and DCM-Linear-C. The DCM-Linear-A only includes\r\nalternative-specific attributes, while the DCM-Linear-B additionally considers first-order interactions between travel time and individual attributes. Referring to the model specification of Bierlaire et al. (2001) and Han et al. (2022), we find the best specification for\r\nDCM-Linear-A and Linear-B, which has a good predictive performance and statistically significant interaction effects at the 10 %\r\nsignificance level at least for one alternative. The DCM-Linear-C represents the utility specification optimized by an automatic (or\r\nassisted) specification in Ortelli et al. (2021). It considers first-order interaction between travel time, travel cost, and individual attributes. Also, non-linear effects of travel time and headway are considered by log and square root transformation, respectively. The\r\noptimized utility function was selected among 4.6 \u00d7 108 distinct specifications based on the out-of-sample log-likelihood.The\r\nparameter estimates of DCM-Linear-A, DCM-Linear-B, and DCM-Linear-C are presented in Tables A.5\u2013A.7 in Appendix F. We design\r\nthe architecture of DCM-LN (Fig. 2a) and DCM-DNN (Fig. 2b) based on the alternative-specific utility specification. Table A.8 in\r\nAppendix G summarizes the search space for hyperparameters, training conditions, and the tuned hyperparameters for DCM-LN and\r\nDCM-DNN for the Swissmetro dataset. Since the DCM-LN requires only one-twentieth of the model parameters of DCM-DNN, the\r\nregularization effects would be much more pronounced in the Swissmetro dataset than those in the DGP-Base and DGP-New.\r\n5.2. Evaluation results for the Swissmetro dataset\r\nWe use similar measures of predictability and interpretability as those of the Monte Carlo study. To evaluate taste heterogeneity in\r\nWTP estimates, we define 60 demographic groups based on three individual-specific attributes \u2013 five categories for age, three categories for income, and four categories for purpose. We also compare five quantile values of the WTP distribution.\r\nUnlike the Monte Carlo study, the true values of parameters (i.e., true VOT) remain unknown in the empirical data. We will use the\r\nFig. 6. VOT and VOWT estimates for 40 demographic groups in DGP-New.\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n19\r\nfollowing facts based on theory-driven intuition and results of the previous empirical studies in the Swiss context for model benchmarking (Axhausen et al., 2007, 2004): (i) the VOT in the car is larger than VOT in the railway; (ii) VOT cannot be negative for any\r\nsocio-demographic group. In light of these facts, we discuss the causes and implications of the discrepancy between VOT estimates of\r\ndifferent DCM-Linear specifications, DCM-DNN, and DCM-LN.\r\nTable 5 summarizes the estimated quantiles of the VOT distribution for all models. We observe two insightful trends. First, DCMLinear-A, DCM-Linear-B, DCM-Linear-C and DCM-LN estimate similar levels of VOT, while the estimated VOTs of DCM-DNN are much\r\nlower than those of DCM-LN and DCM-Linear across all quantiles and alternatives. In contrast, the DCM-DNN shows the best predictability for all metrics. These results further verify the insights of the simulation study that the DCM-DNN does not ensure interpretability while optimizing the loss function to maximize the predictability. Second, DCM-Linear-B\u2019s VOT estimates have two biases:\r\n(i) negative VOT for some demographic groups (see 1 % quantile) and (ii) higher VOT in the train than in the car. DCM-Linear-C\r\ncorrects both biases of DCM-Linear-B but exacerbates another bias of VOT overestimation for a large proportion of the population.\r\nThe one-percentile of the estimated VOT distribution (i.e., 1.759) by DCM-Linear-C is higher than the median VOT (i.e., 1.435) estimate of DCM-Linear-B for Swissmetro. This result implies that the estimated VOT is sensitive to the model specification of DCMLinear, and the optimal model with the best model fit may not guarantee the best estimation of the true VOT. DCM-LN corrects all\r\nbiases of DCM-Linear-B and DCM-Linear-C, highlighting the strength of DCM-LN to enhance the trustworthiness of behavioral\r\nFig. 7. Attribute-specific utility functions estimated by (a) DCM-Linear, (b) DCM-DNN, (c) DCM-LN in DGP-New at the individual and population\r\nlevel, and d) overlapping population-level utility functions.\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n20\r\ninterpretations. This result underlies our argument that the DCM-LN better approximates true VOT than the DCM-Linear by capturing\r\nthe complex high-order interaction and non-linear effects, which are not captured by DCM-Linear. Importantly, such improved\r\ninterpretability comes with DCM-LN\u2019s improved predictability over the DCM-Linear, thanks to the flexible utility specification with\r\nregularization generated by monotonicity constraints.\r\nWe delve deeper into insights from Table 5 by plotting VOT estimates for 60 demographic groups (in ascending order of DCMLinear-B\u2019s estimates \u2013 black solid line) in Fig. 8 and plotting PD and ICE estimates in Fig. 9. Among the three DCM-Linear, we adopt the\r\nDCM-Linear-B for the comparison since it shows the highest predictability and a reasonable range of VOT estimates.\r\nTwo meaningful patterns from Figs. 8 and 9 are summarized as follows. First, DCM-DNN in Fig. 8 consistently underestimates the\r\nVOT for all three alternatives, and their trend seems to be incoherent with the trend of DCM-Linear. This pattern reconfirms our\r\nhypothesis that DNN\u2019s capability to maximize the data-fitting does not relate to the behavioral relationships between individual- and\r\nalternative-specific attributes. Fig. 9 provides clear evidence for this pattern in which several individuals have a positive marginal\r\nutility of travel time and cost for each alternative. These negative values of VOTs cause the underestimation of group specific VOTs.\r\nDespite the highly heterogenous individual-level utility, the PD of DCM-DNN (i.e., population-level utility) is not very different from\r\nthose of DCM-Linear and DCM-LN. This result suggests that even if DCM-DNN can provide some useful economic information at the\r\npopulation level, it still cannot be applied to individual-level behavioral modeling. Second, Fig. 9 shows that DCM-LN could successfully impose monotonicity constraints on the utility of travel time and travel cost. It is promising that the DCM-LN could capture\r\nthe diminishing marginal utility of travel cost, a well-known behavioral pattern (Daly et al., 2017; Rich and Mabit, 2016), while the\r\nutility functions estimated by DCM-DNN do not adhere to economic theory. These results imply that the monotonicity constraints in\r\nthe DCM-LN help the model approximate the true utility function, without just focusing on enhancing the predictive performance.\r\nTable 4\r\nDescriptive statistics of the Swiss metro datasets.\r\nAlternative Alternative attributes\r\nTrain (TR) Intercept; Travel time; Travel cost; Headway;\r\nSwiss Metro (SM) Intercept; Travel time; Travel cost; Headway; Airline seats\r\nCar (CAR) (reference) Travel time; Travel cost\r\nIndividual\r\nattributes\r\nAttribute levels\r\nAnnual pass 0: No, 1: Yes\r\nAge 1: age \u2264 24 (reference), 2: 24 < age \u2264 39, 3: 39 < age \u2264 54, 4: 54 < age \u2264 65, 5: 65 < age\r\nIncome 1: under 50 (reference), 2: between 50 and 100, 3: over 100\r\n* Traveler\u2019s income per year [thousand CHF]\r\nPurpose 1: Commuter or return from work (reference), 2: Shopping or return from shopping,\r\n3: Business or return from business, 4: Leisure or return from leisure\r\nNote: Airline seats indicate seat configuration in the Swissmetro (dummy attributes).\r\nTable 5\r\nInterpretability and predictability evaluation for Swissmetro dataset.\r\nParameter DCM-LinearA\r\nDCM-LinearB\r\nDCM-LinearC\r\nDCM-DNN (50\r\ntrials)\r\nDCM-LN (50\r\ntrials)\r\nMean Mean Mean Mean Std. Mean Std.\r\nInterpretability: estimated distribution Train VOT\r\n(Median)\r\n2.423 1.931 2.249 0.585 0.192 1.321 0.492\r\nVOT (1 %) \u2212 0.079 1.537 0.187 0.093 0.214 0.197\r\nVOT (25 %) 1.041 1.852 0.475 0.102 0.892 0.274\r\nVOT (75 %) 2.565 2.921 0.696 0.233 2.066 0.686\r\nVOT (99 %) 3.340 5.696 0.931 0.272 5.703 2.643\r\nSwiss VOT\r\n(Median)\r\n1.951 1.435 3.054 0.507 0.101 1.039 0.385\r\nmetro VOT (1 %) \u2212 1.088 1.759 \u2212 0.189 0.51 0.251 0.22\r\nVOT (25 %) 0.730 2.506 0.312 0.162 0.706 0.377\r\nVOT (75 %) 2.135 4.467 0.664 0.141 1.778 0.661\r\nVOT (99 %) 2.838 9.249 1.252 0.341 4.76 1.653\r\nCar VOT\r\n(Median)\r\n1.529 1.512 2.790 0.33 0.295 1.450 0.29\r\nVOT (1 %) \u2212 0.165 1.160 \u2212 0.335 0.232 0.318 0.255\r\nVOT (25 %) 0.960 2.221 0.11 0.106 0.931 0.29\r\nVOT (75 %) 2.050 4.259 0.607 0.33 2.191 0.463\r\nVOT (99 %) 3.053 9.175 1.046 0.417 5.918 3.126\r\nPredictability: chosen alternative and\r\nprobabilities\r\nTraining accuracy 0.675 0.689 0.673 0.752 0.008 0.716 0.005\r\nTest accuracy 0.657 0.688 0.651 0.719 0.005 0.705 0.01\r\nTraining Brier score 0.453 0.432 0.448 0.344 0.011 0.391 0.005\r\nTest Brier score 0.464 0.447 0.459 0.387 0.003 0.415 0.007\r\nNote: Std. indicates the standard deviation from different datasets generated; The bold indicates the best performance among the benchmark models.\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n21\r\nAppendix H compares the computational efficiency of DCM-DNN and DCM-LN to evaluate the scalability. The main result indicates\r\nthat although the DCM-LN is slightly computationally expensive than DCM-DNN as the lattice size increases, its computational expense\r\nis still reasonable. For instance, the DCM-LN only takes one minute to train the model for the Swissmetro dataset, which has the same\r\norder of observations and attributes as of generally encountered SP choice datasets.\r\n6. Conclusion\r\nWhile marrying emerging data-driven learning approaches with traditional econometric models is a need of this hour, flexibilitydriven predictability gains should not come at the expense of violating theory-driven constraints and losing domain-specific interpretability. To this end, this study proposes a flexible and partially monotonic discrete choice model (DCM), which ensures the\r\nmonotonicity of the utility relative to a subset of alternative-specific attributes while learning non-linear and interaction effects of\r\nattributes in a data-driven manner. The proposed DCM specifies the systematic utility using the lattice networks (LNs) (i.e., DCM-LN,\r\nhenceforth). DCM-LN estimates the attribute-specific non-linear effects as piecewise linear functions and considers their interactions\r\nusing multilinear interpolation. Relatively fewer inequality constraints to ensure partial monotonicity and an automated process to\r\nwrite these constraints in DCM-LN make it scalable and translatable to practice. The proposed LN-based approach has broad appeal to\r\napplied economics because monotonicity is the most intuitive and incontrovertible constraint in economic-related domains (e.g.,\r\nmonotonically decreasing utility relative to cost).\r\nWe benchmark the DCM-LN against DCM-DNN (i.e., DCM with deep neural network-based systematic utility) and a DCM-Linear (i.\r\nFig. 8. VOT estimates for three alternatives for 60 demographic groups in the Swissmetro dataset.\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n22\r\nFig. 9. Attribute-specific utility functions estimated by DCM-Linear, DCM-DNN, and DCM-LN in Swissmetro dataset at the individual and population level: (a) travel time for the train, (b) travel cost for the train, (c) travel time for the Swiss metro, (d) travel cost for the Swiss metro, (e) travel\r\ntime for the car, (f) travel cost for the car.\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n23\r\ne., multinomial logit model with linear additive utility specification considering the first-order interactions) in a Monte Carlo study.\r\nThe results show that DCM-LN highly outperforms both models in terms of interpretability, i.e., recovering willingness to pay at individual and population levels. The visualization of the estimated and true utility functions shows that the DCM-LN outperforms\r\nconsidered models in capturing the underlying non-linear and interaction effects (i.e., taste heterogeneity) of attributes at individual\r\nand population levels while circumventing the main shortcoming of DCM-DNN \u2013 unreasonable or abrupt changes in the utility\r\nfunction, thus avoiding unexpected signs of marginal utility. DCM-LN is slightly outperformed by DCM-DNN in predictability, which is\r\nnot surprising because DCM-LN reduces the parameter search space by imposing monotonicity constraints. This balanced performance\r\nof DCM-LN is quite promising because it approximates the true utility function during the training rather than learning arbitrary utility\r\nfunctions to maximize the predictability as DCM-DNN does. We further validate the proposed DCM-LN in an empirical study. The\r\nresults suggest that DCM-LN provides trustworthy behavioral interpretations compared to DCM-DNN and DCM-Linear. For instance,\r\nwhile DCM-linear and DCM-DNN estimate negative willingness to pay to save travel time in travel mode choice for some demographic\r\ngroups, such unreasonable results are not produced by DCM-LN. In summary, if predictability is the only important factor, then DCMDNN should be preferred. All other policy-relevant scenarios, where recovery of underlying elasticity and willingness to pay distributions is critical, should choose DCM-LN over DCM-DNN and DCM-Linear.\r\nWhile the interest in data-driven DCMs has been exponentially growing with the hope of improving predictability and avoiding the\r\nmisspecification arising from hand-crafting the utility function in theory-driven DCMs, the literature also agrees that existing datadriven DCMs improve predictability but do not provide trustworthy behavioral interpretations. There have been discussions about\r\nachieving interpretability through domain-knowledge-based regularizations in the flexible models (Han et al., 2022; Kim and Bansal,\r\n2023; Sifringer et al., 2020; Wang et al., 2020a), but this is the first study to demonstrate how such regularizations can be applied\r\nthrough constraints in the standard risk minimization framework without losing much of flexibility. This lattice-network-based\r\nframework opens three avenues for future research. First, in addition to hard monotonicity constraints, soft constraints of other\r\nbehavioral theories could be incorporated into the DCM-LN through penalties in the training procedure. Specifically, since DCM-LN\r\ncaptures the attribute-specific non-linear effect as segmented/piece-wise effects, behavioral mechanisms, such as\r\nsemi-compensatory decision rule (e.g., attribute cut-off) (Swait, 2001) and asymmetric marginal utility (e.g., prospect theory) (Van de\r\nKaa, 2010) could be modeled using DCM-LN. Second, the interpretable DCM-LN architecture could be extended to more complex\r\nmodeling objectives. For example, the DCM-LN can be formulated to jointly estimate hierarchical multiple-choice dimensions such as\r\nactivity destination, type, duration, and travel mode in activity-based travel demand models (Castiglione et al., 2014; Kim et al., 2022;\r\nMiller, 2023). The domain knowledge for behavioral mechanisms within/across choice dimensions can reveal the underlying complex\r\ndecision-making process of activity scheduling and inform the necessary constraints. Such models could improve the feasibility and\r\ngeneralizability of generated activity chains by maintaining theory-driven constraints. Third, the individual-level monotonicity is the\r\nmost intuitive and uncontroversial behavioral constraint that is likely to be valid for all decision-makers, and enforcing such constraints in a data-driven manner can help develop a model that approximates the underlying causal relationships, ensuring interpretability rather than fitting the training data to maximize the predictability. However, validating a structural causal model is\r\ninfeasible due to the inability to handle unobserved confounders (i.e., the attribute is correlated with an error term representing the\r\nunobserved data) (Brathwaite and Walker, 2018). Combining DCM-LN with the control function approach could be a potential way\r\nforward to develop a causal DCM.\r\nCRediT authorship contribution statement\r\nEui-Jin Kim: Conceptualization, Data curation, Formal analysis, Software, Writing \u2013 original draft, Methodology. Prateek Bansal:\r\nConceptualization, Funding acquisition, Methodology, Writing \u2013 original draft.\r\nData availability\r\nData will be made available on request.\r\nAcknowledgements\r\nPrateek Bansal acknowledges support from the Presidential Young Professorship Grant, National University of Singapore. This\r\nresearch was conducted at the Future Cities Lab Global at Singapore-ETH Centre. Future Cities Lab Global is supported and funded by\r\nthe National Research Foundation, Prime Minister\u2019s Office, Singapore under its Campus for Research Excellence and Technological\r\nEnterprise (CREATE) programme and ETH Zurich (ETHZ), with additional contributions from the National University of Singapore\r\n(NUS), Nanyang Technological University (NTU), Singapore and the Singapore University of Technology and Design (SUTD). Eui-Jin\r\nKim was supported by a National Research Foundation of Korea (NRF) grant funded by the Korean government (MSIT) (No.RS-2023-\r\n00246523) and by a Korea Agency for Infrastructure Technology Advancement (KAIA) grant funded by the Korean government\r\n(MOLIT) (No.RS-2022-001560).\r\nAppendix A. Bayesian Optimization (BO) for Hyperparameter Tuning of DCM-LN\r\nThe BO for hyperparameter tuning is implemented in four steps: (a) DCM-LN is initialized with a set of hyperparameters; (b) DCMLN is trained for these hyperparameters, and its validation accuracy is saved; (c) a probabilistic surrogate model (Gaussian process (GP)\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n24\r\nin this study) is fitted in which the independent variables are combinations of hyperparameters so far, and the dependent variable is a\r\ncorresponding validation accuracy for each combination of hyperparameters; (d) an acquisition function is maximized to determine\r\nthe next set of hyperparameters which could potentially improve the validation accuracy.\r\nThe GP estimates the relationship between a combination of hyperparameters and the validation accuracy, as denoted by Equation\r\n(A.1), where f is the validation accuracy that we target, C = (C1,\u2026, Ct) is the observed sets of hyperparameters in previous t iterations,\r\n\u03bc and K are mean and covariance of the GP, respectively.\r\nP(f |C) = GP(\r\nf ; \u03bcf |C, Kf |C\r\n)\r\n(A.1)\r\nGiven this GP, the acquisition function evaluates an expected accuracy at the next set of hyperparameters Ct + 1. This study uses the\r\nupper confidence bound acquisition function (Srinivas et al., 2010). The upper confidence bound is a weighted sum of the expected\r\naccuracy captured by the GP\u2019s mean \u03bc(C) and uncertainty captured by the GP\u2019s covariance K(C, C), as shown in Equation (A.2). We\r\nuse the generally recommended \u03b2 = 2.6 (O\u2019Malley et al., 2019). Readers are referred to (Shahriari et al., 2016) for more details on BO.\r\naUCB(C; \u03b2) = \u03bc(C) \u2212 \u03b2 \u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305 trace(K(C, C)) \u221a (A.2)\r\nAppendix B. Sampling Distribution of DGP-Base and DGP-New\r\nTable A.1 describes the sampling distribution of each attribute in DGP-Base and DGP-New. The FUL and FLX are sampled from the\r\nBernoulli distribution with p = 0.5, and the IN is sampled conditional on the FUL from a log-normal distribution. The TC, TT, and WT\r\nhave ranges of (0.2,100), (5100), and (5,30), respectively, and are sampled from the uniform distribution. We assume that the train is\r\nnot affected by crowding due to the reserved seat system; thus, only the CR of the metro is sampled from the uniform distribution,\r\nranging from \u2212 5 to 5.\r\nTable A.1\r\nDescription of input attributes in DGP-Base and DGP-New.\r\nDGP-Base DGP-New Meaning\r\nIndividual\r\nattributes\r\nIN LogNormal(log(0.5),0.25) for full-time;\r\nLogNormal(log(0.25),0.2) for not full-time\r\nLogNormal(log(0.5),0.25) for full-time;\r\nLogNormal(log(0.25),0.2) for not full-time\r\nHousehold income ($ per\r\nmin)\r\nFUL Bernoulli(0.5) Bernoulli(0.5) Full time worker (1=yes,\r\n0=no)\r\nFLX Bernoulli(0.5) Bernoulli(0.5) Flexible working hours\r\n(1=yes, 0=no)\r\nAlternative\r\nattributes\r\nTC Uniform(0.2,100) for train and metro Uniform(0.2,100) for train and metro Travel cost ($)\r\nTT Uniform(5,100) for train and metro Uniform(5,100) for train and metro Travel time (min)\r\nWT Uniform(5,30) for train and metro Uniform(5,30) for train and metro Waiting time (min)\r\nCR \u2013 Uniform(\u2212 5,5) for metro; 0 for train Degree of crowding\r\nNote: DGP-Base is the same as the one considered by Han et al. (2022).\r\nAppendix C. Formula and Interpretation for the Evaluation Metrics\r\nThe interpretability is evaluated by computing RMSE and MAPE, denoted by Eqs. (A.3) and (A.4), where the Vg and V\r\n\u0302g are the true\r\nand estimated VOT or VOWT for the demographic group g.\r\nRMSE =\r\n\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\r\n1\r\n40\r\n\u221140\r\ng=1\r\n(\r\nVg \u2212 \u0302Vg\r\n)2\r\n\u221a\u221a\u221a\u221a (A.3)\r\nMAPE = 100%\r\n40\r\n\u221140\r\ng=1\r\n\u20d2\r\n\u20d2\r\n\u20d2\r\n\u20d2\r\nVg \u2212 \u0302Vg\r\nVg\r\n\u20d2\r\n\u20d2\r\n\u20d2\r\n\u20d2\r\n(A.4)\r\nThe predictability is evaluated by accuracy and Brier score, denoted by Eqs. (A.5) and (A.6).\r\nAccuracy = 1\r\nN\r\n\u2211N\r\nn=1\r\n1Y\u02c6n=Yn (A.5)\r\nBrier Score = 1\r\nN\r\n\u2211N\r\nn=1\r\n\u2211\r\no\r\n(Pon \u2212 Yon)\r\n2 (A.6)\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n25\r\nwhere the 1( \u22c5 ) is an indicator function, which takes value 1 if the observed choice (Yn) is the same as the predicted choice (Y\r\n\u0302n ) for an\r\nindividual n; Pon is the estimated choice probability of the target alternative o for the nthindividual, and Yon is 1 if o is the chosen\r\nalternative and is 0 otherwise. While the accuracy measures how close the estimated choice is to the true one, the Brier score measures\r\nthe accuracy of the estimated choice probability vector. The accurate estimation of the choice probability vector is necessary for\r\ntransportation planning because it is applied in many practical applications, such as the prediction of modal share.\r\nAppendix D. Hyperparameter Tuning for DCM-DNN and DCM-LN in DGP-Base and DGP-New\r\nTable A.2 shows the search space for optimal hyperparameter tuning of DCM-LN and DCM-DNN for DGP-Base and DGP-New. The\r\nlarger lattice size is searched for the DGP-New due to its higher complexity than the DGP-Base. We consider the batch size and the\r\nnumber of epochs to be 128 and 200, respectively. We use the l2 norm for wrinkles and Hessian regularizers with weights of 0.5 and\r\n0.0001, respectively. To reduce the overfitting, we set the callback for early stopping, in which the training stops if the validation\r\naccuracy does not increase during 20 epochs.\r\nTable A.2\r\nSearch space for tuning optimal hyperparameters of DCM-LN and DCM-DNN for DGP-Base and DGP-New.\r\nDGP-Base DGP-New\r\nHyperparameter Search space Hyperparameter Search space\r\nDCM-DNN DCM-DNN\r\nLayer depth [1,2,3,4,5] Layer depth [1,2,3,4,5]\r\nLayer width [50,100,150 200,250,300] Layer width [50,100,150 200,250,300]\r\nDropout rate [0.005,0.05,0.1,0.2,0.3] Dropout rate [0.005,0.05,0.1,0.2,0.3]\r\nLearning rate [0.0005, 0.001, 0.005, 0.01] Learning rate [0.0005, 0.001, 0.005, 0.01]\r\nNumber of model parameters 11,001 Number of model parameters 93,301\r\nDCM-LN DCM-LN\r\nNumber of changing points Number of changing points\r\nTC [10,20,30,40] TC [10,20,30,40]\r\nTT [10,20,30,40] TT [0,20,30,40]\r\nWT [10,20,30,40] WT [10,20,30,40]\r\nCR \u2013 CR [10,20,30,40]\r\nINC [10,20,30,40] INC [10,20,30,40]\r\nOutput calibration [2,3,4,5] Output calibration [2,3,4,5]\r\nLattice size Lattice size\r\nASC [2,3,4,5] ASC [2,3,4,5]\r\nTC [2,3,4,5] TC [2,3,4,5,10,20]\r\nTT [2,3,4,5] TT [2,3,4,5,10,20]\r\nWT [2,3,4,5] WT [2,3,4,5,10,20]\r\nCR \u2013 CR [2,3,4,5,10,20]\r\nINC [2,3,4,5] INC [2,3,4,5,10,20]\r\nFLX [2,3,4,5] FLX [2,3,4,5,10,20]\r\nFUL [2,3,4,5] FUL [2,3,4,5,10,20]\r\nLearning rate [0.0005, 0.001, 0.005, 0.01] Learning rate [0.0005, 0.001, 0.005, 0.01]\r\nNumber of model parameters 4049 Number of model parameters 50,119\r\nNote: Bold indicates the optimal hyperparameters calibrated by Bayesian optimization.\r\nAppendix E. Evaluations Result for DGP-Base\r\nTable A.3 summarizes the evaluation results of the recovery of VOT and VOWT for DGP-Base, where values in bold indicate the best\r\nperformance among the benchmarked models. Table A.4 shows the parameter estimates of DCM-Linear, highlighting the need for\r\nDCMs with a flexible utility specification.\r\nThree main implications are derived from the evaluation results for DGP-Base. First, DCM-LN exhibits the best performance in\r\nrecovering VOT and VOWT distributions and the demographic group-level estimates. Considering a good recovery of model parameters by DCM-Linear (as summarized in Table A.4), the performance of DCM-LN in recovering WTP is impressive. This result implies\r\nthat DCM-LN not only identifies the main and first-order interactions but also successfully uncovers the second-order interactions that\r\nDCM-Linear ignores. Second, DCM-LN only slightly underperforms DCM-DNN and outperforms DCM-Linear in predictability. This\r\nresult is aligned with our hypothesis that DCM-LN can provide trustworthy behavioral interpretations at the expense of a slight\r\ndecrease in predictive performance by approximating the true attribute-specific utility function rather than just fitting it to the data.\r\nThe first two insights also imply a trade-off between interpretability and predictability. If predictability is the only objective, the DCMDNN should be the preferred model due to its superior prediction accuracy even for less complex DGPs like DGP-Base. Third, the\r\nstandard deviation (across 50 synthetic datasets) of VOT and VOWT estimates of DCM-LN is much lower than those estimated by DCMDNN. For example, the standard deviations of quantiles estimated by DCM-LN range from 5 % to 11 % of the mean quantiles, which\r\nrange from 25 % to 32 % for DCM-DNN. This result reflects reasonably stable training of DCM-LN due to constrained parameter space.\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n26\r\nTable A.3\r\nInterpretability and predictability evaluation for DGP-Base.\r\nParameter True DCM-Linear\r\n(50 trials)\r\nDCM-DNN\r\n(50 trials)\r\nDCM-LN\r\n(50 trials)\r\nMean Std. Mean Std. Mean Std. Mean Std.\r\nInterpretability: recovery of distribution VOT (Median) 0.276 0.010 0.306 0.019 0.393 0.104 0.276 0.019\r\nVOT (1 %) 0.142 0.000 0.103 0.004 0.276 0.069 0.156 0.008\r\nVOT (25 %) 0.213 0.002 0.236 0.007 0.356 0.092 0.218 0.012\r\nVOT (75 %) 0.392 0.006 0.403 0.005 0.433 0.115 0.373 0.039\r\nVOT (99 %) 0.656 0.004 0.620 0.006 0.552 0.161 0.550 0.045\r\nVOWT (Median) 0.470 0.020 0.419 0.024 0.836 0.266 0.514 0.045\r\nVOWT (1 %) 0.247 0.000 0.019 0.021 0.502 0.162 0.291 0.033\r\nVOWT (25 %) 0.363 0.009 0.286 0.015 0.702 0.208 0.408 0.044\r\nVOWT (75 %) 0.768 0.012 0.605 0.018 0.988 0.251 0.775 0.088\r\nVOWT (99 %) 1.216 0.006 0.988 0.032 1.280 0.394 1.135 0.102\r\nInterpretability: recovery of demographic groups\u2019 value VOT (MAPE) 0.102 0.002 0.558 0.274 0.091 0.022\r\nVOT (RMSE) 0.029 0.001 0.156 0.067 0.045 0.012\r\nVOWT (MAPE) 0.269 0.030 0.780 0.365 0.128 0.036\r\nVOWT (RMSE) 0.151 0.012 0.383 0.175 0.085 0.026\r\nPredictability: chosen alternative and probabilities Training accuracy 0.716 0.006 0.777 0.007 0.765 0.008\r\nTest accuracy 0.717 0.011 0.748 0.012 0.737 0.013\r\nTraining Brier score 0.372 0.005 0.305 0.008 0.347 0.010\r\nTest Brier score 0.371 0.008 0.339 0.012 0.369 0.010\r\nNote: Std. indicates the standard deviation across synthetic datasets; The bold indicates the best performance among the benchmark models.\r\nWe conduct an in-depth analysis of the results in Table A.3 with Figs. A.1 and A.2. Fig. A.1 shows the demographic group\u2019s VOT and\r\nVOWT estimates for DGP-Base in ascending order of the demographic groups\u2019 true VOT and VOWT. Fig. A.2 shows the utility functions\r\nof TT, WT, and TC. The thick lines in the figure are the population-level utility function (indicated by PD), and the multiple thin lines\r\nare the heterogeneous individual-level utility functions (indicated by ICE). The ICE spread helps in visualizing the extent of interaction\r\neffects or taste heterogeneity. A comparison of PD for all models is provided in Fig. A.2d.\r\nWe observe three insightful patterns in these figures. First, DCM-DNN provides much higher VOT and VOWT estimates for all\r\ndemographic groups in Fig. A.1. This erroneous trend most likely occurs because the estimated utility function of TC (the third plot in\r\nFig. A.2b) is partially flat, leading to the low marginal utility of TC and the overestimation of VOT and VOWT. Second, Fig. A.1 shows\r\nthe highly jagged pattern for DCM-DNN\u2019s estimates of VOT and VOWT (which is expected to be increasing as true values are arranged\r\nin that order), indicating that DCM-DNN cannot provide meaningful behavioral implications for WTP of demographic groups (i.e.,\r\ntaste heterogeneity). This pattern might be a consequence of accounting for non-existing interaction effects of TC by DNN, as indicated\r\nby the DCM-DNN\u2019s non-linear utility function of TC \u2013 leading to erroneous variation in the marginal utility of TC across its domain and\r\ncorresponding WTP estimates. Although such erroneous variations in the marginal utility of TC also exist in DCM-LN, the extent of\r\nvariations is much smaller than those of DCM-DNN. Third, DCM-LN and DCM-Linear well approximate the distribution of VOT and\r\nVOWT for demographic groups. However, better recovery of WTP in DCM-LN compared to that in DCM-Linear could be attributed to\r\nthe former\u2019s capability to capture the second-order interactions ignored by the latter.\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n27\r\nFig. A.1. VOT and VOWT estimates for 40 demographic groups in DGP-Base.\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n28\r\nFig. A.2. Attribute-specific utility functions estimated by (a) DCM-Linear, (b) DCM-DNN, (c) DCM-LN in DGP-Base at the individual and population\r\nlevel, and (d) overlapping population-level utility functions.\r\nTable A.4 reports the mean and standard deviation (across 50 synthetic datasets or trials) of the estimated coefficients and t-statistics of DCM-Linear for DGP-Base and DGP-New. To control the magnitude of the estimated coefficients, we fix the TC\u2019s coefficient of\r\nDCM-Linear as \u20131. While the DGP-Base can describe the true coefficients for each attribute as a single WTP value, the DGP-New cannot\r\ndo so due to the non-linear utility of TC.2 Therefore, we compare the true coefficients with the estimated ones only in DGP-Base.\r\nThe estimation results in DGP-Base show that the DCM-Linear generally provides good estimates for the true coefficients, and tstatistics indicate statistically significant effects for all parameters. However, overlooking the second-order interactions causes biased\r\nestimates for TT \u00d7 FLX and WT \u00d7 FLX, which have second-order interactions in the true DGP-Base. In the DGP-New, the t-statistics of\r\n2 Since the true coefficient of TC (8 \u22c5 \u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305 TCnj \u221a ) in DGP-New is set to have a similar magnitude of utility as in DGP-Base, the estimated coefficients in\r\nDGP-New would have a similar scale to those in DGP-Base.\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n29\r\nall estimated coefficients drastically decrease. In particular, the coefficients for TT and WT are no longer statistically significant, and\r\ntheir t-statistics show large variations across synthetic datasets. Even among other statistically significant coefficients, t-statistics vary\r\nsignificantly across trials. For example, the estimated coefficients for TT \u00d7 FUL and TT \u00d7 CR would be interpreted as significant in\r\nsome trials but not in others. These results verify that the misspecification of utility functions causes unstable and biased estimates for\r\nDGP-New. Such unreliable estimation also causes a sharp decline in model fit measured by Pseudo R2 (0.200 for DGP-Base vs. 0.012 for\r\nDGP-New). These results suggest the need for more flexible models, such as DCM-DNN and DCM-LN, to deal with the complex choice\r\nmechanisms.\r\nTable A.4\r\nEstimation results of DCM-Linear for DGP-Base and DGP-New.\r\nDGP-Base DGP-New\r\nAttribute True DCM-Linear (50 trials) DCM-Linear (50 trials)\r\nCoef. Std (Coef.) t-stat Std (t-stat.) Coef. Std (Coef.) t-stat Std (t-stat.)\r\nConstant \u2212 0.1 \u00a10.158 \u2212 0.051 \u00a13.144 1.000 \u00a11.183 \u2212 0.385 \u00a12.927 0.950\r\nTC \u2212 1 (fixed) \u00a11.000 \u2212 0.027 \u00a136.696 0.404 \u00a11.000 \u2212 0.132 \u00a19.105 0.920\r\nTT \u2212 0.1 \u00a10.089 \u2212 0.005 \u00a118.357 0.917 0.034 \u2212 0.039 1.019 1.185\r\nWT \u2212 0.2 \u00a10.225 \u2212 0.016 \u00a113.394 0.949 0.034 \u2212 0.122 0.269 0.980\r\nCR \u2212 0.2 \u00a10.166 \u2212 0.282 \u00a10.546 0.929\r\nTT \u00d7 IN \u2212 0.5 \u00a10.651 \u2212 0.024 \u00a129.009 0.721 \u00a10.530 \u2212 0.144 \u00a14.347 1.176\r\nTT \u00d7 FUL \u2212 0.1 \u00a10.107 \u2212 0.005 \u00a120.108 0.766 \u00a10.055 \u2212 0.035 \u00a11.551 0.993\r\nTT \u00d7 FLX 0.05 0.120 \u2212 0.004 28.14 0.603 0.095 \u2212 0.020 4.116 0.867\r\nTT \u00d7 CR \u2212 0.02 \u00a10.011 \u2212 0.005 \u00a12.104 1.036\r\nWT \u00d7 INC \u2212 0.8 \u00a11.018 \u2212 0.051 \u00a117.46 0.777 \u00a10.898 \u2212 0.395 \u00a12.156 0.937\r\nWT \u00d7 FUL \u2212 0.3 \u00a10.236 \u2212 0.016 \u00a113.297 0.880 \u00a10.125 \u2212 0.108 \u00a10.949 0.816\r\nWT \u00d7 FLX 0.1 0.280 \u2212 0.015 22.087 0.811 0.207 \u2212 0.088 2.517 1.077\r\nPseudo R2 0.200 (0.003) 0.012 (0.0004)\r\nAppendix F. Estimation Results of DCM-Linear-A, DCM-Linear-B, and DCM-Linear-C\r\nTables A.5\u2013A.7 show the estimation results of DCM-Linear-A, DCM-Linear-B, and DCM-Linear-C, respectively. In DCM-Linear-A, all\r\ncoefficients for alternative attributes are statistically significant at the 5 % level. In DCM-Linear-B, considerable and significant\r\ninteraction effects indicate the presence of systematic taste heterogeneity among different demographic groups. The improved predictability of DCM-Linear-B over DCM-Linear-A suggests the importance of including interactions between alternative- and individualspecific attributes (i.e., taste heterogeneity). DCM-Linear-C shows comparable predictability to DCM-Linear-A but underperforms\r\nDCM-Linear-B, implying that considering the non-linear effect and interaction does not always enhance the predictability. These\r\nresults show that data-driven DCMs could further enhance predictability by capturing the other underlying interactions (e.g., the\r\ninteractions between alternative attributes) and the non-linearity of attribute-specific effects that are ignored by DCM-Linear-B.\r\nTable A.5\r\nEstimated parameters of DCM-Linear-A.\r\nAttributes Train Swiss metro Car (reference)\r\nCoef. t-stat Coef. t-stat Coef. t-stat\r\nConstant 0.216 1.199 0.394 3.598\r\nTravel cost \u00a10.755 \u2212 15.977 \u00a10.755 \u2212 15.977 \u00a10.755 \u2212 15.977\r\nHeadway \u00a10.814 \u2212 5.658 \u2212 0.493 \u2212 1.422\r\nAirline seat 0.759 6.545\r\nAnnual ticket 2.664 10.979 1.429 6.264\r\nTravel time \u00a11.831 \u2212 17.963 \u00a11.474 \u2212 18.65 \u00a11.155 \u2212 19.292\r\nTraining accuracy Test accuracy Training Brier Test Brier\r\nPredictability 0.675 0.657 0.453 0.464\r\nNote: Bold indicates the coefficient is statistically significant at the 10% level.\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n30\r\nAppendix G. Hyperparameter Tuning for DCM-DNN and DCM-LN in Swissmetro Dataset\r\nTable A.8 summarizes the search space for hyperparameters and optimal values for DCM-LN and DCM-DNN for the Swissmetro\r\ndataset. To prevent excessive model complexity and memory requirement, we limit the lattice size for each attribute to below five and\r\nthe number of change points below thirty. The different optimal values of hyperparameters for different alternatives indicate that the\r\nsame attribute affects the utility of different alternatives at different complexity levels. Comparison of the hyperparameters of the\r\nempirical study with those of DGP-Base and DGP-New in the simulation study indicates that the complexity of the Swissmeto dataset\u2019s\r\nDGP could be between those of DGP-Base and DGP-New. The batch size, the number of epochs, and l2 norm weights for wrinkles and\r\nHessian regularizers are set to 128, 200, 0.5, and 0.00001, respectively.\r\nTable A.6\r\nEstimated parameters of DCM-Linear-B.\r\nAttributes Train Swiss metro Car (reference)\r\nCoef. t-stat Coef. t-stat Coef. t-stat\r\nConstant 0.129 0.701 0.299 2.596\r\nTravel cost \u00a10.863 \u2212 17.168 \u00a10.863 \u2212 17.168 \u00a10.863 \u2212 17.168\r\nHeadway \u00a10.844 \u2212 5.773 \u00a10.601 \u2212 1.679\r\nAirline seat 0.717 5.966\r\nAnnual ticket 2.370 9.565 1.091 4.701\r\nTravel time (TT) 0.048 0.196 0.693 1.955 \u2212 0.096 \u2212 0.731\r\nTT \u00d7 Age: 2 \u00a11.957 \u2212 7.032 \u00a11.937 \u2212 4.349 \u00a11.609 \u2212 6.07\r\nTT \u00d7 Age: 3 \u00a11.735 \u2212 6.398 \u00a11.825 \u2212 4.199 \u00a11.394 \u2212 5.521\r\nTT \u00d7 Age: 4 \u00a11.012 \u2212 3.792 \u00a11.157 \u2212 2.728 \u00a10.901 \u2212 3.609\r\nTT \u00d7 Age: 5 \u2212 0.491 \u2212 1.612 \u2212 0.710 \u2212 1.45 \u2212 0.434 \u2212 1.464\r\nTT \u00d7 Income: 2 0.042 0.247 0.501 1.914 0.428 2.384\r\nTT \u00d7 Income: 3 \u00a10.601 \u2212 3.369 \u00a10.100 \u2212 0.367 \u2212 0.147 \u2212 0.797\r\nTT \u00d7 Purpose: 2 \u2212 0.382 \u2212 1.38 \u00a11.095 \u2212 2.613 \u00a10.857 \u2212 2.748\r\nTT \u00d7 Purpose: 3 \u00a10.341 \u2212 2.236 \u00a11.113 \u2212 5.558 \u00a10.269 \u2212 1.784\r\nTT \u00d7 Purpose: 4 \u00a10.363 \u2212 2.268 \u00a11.053 \u2212 5.522 0.056 0.37\r\nTraining accuracy Test accuracy Training Brier Test Brier\r\nPredictability 0.689 0.688 0.432 0.447\r\nNote: Bold indicates the coefficient is statistically significant at the 10 % level.\r\nTable A.7\r\nEstimated parameters of DCM-Linear-C.\r\nAttributes Train Swiss metro Car (reference)\r\nCoef. t-stat Coef. t-stat Coef. t-stat\r\nConstant 0.368 1.224 \u2212 0.001 \u2212 0.003\r\nConstant \u00d7 Male \u00a10.806 \u2212 6.094 \u00a10.217 \u2212 2.590\r\nTravel cost \u00a10.918 \u2212 5.329 \u00a10.749 \u2212 8.510 \u00a10.442 \u2212 3.535 \u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305 Headway \u221a 0.741 1.371 1.168 1.349\r\nLog (Travel time) \u00a13.237 \u2212 22.291 \u00a11.769 \u2212 21.773 \u00a11.768 \u2212 16.877\r\nTT \u00d7 Annual ticket 1.623 5.045 1.358 2.372 \u2212 0.113 \u2212 0.245\r\nTT \u00d7 First class \u2212 0.120 \u2212 0.710 \u00a10.196 \u2212 1.939 \u00a10.573 \u2212 4.615\r\nTT \u00d7 Age: 2 \u00a11.893 \u2212 5.260 \u2212 1.202 \u2212 1.213\r\nTT \u00d7 Age: 3 \u00a11.499 \u2212 4.385 \u2212 1.519 \u2212 1.542\r\nTT \u00d7 Age: 4 \u00a11.101 \u2212 3.115 \u00a12.425 \u2212 2.412\r\nTT \u00d7 Age: 5 \u2212 0.552 \u2212 1.475 \u00a14.456 \u2212 4.016\r\nTraining accuracy Test accuracy Training Brier Test Brier\r\nPredictability 0.673 0.650 0.448 0.459\r\nNote: Bold indicates the coefficient is statistically significant at the 10 % level. While the original model specification for travel cost was piecewise\r\nlinear in Ortelli et al. (2021), the details were missing in that study; thus, we consider the effect of travel cost as linear.\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n31\r\nTable A.8\r\nSearch space for tuning optimal hyperparameters of DCM-LN and DCM-DNN\r\nfor the Swissmetro dataset.\r\nSwissmetro dataset\r\nHyperparameter Search space\r\nDCM-DNN\r\nLayer depth [1,2,3,4,5]\r\nLayer width (N) [50,100,150, 200,250,300]\r\nDropout rate [0.005,0.05,0.1,0.2,0.3]\r\nLearning rate [0.0005, 0.001, 0.005, 0.01]\r\nNumber of model parameters 143,803\r\nDCM-LN\r\nNumber of changing points\r\nTravel time (Train) [10,20,30]\r\nTravel time (Swissmetro) [10,20,30]\r\nTravel time (Car) [10,20,30]\r\nTravel cost (Train) [10,20,30]\r\nTravel cost (Swissmetro) [10,20,30]\r\nTravel cost (Car) [10,20,30]\r\nHeadway (Train) [10,20,30]\r\nHeadway (Swissmetro) [10,20,30]\r\nOutput calibration (Train) [2,3,4]\r\nOutput calibration (Swissmetro) [2,3,4]\r\nOutput calibration (Car) [2,3,4]\r\nLattice size\r\nTravel time (Train) [2,3,4]\r\nTravel time (Swissmetro) [2,3,4]\r\nTravel time (Car) [2,3,4]\r\nTravel cost (Train) [2,3,4]\r\nTravel cost (Swissmetro) [2,3,4]\r\nTravel cost (Car) [2,3,4]\r\nHeadway (Train) [2,3,4]\r\nHeadway (Swissmetro) [2,3,4]\r\nAirline seat (Swissmetro) [2,3,4]\r\nAge (All) [2,3,4]\r\nIncome (All) [2,3,4]\r\nPurpose (All) [2,3,4]\r\nLearning rate [0.0005, 0.001, 0.005, 0.01]\r\nNumber of model parameters 6296\r\nNote: Bold indicates the optimal hyperparameters calibrated by Bayesian\r\noptimization.\r\nAppendix H. Computational expense\r\nThe number of parameters of the model is a well-known measure of model complexity; however, the constrained DCM-LN have\r\ndifferent convergence characteristics to the conventional unconstrained DCM-DNN because the inequality constraints can affect model\r\nconvergence. Therefore, we evaluate the computational expense by comparing the actual training time until the convergence of DCMDNN and DCM-LN. Also, we examine the changes in computational time according to the lattice size, which is the most critical hyperparameter affecting computational complexity.\r\nTable A.9 shows the actual training time of DCM-DNN and DCM-LN until the convergence, which is obtained on a CPU of 12th Gen\r\nIntel Core i9\u201312900HK 2.50 GHz with 32 GB of RAM. For the tuned models, the DCM-LN takes two times more than the DCM-DNN for\r\ntraining until convergence, and the standard deviation of training time is also larger in DCM-LN. Despite the learning rate of DCM-LN is\r\nten times higher than DCM-DNN, the number of epochs until convergence is comparable, and its standard deviation is much higher in\r\nDCM-LN. These results indicate that the computational expense of DCM-LN is generally higher than that of DCM-DNN due to the\r\nstructure of the lattice. Also, the high volatility of the computational expense in DCM-LN may be attributed to sub-optimal gradient\r\nupdate due to the projection for monotonicity constraints (See Section 3.3). Nevertheless, the DCM-LN only takes one minute to train\r\nthe model for the Swissmetro dataset, which has the same order of observations and attributes as of generally encountered SP choice\r\ndatasets. This result indicates the DCM-LN is likely to be scalable for most SP choice datasets, even with a general personal computer.\r\nThe change in computational time according to the lattice size is a good measure of the scalability of the DCM-LN. We arbitrarily\r\nincrease the lattice size for 8 alternative-specific attributes (i.e., travel time, travel cost, and headway for each alternative) from the\r\ntuned DCM-LN ([4,4,4,4,2,4,2,2]) and measure the training time and number of epochs. For example, the DCM-LN (+1) has a lattice\r\nsize of [5,5,5,5,3,5,3,3]. As expected, the training time until convergence increases substantially with the increase in Lattice size, but\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n32\r\nthe number of epochs until convergence is maintained. This result indicates that the model can be stably converged despite the\r\nincreasing computational expenses to estimate the complex utility function. In other words, the DCM-LN is scalable for the choice\r\ndataset that requires inferring more complex utility functions than the Swissmetro dataset.\r\nTable A.9\r\nActual training time until the convergence with 50 trials.\r\nMetric DCM-DNN (Tuned) DCM-LN (Tuned) DCM-LN (+1) DCM-LN (+2)\r\nMean Std Mean Std Mean Std Mean Std\r\nTraining time until the convergence (sec) 27.88 6.50 61.36 23.33 123.03 31.51 148.61 34.55\r\nNumber of epochs until convergence (times) 43.66 5.62 50.76 16.08 51.03 13.45 49.76 10.37\r\nNote: The callback for early stopping is set, in which the training stops if the validation accuracy does not increase during 20 epochs, and the early\r\nstopping point indicate the convergence. The learning rate of DCM-DNN and DCM-LN are 0.0005 and 0.005, respectively.\r\nReferences\r\nAlwosheel, A., van Cranenburgh, S., Chorus, C.G., 2021. Why did you predict that? Towards explainable artificial neural networks for travel demand analysis. Transp.\r\nRes. Part C. Emerg. Technol. 128 https://doi.org/10.1016/j.trc.2021.103143.\r\nArcher, N.P., Wang, S., 1993. Application of the back propagation neural network algorithm with monotonicity constraints for two-group classification problems.\r\nDecis. Sci. 24, 60\u201375. https://doi.org/10.1111/j.1540-5915.1993.tb00462.x.\r\nArkoudi, I., Krueger, R., Azevedo, C.L., Pereira, F.C., 2023. Combining discrete choice models and neural networks through embeddings: formulation, interpretability\r\nand performance. Transp. Res. Part B Methodol. 175, 102783 https://doi.org/10.1016/j.trb.2023.102783.\r\nAxhausen, K.W., Konig, \u00a8 A., Abay, G., Bates, J.J., Bierlaire, M., 2004. Swiss Value of Travel Time Savings. In: Proceedings of the European Transport Conference 2004\r\n(ETC 2004). doi:10.3929/ethz-b-000023559.\r\nAxhausen, K.W., Hess, S., Konig, \u00a8 A., Abay, G., Bates, J., Bierlaire, M., Axhausen, K.W., Hess, S., Konig, \u00a8 A., Abay, G., Bates, J.J., 2007. State of the art estimates of the\r\nSwiss value of travel time savings. In: Proceedings of the 86th Annual Meeting of the Transportation Research Board. https://doi.org/10.3929/ethz-a-005240029.\r\nBansal, P., Daziano, R.A., Sunder, N., 2019. Arriving at a decision: a semi-parametric approach to institutional birth choice in India. J. Choice Model. 31, 86\u2013103.\r\nhttps://doi.org/10.1016/j.jocm.2019.04.001.\r\nBansal, P., Kumar, R.R., Raj, A., Dubey, S., Graham, D.J., 2021. Willingness to pay and attitudinal preferences of Indian consumers for electric vehicles. Energy Econ.\r\n100 https://doi.org/10.1016/j.eneco.2021.105340.\r\nBansal, P., Horcher, \u00a8 D., Graham, D.J., 2022. A dynamic choice model to estimate the user cost of crowding with large-scale transit data. J. R. Stat. Soc. Ser. A (Stat.\r\nSoc.) 1\u201325. https://doi.org/10.1111/rssa.12804.\r\nBarlow, R.E., Bartholomew, D.J., Bremner, J.M., Brunk, H.D., 1974. Statistical inference under order restrictions. The theory and application of isotonic regression.\r\nJ. R. Stat. Soc. Ser. A 137, 92. https://doi.org/10.2307/2345150.\r\nBarredo Arrieta, A., D\u00edaz-Rodr\u00edguez, N., del Ser, J., Bennetot, A., Tabik, S., Barbado, A., Garcia, S., Gil-Lopez, S., Molina, D., Benjamins, R., Chatila, R., Herrera, F.,\r\n2020. Explainable Artificial Intelligence (XAI): concepts, taxonomies, opportunities and challenges toward responsible AI. Inf. Fusion 58, 82\u2013115. https://doi.\r\norg/10.1016/j.inffus.2019.12.012.\r\nBatarce, M., Munoz, \u02dc J.C., de Ort\u00fazar, J.D., 2016. Valuing crowding in public transport: implications for cost-benefit analysis. Transp. Res. Part A Policy Pract. 91,\r\n358\u2013378. https://doi.org/10.1016/j.tra.2016.06.025.\r\nBierlaire, M., Axhausen, K., Abay, G., 2001. The acceptance of modal innovation: the case of Swissmetro. In: Proceedings of the 1st Swiss Transport Research\r\nConference (STRC 2001). doi:10.3929/ethz-a-004238511.\r\nBierlaire, M., 2018. Swissmetro [WWW Document]. URL https://transp-or.epfl.ch/documents/technicalReports/CS_SwissmetroDescription.pdf (accessed 10.14.22).\r\nBrathwaite, T., Walker, J.L., 2018. Causal inference in travel demand modeling (and the lack thereof). J. Choice Model. 26, 1\u201318. https://doi.org/10.1016/j.\r\njocm.2017.12.001.\r\nBrownstone, D., Ghosh, A., Golob, T.F., Kazimi, C., van Amelsfort, D., 2003. Drivers\u2019 willingness-to-pay to reduce travel time: evidence from the San Diego I-15\r\ncongestion pricing project. Transp. Res. Part A Policy Pract. 37, 373\u2013387. https://doi.org/10.1016/S0965-8564(02)00021-6.\r\nCastiglione, J., Bradley, M., Gliebe, J., 2014. Activity-Based Travel Demand Models: A Primer, Activity-Based Travel Demand Models: A Primer. Transportation\r\nResearch Board, Washington, D.C.. https://doi.org/10.17226/22357\r\nCybenkot, G., 1989. Mathematics of control, signals, and systems approximation by superpositions of a sigmoidal function. Math. Control Signal. 2, 303\u2013314.\r\nDaly, A., Sanko, N., Wardman, M., 2017. Cost and time damping: evidence from aggregate rail direct demand models. Transportation 44, 1499\u20131517. https://doi.org/\r\n10.1007/s11116-016-9711-9 (Amst).\r\nDaniels, H., Velikova, M., 2010. Monotone and partially monotone neural networks. IEEE Trans. Neural Netw. 21, 906\u2013917. https://doi.org/10.1109/\r\nTNN.2010.2044803.\r\nDubey, S., Cats, O., Hoogendoorn, S., Bansal, P., 2022. A multinomial probit model with Choquet integral and attribute cut-offs. Transp. Res. Part B Methodol. 158,\r\n140\u2013163. https://doi.org/10.1016/j.trb.2022.02.007.\r\nFriedman, J.H., 2001. Greedy function approximation: a gradient boosting machine. Ann. Stat. 29, 225\u2013244. https://doi.org/10.1214/aos/1013203451.\r\nFukuda, D., Yai, T., 2010. Semiparametric specification of the utility function in a travel mode choice model. Transportation 37, 221\u2013238. https://doi.org/10.1007/\r\ns11116-009-9253-5 (Amst).\r\nGoldstein, A., Kapelner, A., Bleich, J., Pitkin, E., 2015. Peeking inside the black box: visualizing statistical learning with plots of individual conditional expectation.\r\nJ. Comput. Graph. Stat. 24, 44\u201365. https://doi.org/10.1080/10618600.2014.907095.\r\nGunning, D., Stefik, M., Choi, J., Miller, T., Stumpf, S., Yang, G.Z., 2019. XAI-Explainable artificial intelligence. Sci. Robot. 4 https://doi.org/10.1126/scirobotics.\r\naay7120.\r\nGupta, M., Cotter, A., Pfeifer, J., Voevodski, K., Canini, K., Mangylov, A., Moczydlowski, W., Van Esbroeck, A., 2016. Monotonic calibrated interpolated look-up\r\ntables. J. Mach. Learn. Res. 17, 1\u201347. https://doi.org/10.5555/2946645.3007062.\r\nHan, Y., Pereira, F.C., Ben-Akiva, M., Zegras, C., 2022. A neural-embedded discrete choice model: learning taste representation with strengthened interpretability.\r\nTransp. Res. Part B Methodol. 163, 166\u2013186. https://doi.org/10.1016/j.trb.2022.07.001.\r\nHastie, T., Tibshirani, R., 1987. Generalized additive models: some applications. J. Am. Stat. Assoc. 82, 371\u2013386. https://doi.org/10.1080/\r\n01621459.1987.10478440.\r\nHernandez, J.I., van Cranenburgh, S., Chorus, C., Mouter, N., 2023. Data-driven assisted model specification for complex choice experiments data: association rules\r\nlearning and random forests for participatory value evaluation experiments. J. Choice Model. 46 https://doi.org/10.1016/j.jocm.2022.100397.\r\nE.-J. Kim and P. Bansal\r\nTransportation Research Part B 183 (2024) 102947\r\n33\r\nHo, C.Q., Mulley, C., Hensher, D.A., 2020. Public preferences for mobility as a service: insights from stated preference surveys. Transp. Res. Part A Policy Pract. 131,\r\n70\u201390. https://doi.org/10.1016/j.tra.2019.09.031.\r\nJi, S., Wang, X., Lyu, T., Liu, X., Wang, Y., Heinen, E., Sun, Z., 2022. Understanding cycling distance according to the prediction of the XGBoost and the interpretation\r\nof SHAP: a non-linear and interaction effect analysis. J. Transp. Geogr. 103 https://doi.org/10.1016/j.jtrangeo.2022.103414.\r\nKim, E.J., Bansal, P., 2023. A deep generative model for feasible and diverse population synthesis. Transp. Res. Part C Emerg. Technol. 148 https://doi.org/10.1016/j.\r\ntrc.2023.104053.\r\nKim, E.J., Kim, Y., Kim, D.K., 2020. Interpretable machine learning models for estimating trip purpose in smart card data. Proc. Inst. Civ. Eng. Munic. Eng. 1\u201322.\r\nhttps://doi.org/10.1680/jmuen.20.00003.\r\nKim, E., Kim, Y., Jang, S., Kim, D., 2021a. Tourists\u2019 preference on the combination of travel modes under Mobility-as-a-Service environment. Transp. Res. Part A 150,\r\n236\u2013255. https://doi.org/10.1016/j.tra.2021.06.016.\r\nKim, Y., Kim, E., Jang, S., Kim, D., 2021b. A comparative analysis of the users of private cars and public transportation for intermodal options under Mobility-as-aService in Seoul. Travel. Behav. Soc. 24, 68\u201380. https://doi.org/10.1016/j.tbs.2021.03.001.\r\nKim, E.J., Kim, D.K., Sohn, K., 2022. Imputing qualitative attributes for trip chains extracted from smart card data using a conditional generative adversarial network.\r\nTransp. Res. Part C Emerg. Technol. 137 https://doi.org/10.1016/j.trc.2022.103616.\r\nKim, E.J., 2021. Analysis of travel mode choice in seoul using an interpretable machine learning approach. J. Adv. Transp. 2021, 1\u201313. https://doi.org/10.1155/\r\n2021/6685004.\r\nLipton, Z.C., 2018. The mythos of model interpretability: In machine learning, the concept of interpretability is both important and slippery. Queue 16, 31\u201357.\r\nhttps://doi.org/10.1145/3236386.3241340.\r\nLiu, X., Han, X., Zhang, N., Liu, Q., 2020. Certified Monotonic Neural Networks. In: Proceedings of the 34th Conference on Neural Information Processing Systems.\r\nLundberg, S.M., Allen, P.G., Lee, S.I., 2017. A unified approach to interpreting model predictions. In: Proceedings of the 31st Conference on Neural Information\r\nProcessing Systems.\r\nMcFadden, D., 1973. Conditional logit analysis of qualitative choice behavior. In: Zaremmbka, P. (Ed.), Frontiers in Econometrics. Academic Press, New York.\r\nMiller, T., 2019. Explanation in artificial intelligence: insights from the social sciences. Artif. Intell. https://doi.org/10.1016/j.artint.2018.07.007.\r\nMiller, E., 2023. The current state of activity-based travel demand modelling and some possible next steps. Transp. Rev. 43, 565\u2013570. https://doi.org/10.1080/\r\n01441647.2023.2198458.\r\nO\u2019Malley, T., Bursztein, E., Long, J., Chollet, F., Jin, H., Invernizzi, L., 2019. Keras Tuner [WWW Document]. https://github.com/keras-team/keras-tuner.\r\nOrtelli, N., Hillel, T., Pereira, F.C., de Lapparent, M., Bierlaire, M., 2021. Assisted specification of discrete choice models. J. Choice Model. 39 https://doi.org/\r\n10.1016/j.jocm.2021.100285.\r\nQu, Y.J., Hu, B.G., 2011. Generalized constraint neural network regression model subject to linear priors. IEEE Trans. Neural Netw. 22, 2447\u20132459. https://doi.org/\r\n10.1109/TNN.2011.2167348.\r\nRibeiro, M.T., Singh, S., Guestrin, C., 2016. Why should i trust you?\u201d Explaining the predictions of any classifier. In: Proceedings of the ACM SIGKDD International\r\nConference on Knowledge Discovery and Data Mining. Association for Computing Machinery, pp. 1135\u20131144. https://doi.org/10.1145/2939672.2939778.\r\nRich, J., Mabit, S.L., 2016. Cost damping and functional form in transport models. Transportation 43, 889\u2013912. https://doi.org/10.1007/s11116-015-9628-8 (Amst).\r\nRodrigues, F., Ortelli, N., Bierlaire, M., Pereira, F.C., 2022. Bayesian automatic relevance determination for utility function specification in discrete choice models.\r\nIEEE Trans. Intell. Transp. Syst. 23, 3126\u20133136. https://doi.org/10.1109/TITS.2020.3031965.\r\nShahriari, B., Swersky, K., Wang, Z., Adams, R.P., de Freitas, N., 2016. Taking the human out of the loop: a review of Bayesian optimization. Proc. IEEE. https://doi.\r\norg/10.1109/JPROC.2015.2494218.\r\nSifringer, B., Lurkin, V., Alahi, A., 2020. Enhancing discrete choice models with representation learning. Transp. Res. Part B Methodol. 140, 236\u2013261. https://doi.org/\r\n10.1016/j.trb.2020.08.006.\r\nSill, J., 1997. Monotonic networks. In: Proceedings of the 11th Conference on Neural Information Processing Systems, pp. 661\u2013667.\r\nSrinivas, N., Krause, A., Kakade, S.M., Seeger, M., 2010. Gaussian process optimization in the bandit setting: no regret and experimental design. In: Proceedings of the\r\n27th International Conference on Machine Learning, pp. 1015\u20131022.\r\nSwait, J., 2001. A non-compensatory choice model incorporating attribute cutoffs. Transp. Res. Part B Methodol. 35, 903\u2013928. https://doi.org/10.1016/S0191-2615\r\n(00)00030-8.\r\nTrain, K.E., 2009. Discrete Choice Methods with Simulation. Cambridge University Press. https://doi.org/10.1017/CBO9780511805271.\r\nvan Cranenburgh, S., Wang, S., Vij, A., Pereira, F., Walker, J., 2022. Choice modelling in the age of machine learning\u2013discussion paper. J. Choice Model. 42, 100340\r\nhttps://doi.org/10.1016/j.jocm.2021.100340.\r\nVan de Kaa, E.J., 2010. Applicability of an extended prospect theory to travel behaviour research: a meta-analysis. Transp. Rev. 30, 771\u2013804. https://doi.org/\r\n10.1080/01441647.2010.486907.\r\nWang, S., Mo, B., Zhao, J., 2020a. Deep neural networks for choice analysis: architecture design with alternative-specific utility functions. Transp. Res. Part C Emerg.\r\nTechnol. 112, 234\u2013251. https://doi.org/10.1016/j.trc.2020.01.012.\r\nWang, S., Wang, Q., Zhao, J., 2020b. Deep neural networks for choice analysis: extracting complete economic information for interpretation. Transp. Res. Part C\r\nEmerg. Technol. 118, 102701 https://doi.org/10.1016/j.trc.2020.102701.\r\nWang, S., Mo, B., Zhao, J., 2021. Theory-based residual neural networks: a synergy of discrete choice models and deep neural networks. Transp. Res. Part B Methodol.\r\n146, 333\u2013358. https://doi.org/10.1016/j.trb.2021.03.002.\r\nWong, M., Farooq, B., 2021. ResLogit: a residual neural network logit model for data-driven choice modelling. Transp. Res. Part C Emerg. Technol. 126, 103050\r\nhttps://doi.org/10.1016/j.trc.2021.103050.\r\nYou, S., Ding, D., Canini, K., Pfeifer, J., Gupta, M., 2017. Deep Lattice Networks and Partial Monotonic Functions. In: Proceedings of the 31st Conference on Neural\r\nInformation Processing Systems.\r\nZhao, X., Yan, X., Yu, A., van Hentenryck, P., 2020. Prediction and behavioral analysis of travel mode choice: a comparison of machine learning and logit models.\r\nTravel Behav. Soc. 20, 22\u201335. https://doi.org/10.1016/j.tbs.2020.02.003.\r\nE.-J. Kim and P. Bansal\nCode:\n#!/usr/bin/env python\r\n# coding: utf-8\r\n\r\n# In[ ]:\r\n\r\n\r\n## Python basics\r\nimport os\r\nimport numpy as np\r\nimport scipy\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nimport random\r\nfrom IPython.core.pylabtools import figsize\r\nfrom time import time\r\nfrom scipy.stats import norm, uniform\r\nimport math\r\nimport collections\r\nimport collections.abc\r\nfrom collections import OrderedDict    # For recording the model specification \r\ncollections.Iterable = collections.abc.Iterable\r\nimport pylogit as pl  \r\nimport lxml\r\n\r\n## DNN\r\nimport tensorflow as tf\r\nimport tensorflow_lattice as tfl\r\nfrom scikeras.wrappers import KerasRegressor, KerasClassifier\r\nfrom tensorflow.keras.layers import Activation,Input, Dense, Reshape, Concatenate, Layer, Dropout\r\nfrom tensorflow.keras.layers import BatchNormalization, Activation, Embedding, Flatten,LeakyReLU,ReLU\r\nfrom tensorflow.keras.models import Sequential, Model\r\nfrom tensorflow.keras.optimizers import RMSprop, Adam\r\n\r\nfrom sklearn.metrics import accuracy_score,f1_score\r\nfrom statsmodels.formula.api import logit\r\nimport statsmodels.api as sm\r\nfrom sklearn.base import BaseEstimator, ClassifierMixin\r\nfrom sklearn.utils.multiclass import unique_labels\r\nimport torch.nn.functional as F\r\nimport torch\r\nfrom torch import tensor\r\nimport torch.distributions.log_normal as log_normal\r\nimport torch.distributions.bernoulli as bernoulli \r\n\r\n\r\n## PDP\r\nfrom sklearn.inspection import PartialDependenceDisplay, partial_dependence\r\nfrom sklearn.linear_model import LogisticRegression\r\nimport matplotlib.pyplot as plt\r\nfrom sklearn.metrics import mean_absolute_error,mean_absolute_percentage_error,accuracy_score,mean_squared_error\r\nfrom tensorflow.keras import regularizers\r\nfrom sklearn.metrics import brier_score_loss\r\n\r\n\r\n# Get the prediction metrics\r\ndef brier_multi(targets, probs):\r\n     return np.mean(np.sum((probs - targets)**2, axis=1))\r\ndef save_clipboard(X):\r\n    pd.DataFrame(X).to_clipboard(index=False,header=False)\r\nnp.set_printoptions(suppress=True)\r\n\r\npd.options.mode.chained_assignment = None  # default='warn'\r\n\r\ndef compute_VOT_POP(X,Y):\r\n    VOT_temp = []\r\n    for i in range(X.shape[0]):\r\n        for j in range(Y.shape[0]):\r\n            VOT_temp.append(X[i]/Y[j])\r\n    return np.array(VOT_temp)\r\n\r\ndef compute_VOT_IND(X,Y):\r\n    VOT_temp = []\r\n    for i in range(X.shape[0]):\r\n        #VOT_temp.append(compute_VOT_POP(X[i,:],Y[i,:]).mean())\r\n         VOT_temp.append(np.median(compute_VOT_POP(X[i,:],Y[i,:])))\r\n    return np.array(VOT_temp)\r\n\r\nimport warnings\r\n\r\n#suppress warnings\r\nwarnings.filterwarnings('ignore')\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\nimport os\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    \r\nimport tensorflow as tf\r\n\r\n# gpu = tf.config.experimental.get_visible_devices('GPU')[0]\r\n# tf.config.experimental.set_memory_growth(device = gpu, enable = True)\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\ndf_wide = pd.read_csv(\"data/data_METRO.csv\")\r\ndf_wide = df_wide[(df_wide.AGE != 6) & (df_wide.CHOICE != 0) & (df_wide.INCOME != 4) & (df_wide.PURPOSE != 9) & (df_wide.CAR_AV != 0)]\r\n\r\n# Create AGE dummy\r\ndf_wide[\"AGES\"] = 0\r\ndf_wide.loc[df_wide[\"AGE\"] == 1,\"AGES\"] = 1\r\ndf_wide.loc[df_wide[\"AGE\"] == 2,\"AGES\"] = 2\r\ndf_wide.loc[df_wide[\"AGE\"] == 3,\"AGES\"] = 3\r\ndf_wide.loc[df_wide[\"AGE\"] == 4,\"AGES\"] = 4\r\ndf_wide.loc[df_wide[\"AGE\"] == 5,\"AGES\"] = 5\r\n\r\n# Create INCOME dummy\r\ndf_wide[\"INCOMES\"] = 0\r\ndf_wide.loc[df_wide[\"INCOME\"].isin([0,1]),\"INCOMES\"] = 1\r\ndf_wide.loc[df_wide[\"INCOME\"] == 2,\"INCOMES\"] = 2\r\ndf_wide.loc[df_wide[\"INCOME\"] == 3,\"INCOMES\"] = 3\r\ndf_wide.loc[df_wide[\"INCOME\"] == 4,\"INCOMES\"] = 4\r\n\r\n\r\n# Create PURPOSE dummy\r\ndf_wide[\"PURPOSES\"] = 0\r\ndf_wide.loc[df_wide[\"PURPOSE\"].isin([1,5]),\"PURPOSES\"] = 1\r\ndf_wide.loc[df_wide[\"PURPOSE\"].isin([2,6]),\"PURPOSES\"] = 2\r\ndf_wide.loc[df_wide[\"PURPOSE\"].isin([3,7]),\"PURPOSES\"] = 3\r\ndf_wide.loc[df_wide[\"PURPOSE\"].isin([4,8]),\"PURPOSES\"] = 4\r\n\r\n\r\n\r\n# Scale the travel time column by 60 to convert raw units (minutes) to hours\r\ndf_wide[\"TRAIN_TT\"] = df_wide[\"TRAIN_TT\"] / 100.0\r\ndf_wide[\"SM_TT\"] = df_wide[\"SM_TT\"] / 100.0\r\ndf_wide[\"CAR_TT\"] = df_wide[\"CAR_TT\"] / 100.0\r\n\r\n# Scale the headway column by 60 to convert raw units (minutes) to hours\r\ndf_wide[\"TRAIN_HE\"] = df_wide[\"TRAIN_HE\"] / 100.0\r\ndf_wide[\"SM_HE\"] = df_wide[\"SM_HE\"] / 100.0\r\n\r\ndf_wide[\"TRAIN_TC\"] = df_wide[\"TRAIN_CO\"] / 100.0\r\ndf_wide[\"SM_TC\"] = df_wide[\"SM_CO\"] / 100.0\r\ndf_wide[\"CAR_TC\"] = df_wide[\"CAR_CO\"] / 100.0\r\n\r\ndf_wide.loc[(df_wide[\"GA\"] == 1),\"TRAIN_TC\"] = 0\r\ndf_wide.loc[(df_wide[\"GA\"] == 1),\"SM_TC\"] = 0\r\n\r\n\r\n##########\r\n# Create various dummy variables to describe the choice context of a given\r\n# invidual for each choice task.\r\n##########\r\n\r\n# Create AGE dummy\r\n#df_wide[\"AGE_1\"] = (df_wide[\"AGE\"] == 1).astype(int)\r\ndf_wide[\"AGE_2\"] = (df_wide[\"AGE\"] == 2).astype(int)\r\ndf_wide[\"AGE_3\"] = (df_wide[\"AGE\"] == 3).astype(int)\r\ndf_wide[\"AGE_4\"] = (df_wide[\"AGE\"] == 4).astype(int)\r\ndf_wide[\"AGE_5\"] = (df_wide[\"AGE\"] == 5).astype(int)\r\n\r\n# Create INCOME dummy\r\n#df_wide[\"INCOME_01\"] = (df_wide[\"INCOME\"].isin([0,1])).astype(int)\r\ndf_wide[\"INCOME_2\"] = (df_wide[\"INCOME\"] == 2).astype(int)\r\ndf_wide[\"INCOME_3\"] = (df_wide[\"INCOME\"] == 3).astype(int)\r\ndf_wide[\"INCOME_4\"] = (df_wide[\"INCOME\"] == 4).astype(int)\r\n\r\n# Create PURPOSE dummy\r\n#df_wide[\"PURPOSE_1\"] = (df_wide[\"PURPOSE\"].isin([1,5])).astype(int)\r\ndf_wide[\"PURPOSE_2\"] = (df_wide[\"PURPOSE\"].isin([2,6])).astype(int)\r\ndf_wide[\"PURPOSE_3\"] = (df_wide[\"PURPOSE\"].isin([3,7])).astype(int)\r\ndf_wide[\"PURPOSE_4\"] = (df_wide[\"PURPOSE\"].isin([4,8])).astype(int)\r\n\r\n# Create LUGGAGE dummy\r\n#df_wide[\"LUGGAGE_0\"] = (df_wide[\"LUGGAGE\"] == 0).astype(int)\r\ndf_wide[\"LUGGAGE_1\"] = (df_wide[\"LUGGAGE\"] == 1).astype(int)\r\ndf_wide[\"LUGGAGE_3\"] = (df_wide[\"LUGGAGE\"] == 3).astype(int)\r\n\r\n# Create a dummy variable indicating that a person is NOT first class\r\ndf_wide[\"TRAIN_CLASS\"] = 1 - df_wide[\"FIRST\"]\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\ndf_wide['TRAIN_TT']\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\n# Create the list of individual specific variables\r\nind_variables = ['ID','GA','AGE_2', 'AGE_3', 'AGE_4',\r\n       'AGE_5', 'INCOME_2', 'INCOME_3', 'INCOME_4', 'PURPOSE_2', 'PURPOSE_3',\r\n       'PURPOSE_4','AGES', 'INCOMES','PURPOSES']\r\n\r\n\r\n# Specify the variables that vary across individuals and some or all alternatives\r\n# The keys are the column names that will be used in the long format dataframe.\r\n# The values are dictionaries whose key-value pairs are the alternative id and\r\n# the column name of the corresponding column that encodes that variable for\r\n# the given alternative. Examples below.\r\nalt_varying_variables = {u'TT': dict([(1, 'TRAIN_TT'),\r\n                                               (2, 'SM_TT'),\r\n                                               (3, 'CAR_TT')]),\r\n                          u'TC': dict([(1, 'TRAIN_TC'),\r\n                                                (2, 'SM_TC'),\r\n                                                (3, 'CAR_TC')]),\r\n                          u'HE': dict([(1, 'TRAIN_HE'),\r\n                                            (2, 'SM_HE')]),\r\n                          u'SEAT': dict([(2, \"SM_SEATS\")])}\r\n\r\n# Specify the availability variables\r\n# Note that the keys of the dictionary are the alternative id's.\r\n# The values are the columns denoting the availability for the\r\n# given mode in the dataset.\r\navailability_variables = {1: 'TRAIN_AV',\r\n                          2: 'SM_AV', \r\n                          3: 'CAR_AV'}\r\n\r\n##########\r\n# Determine the columns for: alternative ids, the observation ids and the choice\r\n##########\r\n# The 'custom_alt_id' is the name of a column to be created in the long-format data\r\n# It will identify the alternative associated with each row.\r\ncustom_alt_id = \"mode_id\"\r\n\r\n# Create a custom id column that ignores the fact that this is a \r\n# panel/repeated-observations dataset. Note the +1 ensures the id's start at one.\r\nobs_id_column = \"custom_id\"\r\ndf_wide[obs_id_column] = np.arange(df_wide.shape[0], dtype=int) + 1\r\n\r\n# Create a variable recording the choice column\r\nchoice_column = \"CHOICE\"\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\n# Perform the conversion to long-format\r\ndf_long = pl.convert_wide_to_long(df_wide, \r\n                                           ind_variables, \r\n                                           alt_varying_variables, \r\n                                           availability_variables, \r\n                                           obs_id_column, \r\n                                           choice_column,\r\n                                           new_alt_id_name=custom_alt_id)\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\ndf_long[\"TTxAGE_2\"] = df_long[\"TT\"]*df_long[\"AGE_2\"]\r\ndf_long[\"TTxAGE_3\"] = df_long[\"TT\"]*df_long[\"AGE_3\"]\r\ndf_long[\"TTxAGE_4\"] = df_long[\"TT\"]*df_long[\"AGE_4\"]\r\ndf_long[\"TTxAGE_5\"] = df_long[\"TT\"]*df_long[\"AGE_5\"]\r\n\r\ndf_long[\"TTxINCOME_2\"] = df_long[\"TT\"]*df_long[\"INCOME_2\"]\r\ndf_long[\"TTxINCOME_3\"] = df_long[\"TT\"]*df_long[\"INCOME_3\"]\r\n\r\ndf_long[\"TTxPURPOSE_2\"] = df_long[\"TT\"]*df_long[\"PURPOSE_2\"]\r\ndf_long[\"TTxPURPOSE_3\"] = df_long[\"TT\"]*df_long[\"PURPOSE_3\"]\r\ndf_long[\"TTxPURPOSE_4\"] = df_long[\"TT\"]*df_long[\"PURPOSE_4\"]\r\n\r\n\r\n# ## 1. MNL-A\r\n\r\n# In[ ]:\r\n\r\n\r\n# Alternative-specific Utility Specification\r\n\r\nbasic_specification = OrderedDict()\r\nbasic_names = OrderedDict()\r\n\r\nbasic_specification[\"intercept\"] = [1, 2]\r\nbasic_names[\"intercept\"] = ['ASC Train',\r\n                            'ASC Swissmetro']\r\n\r\nbasic_specification[\"TT\"] = [1, 2, 3]\r\nbasic_names[\"TT\"] = ['Travel Time(Train)',\r\n                     'Travel Time(Swissmetro)',\r\n                     'Travel Time(Car)']\r\n\r\nbasic_specification[\"TC\"] = [[1, 2, 3]]\r\nbasic_names[\"TC\"] = ['Travel Cost(All)']\r\n\r\nbasic_specification[\"HE\"] = [1, 2]\r\nbasic_names[\"HE\"] = [\"Headway(Train)\",\r\n                     \"Headway(Swissmetro)\"]\r\n\r\nbasic_specification[\"SEAT\"] = [2]\r\nbasic_names[\"SEAT\"] = ['Airline Seat(Swissmetro)']\r\n\r\nbasic_specification[\"GA\"] = [1,2]\r\nbasic_names[\"GA\"] = ['GA(Train)',\r\n                     'GA(Swissmetro)']\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\nfrom sklearn.model_selection import GroupShuffleSplit\r\nfrom sklearn.model_selection import train_test_split\r\n\r\n#Original: 1005\r\n\r\nSS = GroupShuffleSplit(n_splits=2, train_size=0.7, random_state=1234)\r\ntrain_idx, rem_idx = next(SS.split(df_wide,groups = df_wide['custom_id']))\r\n\r\ndf_wide_train = df_wide.iloc[train_idx]\r\ndf_wide_rem = df_wide.iloc[rem_idx]\r\n\r\nSS2 = GroupShuffleSplit(n_splits=2, train_size=0.5, random_state=1234)\r\ntest_idx, valid_idx = next(SS2.split(df_wide_rem,groups = df_wide_rem['custom_id']))\r\ndf_wide_test = df_wide_rem.iloc[test_idx]\r\ndf_wide_valid = df_wide_rem.iloc[valid_idx]\r\n\r\ndf_train = df_long[df_long.custom_id.isin(df_wide_train['custom_id'].unique())]\r\ndf_test = df_long[df_long.custom_id.isin(df_wide_test['custom_id'].unique())]\r\n\r\n\r\n\r\n# Estimate the multinomial logit model (MNL)\r\nMNL_A = pl.create_choice_model(data=df_train,\r\n                                alt_id_col=custom_alt_id,\r\n                                obs_id_col=obs_id_column,\r\n                                choice_col=choice_column,\r\n                                specification=basic_specification,\r\n                                model_type=\"MNL\",\r\n                                names=basic_names)\r\n\r\n# Specify the initial values and method for the optimization.\r\nMNL_A.fit_mle(np.zeros(11),maxiter=3000)\r\n\r\n\r\n# Get the prediction metrics\r\npredict_train = np.argmax(MNL_A.predict(df_train).reshape(-1,3),axis=1)\r\npredict_test =  np.argmax(MNL_A.predict(df_test).reshape(-1,3),axis=1)\r\n\r\ny_train = np.array(df_train.CHOICE).reshape(-1,3)\r\ny_test = np.array(df_test.CHOICE).reshape(-1,3)\r\ny_train_cat = np.argmax(np.array(df_train.CHOICE).reshape(-1,3),axis=1)\r\ny_test_cat = np.argmax(np.array(df_test.CHOICE).reshape(-1,3),axis=1)\r\n\r\n\r\ntrain_p = MNL_A.predict(df_train).reshape(-1,3)\r\ntest_p = MNL_A.predict(df_test).reshape(-1,3)\r\n\r\ntest_NLL = round((F.cross_entropy(input=torch.log(tensor(test_p)),target=torch.Tensor(y_test)).numpy()).item(),3)\r\ntrain_NLL =  round((F.cross_entropy(input=torch.log(tensor(train_p)),target=torch.Tensor(y_train)).numpy()).item(),3)\r\n\r\n\r\ntrain_acc = round(accuracy_score(y_train_cat,predict_train),3)\r\ntest_acc = round(accuracy_score(y_test_cat,predict_test),3)\r\n\r\ntrain_brier = round(brier_multi(y_train,train_p),3)\r\ntest_brier = round(brier_multi(y_test,test_p),3)\r\n\r\nprint([train_acc,test_acc,train_NLL,test_NLL,train_brier,test_brier])\r\npd.DataFrame(np.array([train_acc,test_acc,train_NLL,test_NLL,train_brier,test_brier])).transpose().to_clipboard(index=False,header=False)\r\n# Look at the estimation results\r\nMNL_A.get_statsmodels_summary()\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\n# Get the utility\r\nparam_table = MNL_A.get_statsmodels_summary().tables[1].as_html()\r\nparam_table = pd.read_html(param_table, header=0, index_col=0)[0]\r\nparam_coef = param_table['coef']\r\ndf_TR = df_long.loc[df_long['mode_id'] == 1,['TT','TC','HE','GA']]\r\ndf_SM = df_long.loc[df_long['mode_id'] == 2,['TT','TC','HE','GA','SEAT']]\r\ndf_CAR = df_long.loc[df_long['mode_id'] == 3,['TT','TC']]\r\n\r\nutil_TR = param_table['coef']['ASC Train'] + np.dot(np.array(df_TR),np.array(param_table['coef'][['Travel Time(Train)','Travel Cost(All)','Headway(Train)','GA(Train)']]))\r\nutil_SM = param_table['coef']['ASC Swissmetro'] + np.dot(np.array(df_SM),np.array(param_table['coef'][['Travel Time(Swissmetro)','Travel Cost(All)','Headway(Swissmetro)','GA(Swissmetro)','Airline Seat(Swissmetro)']]))\r\nutil_CAR = np.dot(np.array(df_CAR),np.array(param_table['coef'][['Travel Time(Car)','Travel Cost(All)']]))\r\n\r\nprint(util_TR.min(),util_TR.max(),util_SM.min(),util_SM.max(),util_CAR.min(),util_CAR.max())\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\n# Get the individual-level VOT \r\ndef first(x):\r\n    return(x.iloc[1,:])\r\n\r\nVOT_TR_A =  param_coef['Travel Time(Train)']/param_coef['Travel Cost(All)']\r\nVOT_SM_A =  param_coef['Travel Time(Swissmetro)']/param_coef['Travel Cost(All)']\r\nVOT_CAR_A =  param_coef['Travel Time(Car)']/param_coef['Travel Cost(All)']\r\n\r\nprint(np.array([VOT_TR_A,VOT_SM_A,VOT_CAR_A,]).round(3))\r\n\r\n\r\n# ## 2. MNL-B\r\n\r\n# In[ ]:\r\n\r\n\r\n# Alternative-specific Utility Specification\r\n\r\nbasic_specification = OrderedDict()\r\nbasic_names = OrderedDict()\r\n\r\nbasic_specification[\"intercept\"] = [1, 2]\r\nbasic_names[\"intercept\"] = ['ASC Train',\r\n                            'ASC Swissmetro']\r\n\r\nbasic_specification[\"TT\"] = [1, 2, 3]\r\nbasic_names[\"TT\"] = ['Travel Time(Train)',\r\n                     'Travel Time(Swissmetro)',\r\n                     'Travel Time(Car)']\r\n\r\nbasic_specification[\"TC\"] = [[1, 2, 3]]\r\nbasic_names[\"TC\"] = ['Travel Cost(All)']\r\n                     \r\n\r\nbasic_specification[\"HE\"] = [1, 2]\r\nbasic_names[\"HE\"] = [\"Headway(Train)\",\r\n                     \"Headway(Swissmetro)\"]\r\n\r\nbasic_specification[\"SEAT\"] = [2]\r\nbasic_names[\"SEAT\"] = ['Airline Seat(Swissmetro)']\r\n\r\nbasic_specification[\"GA\"] = [1,2]\r\nbasic_names[\"GA\"] = ['GA(Train)',\r\n                     'GA(Swissmetro)']\r\n\r\n## First-order Interactions\r\nbasic_specification[\"TTxAGE_2\"] = [1, 2, 3]\r\nbasic_names[\"TTxAGE_2\"] = [\"TTxAGE_2(Train)\",\r\n                           \"TTxAGE_2(Swissmetro)\",\r\n                           \"TTxAGE_2(Car)\"]\r\n\r\nbasic_specification[\"TTxAGE_3\"] = [1, 2, 3]\r\nbasic_names[\"TTxAGE_3\"] = [\"TTxAGE_3(Train)\",\r\n                           \"TTxAGE_3(Swissmetro)\",\r\n                           \"TTxAGE_3(Car)\"]\r\n\r\nbasic_specification[\"TTxAGE_4\"] = [1, 2, 3]\r\nbasic_names[\"TTxAGE_4\"] = [\"TTxAGE_4(Train)\",\r\n                           \"TTxAGE_4(Swissmetro)\",\r\n                           \"TTxAGE_4(Car)\"]\r\n\r\nbasic_specification[\"TTxAGE_5\"] = [1, 2, 3]\r\nbasic_names[\"TTxAGE_5\"] = [\"TTxAGE_5(Train)\",\r\n                           \"TTxAGE_5(Swissmetro)\",\r\n                           \"TTxAGE_5(Car)\"]\r\n\r\nbasic_specification[\"TTxINCOME_2\"] = [1, 2, 3]\r\nbasic_names[\"TTxINCOME_2\"] = [\"TTxINCOME_2(Train)\",\r\n                              \"TTxINCOME_2(Swissmetro)\",\r\n                              \"TTxINCOME_2(Car)\"]\r\n\r\nbasic_specification[\"TTxINCOME_3\"] = [1, 2, 3]\r\nbasic_names[\"TTxINCOME_3\"] = [\"TTxINCOME_3(Train)\",\r\n                              \"TTxINCOME_3(Swissmetro)\",\r\n                              \"TTxINCOME_3(Car)\"]\r\n\r\nbasic_specification[\"TTxPURPOSE_2\"] = [1, 2, 3]\r\nbasic_names[\"TTxPURPOSE_2\"] = [\"TTxPURPOSE_2(Train)\",\r\n                              \"TTxPURPOSE_2(Swissmetro)\",\r\n                              \"TTxPURPOSE_2(Car)\"]\r\n\r\nbasic_specification[\"TTxPURPOSE_3\"] = [1, 2, 3]\r\nbasic_names[\"TTxPURPOSE_3\"] = [\"TTxPURPOSE_3(Train)\",\r\n                              \"TTxPURPOSE_3(Swissmetro)\",\r\n                              \"TTxPURPOSE_3(Car)\"]\r\n\r\nbasic_specification[\"TTxPURPOSE_4\"] = [1, 2, 3]\r\nbasic_names[\"TTxPURPOSE_4\"] = [\"TTxPURPOSE_4(Train)\",\r\n                              \"TTxPURPOSE_4(Swissmetro)\",\r\n                              \"TTxPURPOSE_4(Car)\"]\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\nfrom sklearn.model_selection import GroupShuffleSplit\r\n\r\n\r\n# Estimate the multinomial logit model (MNL)\r\nMNL_B = pl.create_choice_model(data=df_train,\r\n                                alt_id_col=custom_alt_id,\r\n                                obs_id_col=obs_id_column,\r\n                                choice_col=choice_column,\r\n                                specification=basic_specification,\r\n                                model_type=\"MNL\",\r\n                                names=basic_names)\r\n\r\n# Specify the initial values and method for the optimization.\r\nMNL_B.fit_mle(np.zeros(38))\r\n\r\n# Look at the estimation results\r\nMNL_B.get_statsmodels_summary()\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\n# Get the prediction metrics\r\npredict_train = np.argmax(MNL_B.predict(df_train).reshape(-1,3),axis=1)\r\npredict_test =  np.argmax(MNL_B.predict(df_test).reshape(-1,3),axis=1)\r\n\r\ny_train = np.array(df_train.CHOICE).reshape(-1,3)\r\ny_test = np.array(df_test.CHOICE).reshape(-1,3)\r\ny_train_cat = np.argmax(np.array(df_train.CHOICE).reshape(-1,3),axis=1)\r\ny_test_cat = np.argmax(np.array(df_test.CHOICE).reshape(-1,3),axis=1)\r\n\r\n\r\ntrain_p = MNL_B.predict(df_train).reshape(-1,3)\r\ntest_p = MNL_B.predict(df_test).reshape(-1,3)\r\n\r\ntest_NLL = round((F.cross_entropy(input=torch.log(tensor(test_p)),target=torch.Tensor(y_test)).numpy()).item(),3)\r\ntrain_NLL =  round((F.cross_entropy(input=torch.log(tensor(train_p)),target=torch.Tensor(y_train)).numpy()).item(),3)\r\n\r\ntrain_acc = round(accuracy_score(y_train_cat,predict_train),3)\r\ntest_acc = round(accuracy_score(y_test_cat,predict_test),3)\r\n\r\ntrain_brier = round(brier_multi(y_train,train_p),3)\r\ntest_brier = round(brier_multi(y_test,test_p),3)\r\n\r\nprint([train_acc,test_acc,train_NLL,test_NLL,train_brier,test_brier])\r\npd.DataFrame(np.array([train_acc,test_acc,train_NLL,test_NLL,train_brier,test_brier])).transpose().to_clipboard(index=False)\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\n# Get the individual-level VOT \r\ndef first(x):\r\n    return(x.iloc[1,:])\r\n\r\nparam_table = MNL_B.get_statsmodels_summary().tables[1].as_html()\r\nparam_table = pd.read_html(param_table, header=0, index_col=0)[0]\r\nparam_coef = param_table['coef']\r\ndf_VOT_B = df_test[['ID','custom_id','AGE_2', 'AGE_3','AGE_4', 'AGE_5',\r\n                  'INCOME_2', 'INCOME_3', 'PURPOSE_2','PURPOSE_3', 'PURPOSE_4','AGES','INCOMES','PURPOSES']].groupby('custom_id').apply(first)\r\ndf_VOT_B['intercept'] = np.ones(df_VOT_B.shape[0])\r\nVOT_TR_B = np.dot(\r\n        np.array(df_VOT_B[['intercept','AGE_2', 'AGE_3','AGE_4', 'AGE_5',\r\n                'INCOME_2', 'INCOME_3', 'PURPOSE_2','PURPOSE_3', 'PURPOSE_4']]),\r\n        np.array(param_coef[['Travel Time(Train)',\r\n                'TTxAGE_2(Train)','TTxAGE_3(Train)','TTxAGE_4(Train)','TTxAGE_5(Train)','TTxINCOME_2(Train)','TTxINCOME_3(Train)',\r\n                'TTxPURPOSE_2(Train)','TTxPURPOSE_3(Train)','TTxPURPOSE_4(Train)']]))\r\n\r\nVOT_SM_B = np.dot(\r\n        np.array(df_VOT_B[['intercept','AGE_2', 'AGE_3','AGE_4','AGE_5',\r\n                'INCOME_2', 'INCOME_3', 'PURPOSE_2','PURPOSE_3','PURPOSE_4']]),\r\n        np.array(param_coef[['Travel Time(Swissmetro)',\r\n                'TTxAGE_2(Swissmetro)','TTxAGE_3(Swissmetro)','TTxAGE_4(Swissmetro)','TTxAGE_5(Swissmetro)','TTxINCOME_2(Swissmetro)','TTxINCOME_3(Swissmetro)',\r\n                'TTxPURPOSE_2(Swissmetro)','TTxPURPOSE_3(Swissmetro)','TTxPURPOSE_4(Swissmetro)']]))\r\n\r\nVOT_CAR_B = np.dot(\r\n        np.array(df_VOT_B[['intercept','AGE_2', 'AGE_3','AGE_4', 'AGE_5',\r\n                'INCOME_2', 'INCOME_3', 'PURPOSE_2','PURPOSE_3', 'PURPOSE_4']]),\r\n        np.array(param_coef[['Travel Time(Car)',\r\n                'TTxAGE_2(Car)','TTxAGE_3(Car)','TTxAGE_4(Car)','TTxAGE_5(Car)','TTxINCOME_2(Car)','TTxINCOME_3(Car)',\r\n                'TTxPURPOSE_2(Car)','TTxPURPOSE_3(Car)','TTxPURPOSE_4(Car)']]))\r\n\r\ndf_VOT_B['VOT_TR'] = VOT_TR_B / param_coef['Travel Cost(All)']\r\ndf_VOT_B['VOT_SM'] = VOT_SM_B / param_coef['Travel Cost(All)']\r\ndf_VOT_B['VOT_CAR'] = VOT_CAR_B / param_coef['Travel Cost(All)']\r\n\r\ndf_VOT_B = df_VOT_B[['ID','VOT_TR','VOT_SM','VOT_CAR',\r\n                     'AGES','INCOMES','PURPOSES']].groupby(['AGES','INCOMES','PURPOSES']).mean()\r\n\r\nprint(np.quantile(df_VOT_B['VOT_TR'],(0.5,0.01,0.25,0.75,0.99)).round(3))\r\nprint(np.quantile(df_VOT_B['VOT_SM'],(0.5,0.01,0.25,0.75,0.99)).round(3))\r\nprint(np.quantile(df_VOT_B['VOT_CAR'],(0.5,0.01,0.25,0.75,0.99)).round(3))\r\n\r\n\r\n# ## 3. DNN\r\n\r\n# In[ ]:\r\n\r\n\r\n## 1. DNN\r\n\r\nx_train = df_wide_train[[\r\n    'TRAIN_TT','TRAIN_TC','TRAIN_HE',\r\n    'SM_TT','SM_TC','SM_HE','SM_SEATS',\r\n    'CAR_TT', 'CAR_TC','GA','AGES','INCOMES','PURPOSES']]\r\n\r\ny_train = np.array(pd.get_dummies(df_wide_train['CHOICE']))\r\n\r\n\r\nx_test = df_wide_test[[\r\n    'TRAIN_TT','TRAIN_TC','TRAIN_HE',\r\n    'SM_TT','SM_TC','SM_HE','SM_SEATS',\r\n    'CAR_TT', 'CAR_TC','GA','AGES','INCOMES','PURPOSES']]\r\n\r\ny_test = np.array(pd.get_dummies(df_wide_test['CHOICE']))\r\n\r\nx_valid = df_wide_valid[[\r\n    'TRAIN_TT','TRAIN_TC','TRAIN_HE',\r\n    'SM_TT','SM_TC','SM_HE','SM_SEATS',\r\n    'CAR_TT', 'CAR_TC','GA','AGES','INCOMES','PURPOSES']]\r\n\r\ny_valid = np.array(pd.get_dummies(df_wide_valid['CHOICE']))\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\n## 2. Define the Original DNN\r\n\r\ndef build_DNN(num_layers,num_neurons,drop_rate,learning_rate):\r\n\r\n    img = Input(shape=x_train.shape[1],name=\"main_input\")   \r\n    h = Dense(num_neurons,activation='relu')(img)\r\n    h = Dropout(drop_rate)(h)\r\n    for num_layer in range(num_layers-1):\r\n        h = Dense(num_neurons,activation='relu')(h)\r\n        h = Dropout(drop_rate)(h)\r\n    util = Dense(1)(h)\r\n    \r\n    ## Alternative-specific utility\r\n    util_ALT1 = Dense(int(num_neurons*0.5))(h)\r\n    util_ALT1 = Dropout(drop_rate)(util_ALT1)\r\n    util_ALT1 = Dense(1,name='output_TR')(util_ALT1)\r\n    \r\n    util_ALT2 = Dense(int(num_neurons*0.5))(h)\r\n    util_ALT2 = Dropout(drop_rate)(util_ALT2)\r\n    util_ALT2 = Dense(1,name='output_SM')(util_ALT2)\r\n       \r\n    util_ALT3 = Dense(int(num_neurons*0.5))(h)\r\n    util_ALT3 = Dropout(drop_rate)(util_ALT3)\r\n    util_ALT3 = Dense(1,name='output_CAR')(util_ALT3)\r\n\r\n    out_prob =  tf.keras.layers.Softmax(name='out_prob')(Concatenate()([util_ALT1,util_ALT2,util_ALT3]))\r\n    \r\n    model = Model(img,[out_prob,util_ALT1,util_ALT2,util_ALT3])  \r\n    \r\n    optimizer = Adam(learning_rate=learning_rate)\r\n    model.compile(optimizer=optimizer, loss=['categorical_crossentropy',None,None,None],\r\n                  metrics=['accuracy',None,None,None])\r\n\r\n    return model\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\nfor i in range(0,1):\r\n    \r\n    num_layers = 3\r\n    num_neurons = 200\r\n    drop_rate = 0.005\r\n    learning_rate = 0.0005\r\n\r\n    DNN = build_DNN(num_layers,num_neurons,drop_rate,learning_rate)\r\n\r\n    batch_size = 128\r\n    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', restore_best_weights=True, verbose=1, patience=20)\r\n    history = DNN.fit(\r\n        x=x_train,\r\n        y=y_train,\r\n        shuffle=True,\r\n        epochs = 200,\r\n        batch_size = batch_size,\r\n        validation_data=[x_valid,y_valid],\r\n        callbacks = [es],\r\n        verbose=0)\r\n\r\n    DNN.save_weights('C:/Users/euijin/Documents/DNN_Models_Revision/DNN_FUL_'+str(i))\r\n    #DNN.load_weights('C:/Users/euijin/Documents/DNN_Models/DNN_FUL_'+str(i))\r\n\r\n\r\n\r\n    # Get the prediction metrics\r\n    test_p = DNN.predict(x_test,verbose=0)\r\n    train_p = DNN.predict(x_train,verbose=0)\r\n\r\n    predict_train = np.argmax(train_p[0],axis=1)\r\n    predict_test =  np.argmax(test_p[0],axis=1)\r\n\r\n    y_train = np.array(df_train.CHOICE).reshape(-1,3)\r\n    y_test = np.array(df_test.CHOICE).reshape(-1,3)\r\n    y_train_cat = np.argmax(np.array(df_train.CHOICE).reshape(-1,3),axis=1)\r\n    y_test_cat = np.argmax(np.array(df_test.CHOICE).reshape(-1,3),axis=1)\r\n\r\n    train_acc = round(accuracy_score(y_train_cat,predict_train),3)\r\n    test_acc = round(accuracy_score(y_test_cat,predict_test),3)\r\n\r\n    train_brier = round(brier_multi(y_train,train_p[0]),3)\r\n    test_brier = round(brier_multi(y_test,test_p[0]),3)\r\n\r\n    print([train_acc,test_acc,train_brier,test_brier])\r\n\r\n\r\n    ## Plot the PD and ICE\r\n    from sklearn.inspection import partial_dependence\r\n    from sklearn.inspection import PartialDependenceDisplay\r\n    import matplotlib.pyplot as plt\r\n\r\n    class DNNFunction(BaseEstimator, ClassifierMixin):\r\n        def fit(self, X, y):\r\n            self.classes_ = unique_labels(y)\r\n            return self\r\n\r\n        def predict_proba(self, X):\r\n            self.proba_,_,_,_ = DNN.predict(X,verbose=0)\r\n            return np.array(self.proba_)\r\n\r\n        def decision_function(self, X):\r\n            self.utility_ = np.array(DNN.predict(X)[1:4]).transpose().reshape(-1,3)\r\n            return self.utility_\r\n\r\n    DNN_ALL = DNNFunction()\r\n    DNN_ALL.fit(x_train,y_train)\r\n\r\n    common_params = {\r\n        \"subsample\": 0.99999,\r\n        \"n_jobs\": 1,\r\n        \"grid_resolution\": 20,\r\n        \"centered\": True,\r\n        \"random_state\": 1,\r\n        \"response_method\": 'decision_function',\r\n        \"percentiles\": (0.01, 0.99),\r\n\r\n    }\r\n\r\n    fig,ax = plt.subplots(nrows=1,ncols=2, figsize=(12,6),sharex=False,sharey=True)\r\n\r\n    display_0 = PartialDependenceDisplay.from_estimator(\r\n        DNN_ALL,\r\n        x_train,\r\n        features=['TRAIN_TT','TRAIN_TC'], # TC,TT\r\n        kind=[\"both\",\"both\"],\r\n        ice_lines_kw={\"color\": \"gray\",'alpha':0.3},pd_line_kw={\"color\": \"black\",\"lw\":3,'linestyle':'solid','label':'True'},\r\n        ax=ax,\r\n        target = 0,\r\n        **common_params,\r\n    )\r\n\r\n    fig,ax = plt.subplots(nrows=1,ncols=2, figsize=(12,6),sharex=False,sharey=True)\r\n\r\n    display_1 = PartialDependenceDisplay.from_estimator(\r\n        DNN_ALL,\r\n        x_train,\r\n        features=['SM_TT','SM_TC'], # TC,TT\r\n        kind=[\"both\",\"both\"],\r\n        ice_lines_kw={\"color\": \"gray\",'alpha':0.3},pd_line_kw={\"color\": \"black\",\"lw\":3,'linestyle':'solid','label':'True'},\r\n        ax=ax,\r\n        target = 1,\r\n        **common_params,\r\n    )\r\n\r\n    fig,ax = plt.subplots(nrows=1,ncols=2, figsize=(12,6),sharex=False,sharey=True)\r\n\r\n    display_2 = PartialDependenceDisplay.from_estimator(\r\n        DNN_ALL,\r\n        x_train,\r\n        features=['CAR_TT','CAR_TC'], # TC,TT\r\n        kind=[\"both\",\"both\"],\r\n        ice_lines_kw={\"color\": \"gray\",'alpha':0.3},pd_line_kw={\"color\": \"black\",\"lw\":3,'linestyle':'solid','label':'True'},\r\n        ax=ax,\r\n        target = 2,\r\n        **common_params,\r\n    )\r\n\r\n\r\n\r\n    ## Population-level Parameters\r\n\r\n    PD_DNN_TT_TR = display_0.pd_results[0]['average'][0]\r\n    PD_DNN_TC_TR = display_0.pd_results[1]['average'][0] \r\n\r\n    PD_DNN_TT_SM = display_1.pd_results[0]['average'][1]\r\n    PD_DNN_TC_SM = display_1.pd_results[1]['average'][1] \r\n\r\n    PD_DNN_TT_CAR = display_2.pd_results[0]['average'][2]\r\n    PD_DNN_TC_CAR = display_2.pd_results[1]['average'][2] \r\n\r\n    PD_values_TT_TR = display_0.pd_results[0]['values'][0]\r\n    PD_values_TC_TR = display_0.pd_results[1]['values'][0]\r\n\r\n    PD_values_TT_SM = display_1.pd_results[0]['values'][0]\r\n    PD_values_TC_SM = display_1.pd_results[1]['values'][0]\r\n\r\n    PD_values_TT_CAR = display_2.pd_results[0]['values'][0]\r\n    PD_values_TC_CAR = display_2.pd_results[1]['values'][0]\r\n\r\n    beta_DNN_TT_TR = (np.diff(PD_DNN_TT_TR)/np.diff(PD_values_TT_TR))\r\n    beta_DNN_TC_TR = (np.diff(PD_DNN_TC_TR)/np.diff(PD_values_TC_TR))\r\n\r\n    beta_DNN_TT_SM = (np.diff(PD_DNN_TT_SM)/np.diff(PD_values_TT_SM))\r\n    beta_DNN_TC_SM = (np.diff(PD_DNN_TC_SM)/np.diff(PD_values_TC_SM))\r\n\r\n    beta_DNN_TT_CAR = (np.diff(PD_DNN_TT_CAR)/np.diff(PD_values_TT_CAR))\r\n    beta_DNN_TC_CAR = (np.diff(PD_DNN_TC_CAR)/np.diff(PD_values_TC_CAR))\r\n\r\n\r\n    TC_TR_IDX =(beta_DNN_TC_TR != 0)\r\n    TC_SM_IDX =(beta_DNN_TC_SM != 0)\r\n    TC_CAR_IDX =(beta_DNN_TC_CAR != 0)\r\n\r\n    beta_DNN_TC_TR = beta_DNN_TC_TR[TC_TR_IDX]\r\n    beta_DNN_TC_SM = beta_DNN_TC_SM[TC_SM_IDX]\r\n    beta_DNN_TC_CAR = beta_DNN_TC_CAR[TC_CAR_IDX]\r\n\r\n    beta_DNN_TT_TR = beta_DNN_TT_TR[TC_TR_IDX]\r\n    beta_DNN_TT_SM = beta_DNN_TT_SM[TC_SM_IDX]\r\n    beta_DNN_TT_CAR = beta_DNN_TT_CAR[TC_CAR_IDX]\r\n\r\n\r\n    beta_DNN_VOT_POP_TR = np.median(compute_VOT_POP(beta_DNN_TT_TR,beta_DNN_TC_TR))\r\n    beta_DNN_VOT_POP_SM = np.median(compute_VOT_POP(beta_DNN_TT_SM,beta_DNN_TC_SM))\r\n    beta_DNN_VOT_POP_CAR = np.median(compute_VOT_POP(beta_DNN_TT_CAR,beta_DNN_TC_CAR))\r\n\r\n\r\n    ## Individual-level Parameters\r\n\r\n    ICE_DNN_TT_TR = display_0.pd_results[0]['individual'][0]\r\n    ICE_DNN_TC_TR = display_0.pd_results[1]['individual'][0]\r\n\r\n    ICE_DNN_TT_SM = display_1.pd_results[0]['individual'][1]\r\n    ICE_DNN_TC_SM = display_1.pd_results[1]['individual'][1]\r\n\r\n    ICE_DNN_TT_CAR = display_2.pd_results[0]['individual'][2]\r\n    ICE_DNN_TC_CAR = display_2.pd_results[1]['individual'][2]\r\n\r\n    beta_DNN_TT_TR_ICE = (np.diff(ICE_DNN_TT_TR)/np.diff(PD_values_TT_TR))\r\n    beta_DNN_TC_TR_ICE = (np.diff(ICE_DNN_TC_TR)/np.diff(PD_values_TC_TR))\r\n    beta_DNN_VOT_TR_ICE = compute_VOT_IND(beta_DNN_TT_TR_ICE[:,TC_TR_IDX],beta_DNN_TC_TR_ICE[:,TC_TR_IDX])\r\n\r\n    beta_DNN_TT_SM_ICE = (np.diff(ICE_DNN_TT_SM)/np.diff(PD_values_TT_SM))\r\n    beta_DNN_TC_SM_ICE = (np.diff(ICE_DNN_TC_SM)/np.diff(PD_values_TC_SM))\r\n    beta_DNN_VOT_SM_ICE = compute_VOT_IND(beta_DNN_TT_SM_ICE[:,TC_SM_IDX],beta_DNN_TC_SM_ICE[:,TC_SM_IDX])\r\n\r\n\r\n    beta_DNN_TT_CAR_ICE = (np.diff(ICE_DNN_TT_CAR)/np.diff(PD_values_TT_CAR))\r\n    beta_DNN_TC_CAR_ICE = (np.diff(ICE_DNN_TC_CAR)/np.diff(PD_values_TC_CAR))\r\n    beta_DNN_VOT_CAR_ICE = compute_VOT_IND(beta_DNN_TT_CAR_ICE[:,TC_CAR_IDX],beta_DNN_TC_CAR_ICE[:,TC_CAR_IDX])\r\n\r\n\r\n    # Estimation # If we use the median value, we don't need to care about the outlier or somethings.\r\n\r\n    x_test_E = x_train[['AGES','INCOMES','PURPOSES']].reset_index(drop=True)\r\n    x_test_E['VOT_TR'] = beta_DNN_VOT_TR_ICE\r\n    x_test_E['VOT_SM'] = beta_DNN_VOT_SM_ICE\r\n    x_test_E['VOT_CAR'] = beta_DNN_VOT_CAR_ICE\r\n\r\n    VOT_DNN_IND = x_test_E[['AGES','INCOMES','PURPOSES','VOT_TR','VOT_SM','VOT_CAR']].groupby(['AGES','INCOMES','PURPOSES']).median()\r\n\r\n\r\n    print(np.quantile(VOT_DNN_IND['VOT_TR'],(0.5,0.01,0.25,0.75,0.99)).round(3))\r\n    print(np.quantile(VOT_DNN_IND['VOT_SM'],(0.5,0.01,0.25,0.75,0.99)).round(3))\r\n    print(np.quantile(VOT_DNN_IND['VOT_CAR'],(0.5,0.01,0.25,0.75,0.99)).round(3))\r\n\r\n\r\n    # Estimation results\r\n    PRED_PERF = np.array([train_acc,test_acc,train_brier,test_brier]).transpose()\r\n    EST_RESULTS = [PRED_PERF,VOT_DNN_IND]\r\n    with open(\"C:/Users/euijin/Documents/DNN_Results_Revision/FUL_RESULTS_FF_\"+str(i), \"wb\") as f:\r\n        pickle.dump(EST_RESULTS, f)\r\n    #save_clipboard(np.concatenate([PRED_PERF,VOT_DNN_IND.median(axis=0).round(3)])) \r\n\r\n\r\n# In[ ]:\r\n\r\n\r\nimport scipy.stats as stats\r\n## Results analysis\r\nPRED_PERF_S = []\r\nVOT_DNN_IND_S = []\r\nVOT_DNN_index = []\r\n\r\nfor i in range(1):\r\n    with open(\"C:/Users/euijin/Documents/DNN_Results_Revision/FUL_RESULTS_FF_\"+str(i),'rb') as f:\r\n        temp = pickle.load(f)\r\n    PRED_PERF_S.append(temp[0])\r\n    VOT_DNN_IND_S.append(temp[1])\r\n    VOT_DNN_index.append(temp[1].index.values)\r\n    \r\n\r\n## Predictability    \r\nPRED_PERF_S = np.array(PRED_PERF_S)\r\nA = np.concatenate([PRED_PERF_S.mean(axis=0).round(3).reshape(-1,1),PRED_PERF_S.std(axis=0).round(3).reshape(-1,1)],axis=1)\r\n\r\n\r\n## Interpretability\r\nIND_stats = []\r\nVOT_DNN_IND_S_TR = []\r\nVOT_DNN_IND_S_SM = []\r\nVOT_DNN_IND_S_CAR = []\r\n\r\nfor i in range(len(VOT_DNN_IND_S)):\r\n    \r\n    inter_IDX_IND = VOT_DNN_IND_S[i].index.isin(np.intersect1d(VOT_DNN_IND_S[i].index,df_VOT_B.index))\r\n        \r\n    TRIND = np.quantile(VOT_DNN_IND_S[i].iloc[inter_IDX_IND,0],(0.5,0.01,0.25,0.75,0.99)).round(3)\r\n    SMIND = np.quantile(VOT_DNN_IND_S[i].iloc[inter_IDX_IND,1],(0.5,0.01,0.25,0.75,0.99)).round(3)\r\n    CARIND = np.quantile(VOT_DNN_IND_S[i].iloc[inter_IDX_IND,2],(0.5,0.01,0.25,0.75,0.99)).round(3)   \r\n    ALLIND = np.concatenate([TRIND,SMIND,CARIND])   \r\n    IND_stats.append(ALLIND)\r\n    \r\n    VOT_DNN_IND_S_TR.append(VOT_DNN_IND_S[i].iloc[inter_IDX_IND,0])\r\n    VOT_DNN_IND_S_SM.append(VOT_DNN_IND_S[i].iloc[inter_IDX_IND,1])\r\n    VOT_DNN_IND_S_CAR.append(VOT_DNN_IND_S[i].iloc[inter_IDX_IND,2])\r\n      \r\nB = np.array(IND_stats)\r\nB = np.concatenate([np.median(B,axis=0).round(3).reshape(-1,1),\r\n                    stats.iqr(B,axis=0).round(3).reshape(-1,1)],axis=1)\r\n\r\n\r\nVOT_DNN_IND_S_TR = np.concatenate(VOT_DNN_IND_S_TR)\r\nVOT_DNN_IND_S_SM = np.concatenate(VOT_DNN_IND_S_SM)\r\nVOT_DNN_IND_S_CAR = np.concatenate(VOT_DNN_IND_S_CAR)\r\n\r\nEST_RESULTS_DNN = np.vstack([B,A])\r\nsave_clipboard(EST_RESULTS_DNN)\r\n\r\n\r\n# ## 4. TCNN\r\n\r\n# In[ ]:\r\n\r\n\r\n## 2. BCDNN\r\n\r\nx_train = df_wide_train[[\r\n    'TRAIN_TT','TRAIN_TC','TRAIN_HE',\r\n    'SM_TT','SM_TC','SM_HE','SM_SEATS',\r\n    'CAR_TT', 'CAR_TC','GA','AGES','INCOMES','PURPOSES']]\r\n\r\ny_train = np.array(pd.get_dummies(df_wide_train['CHOICE']))\r\n\r\n\r\nx_test = df_wide_test[[\r\n    'TRAIN_TT','TRAIN_TC','TRAIN_HE',\r\n    'SM_TT','SM_TC','SM_HE','SM_SEATS',\r\n    'CAR_TT', 'CAR_TC','GA','AGES','INCOMES','PURPOSES']]\r\n\r\ny_test = np.array(pd.get_dummies(df_wide_test['CHOICE']))\r\n\r\nx_valid = df_wide_valid[[\r\n    'TRAIN_TT','TRAIN_TC','TRAIN_HE',\r\n    'SM_TT','SM_TC','SM_HE','SM_SEATS',\r\n    'CAR_TT', 'CAR_TC','GA','AGES','INCOMES','PURPOSES']]\r\n\r\ny_valid = np.array(pd.get_dummies(df_wide_valid['CHOICE']))\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\n## Hyperparameters of Lattice Networks\r\n\r\ndef build_LatDNN(TRAIN_TT_KP,TRAIN_TT_LS,TRAIN_TC_KP,TRAIN_TC_LS,TRAIN_HE_KP,TRAIN_HE_LS,SM_TT_KP,SM_TT_LS,SM_TC_KP,SM_TC_LS,SM_HE_KP,SM_HE_LS,\r\n                 CAR_TT_KP,CAR_TT_LS,CAR_TC_KP,CAR_TC_LS,SM_SEATS_LS,GA_LS,AGE_LS,INCOME_LS,PURPOSE_LS,ACT_TR,ACT_SM,ACT_CAR):\r\n    \r\n    non_split_input = Input(shape=x_train.shape[1], name='non_split_input',dtype='float32')\r\n    \r\n    # Alternative-specific Lattice inputs\r\n    lattice_inputs_TR = []\r\n    lattice_inputs_SM = []\r\n    lattice_inputs_CAR = []\r\n    \r\n    # TRAIN_TT\r\n    TRAIN_TT_input = tf.reshape(non_split_input[:,0],(-1,1))\r\n    \r\n    ## TRAIN_TT to TR\r\n    TRAIN_TT_TR_calibrator = tfl.layers.PWLCalibration(\r\n    input_keypoints=np.linspace(\r\n        x_train['TRAIN_TT'].min(), x_train['TRAIN_TT'].max(), num=TRAIN_TT_KP),\r\n    dtype=tf.float32,\r\n    output_min=0.0,\r\n    output_max=TRAIN_TT_LS - 1.0,\r\n    kernel_regularizer=[(\"wrinkle\", 0.0, 0.5),('hessian', 0.0, 0.0001)],\r\n    monotonicity='decreasing', ## Sign constraints \r\n    name='TRAIN_TT_TR_Calib',\r\n    )(TRAIN_TT_input)\r\n\r\n    ## TRAIN_TT to Others\r\n    TRAIN_TT_OTH_calibrator = tfl.layers.PWLCalibration(\r\n    input_keypoints=np.linspace(\r\n        x_train['TRAIN_TT'].min(), x_train['TRAIN_TT'].max(), num=TRAIN_TT_KP),\r\n    dtype=tf.float32,\r\n    output_min=0.0,\r\n    output_max=TRAIN_TT_LS - 1.0,\r\n    kernel_regularizer=[(\"wrinkle\", 0.0, 0.5),('hessian', 0.0, 0.0001)],\r\n    monotonicity='increasing',\r\n    name='TRAIN_TT_OTH_Calib',\r\n    )(TRAIN_TT_input)\r\n   \r\n\r\n    lattice_inputs_TR.append(TRAIN_TT_TR_calibrator)\r\n    # lattice_inputs_SM.append(TRAIN_TT_OTH_calibrator)\r\n    # lattice_inputs_CAR.append(TRAIN_TT_OTH_calibrator)      \r\n    \r\n    \r\n    # TRAIN_TC\r\n    TRAIN_TC_input = tf.reshape(non_split_input[:,1],(-1,1))\r\n    \r\n    ## TRAIN_TC to TR\r\n    TRAIN_TC_TR_calibrator = tfl.layers.PWLCalibration(\r\n    input_keypoints=np.linspace(\r\n        x_train['TRAIN_TC'].min(), x_train['TRAIN_TC'].max(), num=TRAIN_TC_KP),\r\n    dtype=tf.float32,\r\n    output_min=0.0,\r\n    output_max=TRAIN_TC_LS - 1.0,\r\n    kernel_regularizer=[(\"wrinkle\", 0.0, 0.5),('hessian', 0.0, 0.0001)],\r\n    monotonicity='decreasing', ## Sign constraints \r\n    name='TRAIN_TC_TR_Calib',\r\n    )(TRAIN_TC_input)\r\n\r\n\r\n    ## TRAIN_TC to Others\r\n    TRAIN_TC_OTH_calibrator = tfl.layers.PWLCalibration(\r\n    input_keypoints=np.linspace(\r\n        x_train['TRAIN_TC'].min(), x_train['TRAIN_TC'].max(), num=TRAIN_TC_KP),\r\n    dtype=tf.float32,\r\n    output_min=0.0,\r\n    output_max=TRAIN_TC_LS - 1.0,\r\n    kernel_regularizer=[(\"wrinkle\", 0.0, 0.5),('hessian', 0.0, 0.0001)],\r\n    monotonicity='increasing',\r\n    name='TRAIN_TC_OTH_Calib',\r\n    )(TRAIN_TC_input)\r\n    \r\n    lattice_inputs_TR.append(TRAIN_TC_TR_calibrator)\r\n    # lattice_inputs_SM.append(TRAIN_TC_OTH_calibrator)\r\n    # lattice_inputs_CAR.append(TRAIN_TC_OTH_calibrator)\r\n    \r\n    \r\n        \r\n    # TRAIN_HE\r\n    TRAIN_HE_input = tf.reshape(non_split_input[:,2],(-1,1))\r\n    \r\n    ## TRAIN_HE to TR\r\n    TRAIN_HE_TR_calibrator = tfl.layers.PWLCalibration(\r\n    input_keypoints=np.linspace(\r\n        x_train['TRAIN_HE'].min(), x_train['TRAIN_HE'].max(), num=TRAIN_HE_KP),\r\n    dtype=tf.float32,\r\n    output_min=0.0,\r\n    output_max=TRAIN_HE_LS - 1.0,\r\n    kernel_regularizer=[(\"wrinkle\", 0.0, 0.5),('hessian', 0.0, 0.0001)],\r\n    monotonicity='decreasing', ## Sign constraints \r\n    name='TRAIN_HE_TR_Calib',\r\n    )(TRAIN_HE_input)\r\n\r\n\r\n    ## TRAIN_HE to Others\r\n    TRAIN_HE_OTH_calibrator = tfl.layers.PWLCalibration(\r\n    input_keypoints=np.linspace(\r\n        x_train['TRAIN_HE'].min(), x_train['TRAIN_HE'].max(), num=TRAIN_HE_KP),\r\n    dtype=tf.float32,\r\n    output_min=0.0,\r\n    output_max=TRAIN_HE_LS - 1.0,\r\n    kernel_regularizer=[(\"wrinkle\", 0.0, 0.5),('hessian', 0.0, 0.0001)],\r\n    monotonicity='increasing', ## Sign constraints \r\n    name='TRAIN_HE_OTH_Calib',\r\n    )(TRAIN_HE_input)\r\n   \r\n    lattice_inputs_TR.append(TRAIN_HE_TR_calibrator)\r\n    # lattice_inputs_SM.append(TRAIN_HE_OTH_calibrator)\r\n    # lattice_inputs_CAR.append(TRAIN_HE_OTH_calibrator)\r\n    \r\n    \r\n    \r\n    \r\n    # Swissmetro_TT\r\n    SM_TT_input = tf.reshape(non_split_input[:,3],(-1,1))\r\n    \r\n    ## SM_TT to SM\r\n    SM_TT_SM_calibrator = tfl.layers.PWLCalibration(\r\n    input_keypoints=np.linspace(\r\n        x_train['SM_TT'].min(), x_train['SM_TT'].max(), num=SM_TT_KP),\r\n    dtype=tf.float32,\r\n    output_min=0.0,\r\n    output_max=SM_TT_LS - 1.0,\r\n    kernel_regularizer=[(\"wrinkle\", 0.0, 0.5),('hessian', 0.0, 0.0001)],\r\n    monotonicity='decreasing', ## Sign constraints \r\n    name='SM_TT_SM_Calib',\r\n    )(SM_TT_input)\r\n\r\n    ## SM_TT to Others\r\n    SM_TT_OTH_calibrator = tfl.layers.PWLCalibration(\r\n    input_keypoints=np.linspace(\r\n        x_train['SM_TT'].min(), x_train['SM_TT'].max(), num=SM_TT_KP),\r\n    dtype=tf.float32,\r\n    output_min=0.0,\r\n    output_max=SM_TT_LS - 1.0,\r\n    kernel_regularizer=[(\"wrinkle\", 0.0, 0.5),('hessian', 0.0, 0.0001)],\r\n    monotonicity='increasing', ## Sign constraints \r\n    name='SM_TT_OTH_Calib',\r\n    )(SM_TT_input)\r\n    lattice_inputs_SM.append(SM_TT_SM_calibrator)\r\n    # lattice_inputs_TR.append(SM_TT_OTH_calibrator)\r\n    # lattice_inputs_CAR.append(SM_TT_OTH_calibrator)\r\n    \r\n    \r\n    # Swissmetro_TC\r\n    SM_TC_input = tf.reshape(non_split_input[:,4],(-1,1))\r\n    \r\n    ## SM_TC to SM\r\n    SM_TC_SM_calibrator = tfl.layers.PWLCalibration(\r\n    input_keypoints=np.linspace(\r\n        x_train['SM_TC'].min(), x_train['SM_TC'].max(), num=SM_TC_KP),\r\n    dtype=tf.float32,\r\n    output_min=0.0,\r\n    output_max=SM_TC_LS - 1.0,\r\n    kernel_regularizer=[(\"wrinkle\", 0.0, 0.5),('hessian', 0.0, 0.0001)],\r\n    monotonicity='decreasing', ## Sign constraints \r\n    name='SM_TC_SM_Calib',\r\n    )(SM_TC_input)\r\n\r\n    ## SM_TC to Others\r\n    SM_TC_OTH_calibrator = tfl.layers.PWLCalibration(\r\n    input_keypoints=np.linspace(\r\n        x_train['SM_TC'].min(), x_train['SM_TC'].max(), num=SM_TC_KP),\r\n    dtype=tf.float32,\r\n    output_min=0.0,\r\n    output_max=SM_TC_LS - 1.0,\r\n    kernel_regularizer=[(\"wrinkle\", 0.0, 0.5),('hessian', 0.0, 0.0001)],\r\n    monotonicity='increasing', ## Sign constraints \r\n    name='SM_TC_OTH_Calib',\r\n    )(SM_TC_input)\r\n\r\n    lattice_inputs_SM.append(SM_TC_SM_calibrator)\r\n    # lattice_inputs_TR.append(SM_TC_OTH_calibrator)\r\n    # lattice_inputs_CAR.append(SM_TC_OTH_calibrator)\r\n    \r\n  \r\n\r\n    # Swissmetro_HE\r\n    SM_HE_input = tf.reshape(non_split_input[:,5],(-1,1))\r\n    \r\n    ## SM_HE to SM\r\n    SM_HE_SM_calibrator = tfl.layers.PWLCalibration(\r\n    input_keypoints=np.linspace(\r\n        x_train['SM_HE'].min(), x_train['SM_HE'].max(), num=SM_HE_KP),\r\n    dtype=tf.float32,\r\n    output_min=0.0,\r\n    output_max=SM_HE_LS - 1.0,\r\n    kernel_regularizer=[(\"wrinkle\", 0.0, 0.5),('hessian', 0.0, 0.0001)],\r\n    monotonicity='decreasing', ## Sign constraints \r\n    name='SM_HE_SM_Calib',\r\n    )(SM_HE_input)\r\n\r\n    ## SM_HE to Others\r\n    SM_HE_OTH_calibrator = tfl.layers.PWLCalibration(\r\n    input_keypoints=np.linspace(\r\n        x_train['SM_HE'].min(), x_train['SM_HE'].max(), num=SM_HE_KP),\r\n    dtype=tf.float32,\r\n    output_min=0.0,\r\n    output_max=SM_HE_LS - 1.0,\r\n    kernel_regularizer=[(\"wrinkle\", 0.0, 0.5),('hessian', 0.0, 0.0001)],\r\n    monotonicity='increasing', ## Sign constraints \r\n    name='SM_HE_OTH_Calib',\r\n    )(SM_HE_input)\r\n\r\n    lattice_inputs_SM.append(SM_HE_SM_calibrator)\r\n    # lattice_inputs_TR.append(SM_HE_OTH_calibrator)\r\n    # lattice_inputs_CAR.append(SM_HE_OTH_calibrator)\r\n    \r\n    \r\n    \r\n    \r\n    # CAR_TT\r\n    CAR_TT_input = tf.reshape(non_split_input[:,7],(-1,1))\r\n    \r\n    ## CAR_TT to CAR\r\n    CAR_TT_CAR_calibrator = tfl.layers.PWLCalibration(\r\n    input_keypoints=np.linspace(\r\n        x_train['CAR_TT'].min(), x_train['CAR_TT'].max(), num=CAR_TT_KP),\r\n    dtype=tf.float32,\r\n    output_min=0.0,\r\n    output_max=CAR_TT_LS - 1.0,\r\n    kernel_regularizer=[(\"wrinkle\", 0.0, 0.5),('hessian', 0.0, 0.0001)],\r\n    monotonicity='decreasing', ## Sign constraints \r\n    name='CAR_TT_CAR_Calib',\r\n    )(CAR_TT_input)\r\n\r\n    ## CAR_TT to Others\r\n    CAR_TT_OTH_calibrator = tfl.layers.PWLCalibration(\r\n    input_keypoints=np.linspace(\r\n        x_train['CAR_TT'].min(), x_train['CAR_TT'].max(), num=CAR_TT_KP),\r\n    dtype=tf.float32,\r\n    output_min=0.0,\r\n    output_max=CAR_TT_LS - 1.0,\r\n    kernel_regularizer=[(\"wrinkle\", 0.0, 0.5),('hessian', 0.0, 0.0001)],\r\n    monotonicity='increasing', ## Sign constraints \r\n    name='CAR_TT_OTH_Calib',\r\n    )(CAR_TT_input)\r\n    lattice_inputs_CAR.append(CAR_TT_CAR_calibrator)\r\n    # lattice_inputs_TR.append(CAR_TT_OTH_calibrator)\r\n    # lattice_inputs_SM.append(CAR_TT_OTH_calibrator)\r\n    \r\n    \r\n    # CAR_TC\r\n    CAR_TC_input = tf.reshape(non_split_input[:,8],(-1,1))\r\n    \r\n    ## CAR_TC to CAR\r\n    CAR_TC_CAR_calibrator = tfl.layers.PWLCalibration(\r\n    input_keypoints=np.linspace(\r\n        x_train['CAR_TC'].min(), x_train['CAR_TC'].max(), num=CAR_TC_KP),\r\n    dtype=tf.float32,\r\n    output_min=0.0,\r\n    output_max=CAR_TC_LS - 1.0,\r\n    kernel_regularizer=[(\"wrinkle\", 0.0, 0.5),('hessian', 0.0, 0.0001)],\r\n    monotonicity='decreasing', ## Sign constraints \r\n    name='CAR_TC_CAR_Calib',\r\n    )(CAR_TC_input)\r\n\r\n    ## CAR_TC to Others\r\n    CAR_TC_OTH_calibrator = tfl.layers.PWLCalibration(\r\n    input_keypoints=np.linspace(\r\n        x_train['CAR_TC'].min(), x_train['CAR_TC'].max(), num=CAR_TC_KP),\r\n    dtype=tf.float32,\r\n    output_min=0.0,\r\n    output_max=CAR_TC_LS - 1.0,\r\n    kernel_regularizer=[(\"wrinkle\", 0.0, 0.5),('hessian', 0.0, 0.0001)],\r\n    monotonicity='increasing', ## Sign constraints \r\n    name='CAR_TC_OTH_Calib',\r\n    )(CAR_TC_input)\r\n    lattice_inputs_CAR.append(CAR_TC_CAR_calibrator)\r\n    # lattice_inputs_TR.append(CAR_TC_OTH_calibrator)\r\n    # lattice_inputs_SM.append(CAR_TC_OTH_calibrator)\r\n       \r\n       \r\n    \r\n    \r\n    ## Non-monotonic attributes\r\n    \r\n    ## SM_SEATS\r\n    SM_SEATS_input = tf.reshape(non_split_input[:,6],(-1,1))\r\n    SM_SEATS_calibrator = tfl.layers.CategoricalCalibration(\r\n        num_buckets=2,\r\n        output_min=0.0,\r\n        output_max=SM_SEATS_LS - 1.0,\r\n        name='SM_SEATS_calib',\r\n    )(SM_SEATS_input)\r\n    lattice_inputs_CAR.append(SM_SEATS_calibrator)\r\n    lattice_inputs_TR.append(SM_SEATS_calibrator)\r\n    lattice_inputs_SM.append(SM_SEATS_calibrator)\r\n\r\n    ## GA\r\n    GA_input = tf.reshape(non_split_input[:,9],(-1,1))\r\n    GA_calibrator = tfl.layers.CategoricalCalibration(\r\n        num_buckets=2,\r\n        output_min=0.0,\r\n        output_max=GA_LS - 1.0,\r\n        name='GA_SM_calib',\r\n    )(GA_input)\r\n    lattice_inputs_CAR.append(GA_calibrator)\r\n    lattice_inputs_TR.append(GA_calibrator)\r\n    lattice_inputs_SM.append(GA_calibrator)\r\n    \r\n    ## AGE\r\n    AGE_input = tf.reshape(non_split_input[:,10],(-1,1))\r\n    AGE_calibrator = tfl.layers.CategoricalCalibration(\r\n        num_buckets=5,\r\n        output_min=0.0,\r\n        output_max=AGE_LS - 1.0,\r\n        name='AGE_SM_calib',\r\n    )(AGE_input)\r\n    lattice_inputs_CAR.append(AGE_calibrator)\r\n    lattice_inputs_TR.append(AGE_calibrator)\r\n    lattice_inputs_SM.append(AGE_calibrator)\r\n\r\n    ## INCOME\r\n    INCOME_input = tf.reshape(non_split_input[:,11],(-1,1))\r\n    INCOME_calibrator = tfl.layers.CategoricalCalibration(\r\n        num_buckets=3,\r\n        output_min=0.0,\r\n        output_max=INCOME_LS - 1.0,\r\n        name='INCOME_calib',\r\n    )(INCOME_input)\r\n    lattice_inputs_CAR.append(INCOME_calibrator)\r\n    lattice_inputs_TR.append(INCOME_calibrator)\r\n    lattice_inputs_SM.append(INCOME_calibrator)\r\n    \r\n    \r\n    ## PURPOSE\r\n    PURPOSE_input = tf.reshape(non_split_input[:,12],(-1,1))\r\n    PURPOSE_calibrator = tfl.layers.CategoricalCalibration(\r\n        num_buckets=4,\r\n        output_min=0.0,\r\n        output_max=PURPOSE_LS - 1.0,\r\n        name='PURPOSE_calib',\r\n    )(PURPOSE_input)\r\n    lattice_inputs_CAR.append(PURPOSE_calibrator)\r\n    lattice_inputs_TR.append(PURPOSE_calibrator)\r\n    lattice_inputs_SM.append(PURPOSE_calibrator)   \r\n    \r\n\r\n    ### Non-lienarly fuse the outputs of calibrator\r\n    util_ALT1 = tfl.layers.Lattice(   \r\n    lattice_sizes=[TRAIN_TT_LS,TRAIN_TC_LS,TRAIN_HE_LS,\r\n                   SM_SEATS_LS,GA_LS,AGE_LS,INCOME_LS,PURPOSE_LS],\r\n    monotonicities=[\r\n        'increasing', 'increasing','increasing',\r\n        'none','none','none','none','none'],\r\n\r\n    output_min=0,\r\n    output_max=1,\r\n    # output_min=-100,\r\n    # output_max=100,\r\n    name='lattice_TR',\r\n    )(lattice_inputs_TR)\r\n    \r\n    \r\n    ### Non-lienarly fuse the outputs of calibrator\r\n    util_ALT2 = tfl.layers.Lattice(   \r\n    lattice_sizes=[SM_TT_LS,SM_TC_LS,SM_HE_LS,\r\n                   SM_SEATS_LS,GA_LS,AGE_LS,INCOME_LS,PURPOSE_LS],\r\n    monotonicities=[\r\n        'increasing', 'increasing','increasing',\r\n        'none','none','none','none','none'],\r\n\r\n    output_min=0,\r\n    output_max=1,\r\n    # output_min=-100,\r\n    # output_max=100,\r\n    name='lattice_SM',\r\n    )(lattice_inputs_SM)\r\n    \r\n    ## Non-lienarly fuse the outputs of calibrator\r\n    util_ALT3= tfl.layers.Lattice(   \r\n    lattice_sizes=[CAR_TT_LS,CAR_TC_LS,\r\n                   SM_SEATS_LS,GA_LS,AGE_LS,INCOME_LS,PURPOSE_LS],\r\n    monotonicities=[\r\n        'increasing', 'increasing',\r\n        'none','none','none','none','none'],\r\n\r\n    output_min=0,\r\n    output_max=1,\r\n    # output_min=-100,\r\n    # output_max=100,\r\n    name='lattice_CAR',\r\n    )(lattice_inputs_CAR)\r\n    \r\n    ## Output PWLCalibrator is the key of improving predictability\r\n    util_ALT1 = tfl.layers.PWLCalibration(\r\n    input_keypoints=np.linspace(0.0, 1.0, ACT_TR),\r\n    output_min=-100,\r\n    output_max=100,\r\n    name='output_TR')(util_ALT1)\r\n  \r\n    util_ALT2 = tfl.layers.PWLCalibration(\r\n    input_keypoints=np.linspace(0.0, 1.0, ACT_SM),\r\n    output_min=-100,\r\n    output_max=100,\r\n    name='output_SM')(util_ALT2)\r\n    \r\n    \r\n    util_ALT3 = tfl.layers.PWLCalibration(\r\n    input_keypoints=np.linspace(0.0, 1.0, ACT_CAR),\r\n    output_min=-100,\r\n    output_max=100,\r\n    name='output_CAR')(util_ALT3)\r\n\r\n    out_prob =  tf.keras.layers.Softmax(name='out_prob')(Concatenate()([util_ALT1,util_ALT2,util_ALT3]))\r\n    \r\n    model = Model(non_split_input,[out_prob,util_ALT1,util_ALT2,util_ALT3])   \r\n\r\n    optimizer = Adam(learning_rate=learning_rate)\r\n           \r\n    model.compile(optimizer=optimizer, loss=['categorical_crossentropy',None,None,None],\r\n                  metrics=['accuracy',None,None,None])\r\n    \r\n    return model\r\n\r\nfrom sklearn.metrics import mean_absolute_error,mean_absolute_percentage_error\r\n\r\n\r\n## Repeated Experiments\r\nfor i in range(1):\r\n\r\n    TRAIN_TT_KP = 10\r\n    SM_TT_KP = 30\r\n    CAR_TT_KP = 10\r\n    \r\n    TRAIN_TC_KP = 30\r\n    SM_TC_KP = 30\r\n    CAR_TC_KP = 10\r\n    TRAIN_HE_KP = 10\r\n    SM_HE_KP = 30\r\n        \r\n    TRAIN_TT_LS = 4\r\n    SM_TT_LS = 4\r\n    CAR_TT_LS = 4\r\n    \r\n    TRAIN_TC_LS = 4\r\n    SM_TC_LS = 2\r\n    CAR_TC_LS = 4\r\n\r\n    TRAIN_HE_LS = 2   \r\n    SM_HE_LS = 2\r\n   \r\n    SM_SEATS_LS =2\r\n    GA_LS = 2\r\n    AGE_LS = 3\r\n    INCOME_LS = 2\r\n    PURPOSE_LS = 4\r\n\r\n    ACT_TR = 2\r\n    ACT_SM = 2\r\n    ACT_CAR = 2\r\n    learning_rate = 0.005 #0.0001 is very stable / 0.0005 is not BAD   \r\n\r\n    LatDNN = build_LatDNN(TRAIN_TT_KP,TRAIN_TT_LS,TRAIN_TC_KP,TRAIN_TC_LS,TRAIN_HE_KP,TRAIN_HE_LS,SM_TT_KP,SM_TT_LS,SM_TC_KP,SM_TC_LS,SM_HE_KP,SM_HE_LS,\r\n                     CAR_TT_KP,CAR_TT_LS,CAR_TC_KP,CAR_TC_LS,SM_SEATS_LS,GA_LS,AGE_LS,INCOME_LS,PURPOSE_LS,ACT_TR,ACT_SM,ACT_CAR)\r\n\r\n    batch_size = 128\r\n    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', restore_best_weights=True, verbose=1, patience=20)\r\n\r\n    history = LatDNN.fit(\r\n        x=x_train,\r\n        y=y_train,\r\n        shuffle=True,\r\n        epochs =200,\r\n        batch_size = batch_size,\r\n        validation_data = [x_valid,y_valid],\r\n        callbacks = [es],\r\n        verbose=1)\r\n\r\n    LatDNN.save_weights('C:/Users/euijin/Documents/LatDNN_Models/LatDNN_ASC_FF_SNU1_'+str(i))\r\n    #LatDNN.load_weights('C:/Users/euijin/Documents/LatDNN_Models/LatDNN_ASC_FF_SNU1_'+str(i))\r\n\r\n\r\n\r\n    # Get the prediction metrics\r\n    test_p = LatDNN.predict(x_test,verbose=0)\r\n    train_p = LatDNN.predict(x_train,verbose=0)\r\n\r\n    predict_train = np.argmax(train_p[0],axis=1)\r\n    predict_test =  np.argmax(test_p[0],axis=1)\r\n\r\n    y_train = np.array(df_train.CHOICE).reshape(-1,3)\r\n    y_test = np.array(df_test.CHOICE).reshape(-1,3)\r\n    y_train_cat = np.argmax(np.array(df_train.CHOICE).reshape(-1,3),axis=1)\r\n    y_test_cat = np.argmax(np.array(df_test.CHOICE).reshape(-1,3),axis=1)\r\n\r\n    test_NLL = round((F.cross_entropy(input=torch.log(tensor(test_p[0])),target=torch.Tensor(y_test)).numpy()).item(),3)\r\n    train_NLL =  round((F.cross_entropy(input=torch.log(tensor(train_p[0])),target=torch.Tensor(y_train)).numpy()).item(),3)\r\n\r\n    train_acc = round(accuracy_score(y_train_cat,predict_train),3)\r\n    test_acc = round(accuracy_score(y_test_cat,predict_test),3)\r\n\r\n    train_brier = round(brier_multi(y_train,train_p[0]),3)\r\n    test_brier = round(brier_multi(y_test,test_p[0]),3)\r\n\r\n    print([train_acc,test_acc,train_NLL,test_NLL,train_brier,test_brier])\r\n# In[ ]:\r\n\r\n\r\nfrom sklearn.metrics import mean_absolute_error,mean_absolute_percentage_error\r\nimport pickle\r\nimport time\r\n\r\n## Repeated Experiments\r\nfor i in range(50):\r\n\r\n    # record start time\r\n    start = time.time()\r\n\r\n    TRAIN_TT_KP = 10\r\n    SM_TT_KP = 30\r\n    CAR_TT_KP = 10\r\n\r\n    TRAIN_TC_KP = 20 # SNU2\r\n    SM_TC_KP = 10 # SNU2\r\n    CAR_TC_KP = 10\r\n    TRAIN_HE_KP = 10\r\n    SM_HE_KP = 30\r\n\r\n    TRAIN_TT_LS = 4\r\n    SM_TT_LS = 4\r\n    CAR_TT_LS = 4\r\n\r\n    TRAIN_TC_LS = 4 #\r\n    SM_TC_LS = 2\r\n    CAR_TC_LS = 4\r\n\r\n    TRAIN_HE_LS = 2   \r\n    SM_HE_LS = 2\r\n    SM_SEATS_LS =2\r\n    \r\n    GA_LS = 2\r\n    AGE_LS = 3\r\n    INCOME_LS = 2\r\n    PURPOSE_LS = 4\r\n\r\n    ACT_TR = 2\r\n    ACT_SM = 2\r\n    ACT_CAR = 2\r\n    learning_rate = 0.005 #0.0001 is very stable / 0.0005 is not BAD   \r\n    \r\n    LatDNN = build_LatDNN(TRAIN_TT_KP,TRAIN_TT_LS,TRAIN_TC_KP,TRAIN_TC_LS,TRAIN_HE_KP,TRAIN_HE_LS,SM_TT_KP,SM_TT_LS,SM_TC_KP,SM_TC_LS,SM_HE_KP,SM_HE_LS,\r\n                     CAR_TT_KP,CAR_TT_LS,CAR_TC_KP,CAR_TC_LS,SM_SEATS_LS,GA_LS,AGE_LS,INCOME_LS,PURPOSE_LS,ACT_TR,ACT_SM,ACT_CAR)\r\n\r\n    batch_size = 128\r\n    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', restore_best_weights=True, verbose=1, patience=20)\r\n\r\n    history = LatDNN.fit(\r\n        x=x_train,\r\n        y=y_train,\r\n        shuffle=True,\r\n        epochs =200,\r\n        batch_size = batch_size,\r\n        validation_data = [x_valid,y_valid],\r\n        callbacks = [es],\r\n        verbose=0)\r\n    \r\n\r\n    LatDNN.save_weights('C:/Users/euijin/Documents/LatDNN_Models_Revision/LatDNN_ASC_FF_'+str(i))\r\n    #LatDNN.load_weights('C:/Users/euijin/Documents/LatDNN_Models/LatDNN_ASC_FF_SNU2_'+str(i))\r\n    \r\n    # record end time\r\n    end = time.time()\r\n    training_time = (end-start)\r\n\r\n\r\n    # Get the prediction metrics\r\n    test_p = LatDNN.predict(x_test,verbose=0)\r\n    train_p = LatDNN.predict(x_train,verbose=0)\r\n\r\n    predict_train = np.argmax(train_p[0],axis=1)\r\n    predict_test =  np.argmax(test_p[0],axis=1)\r\n\r\n    y_train = np.array(df_train.CHOICE).reshape(-1,3)\r\n    y_test = np.array(df_test.CHOICE).reshape(-1,3)\r\n    y_train_cat = np.argmax(np.array(df_train.CHOICE).reshape(-1,3),axis=1)\r\n    y_test_cat = np.argmax(np.array(df_test.CHOICE).reshape(-1,3),axis=1)\r\n\r\n    test_NLL = round((F.cross_entropy(input=torch.log(tensor(test_p[0])),target=torch.Tensor(y_test)).numpy()).item(),3)\r\n    train_NLL =  round((F.cross_entropy(input=torch.log(tensor(train_p[0])),target=torch.Tensor(y_train)).numpy()).item(),3)\r\n\r\n    train_acc = round(accuracy_score(y_train_cat,predict_train),3)\r\n    test_acc = round(accuracy_score(y_test_cat,predict_test),3)\r\n\r\n    train_brier = round(brier_multi(y_train,train_p[0]),3)\r\n    test_brier = round(brier_multi(y_test,test_p[0]),3)\r\n\r\n    print([train_acc,test_acc,train_NLL,test_NLL,train_brier,test_brier])\r\n\r\n    ## Plot the PD and ICE\r\n    from sklearn.inspection import partial_dependence\r\n    from sklearn.inspection import PartialDependenceDisplay\r\n    import matplotlib.pyplot as plt\r\n\r\n    class LatDNNFunction(BaseEstimator, ClassifierMixin):\r\n        def fit(self, X, y):\r\n            self.classes_ = unique_labels(y)\r\n            return self\r\n\r\n        def predict_proba(self, X):\r\n            self.proba_,_,_,_ = LatDNN.predict(X,verbose=0)\r\n            return np.array(self.proba_)\r\n\r\n        def decision_function(self, X):\r\n            self.utility_ = np.array(LatDNN.predict(X)[1:4]).transpose().reshape(-1,3)\r\n            return self.utility_\r\n\r\n    LatDNN_ALL = LatDNNFunction()\r\n    LatDNN_ALL.fit(x_train,y_train)\r\n\r\n    common_params = {\r\n        \"subsample\": 0.99999,\r\n        \"n_jobs\": 1,\r\n        \"grid_resolution\": 20,\r\n        \"centered\": True,\r\n        \"random_state\": 1,\r\n        \"response_method\": 'decision_function',\r\n        \"percentiles\": (0.01, 0.99),\r\n\r\n    }\r\n\r\n    fig,ax = plt.subplots(nrows=1,ncols=2, figsize=(12,6),sharex=False,sharey=True)\r\n\r\n    display_0 = PartialDependenceDisplay.from_estimator(\r\n        LatDNN_ALL,\r\n        x_train,\r\n        features=['TRAIN_TT','TRAIN_TC'], # TC,TT\r\n        kind=[\"both\",\"both\"],\r\n        ice_lines_kw={\"color\": \"gray\",'alpha':0.3},pd_line_kw={\"color\": \"black\",\"lw\":3,'linestyle':'solid','label':'True'},\r\n        ax=ax,\r\n        target = 0,\r\n        **common_params,\r\n    )\r\n\r\n    fig,ax = plt.subplots(nrows=1,ncols=2, figsize=(12,6),sharex=False,sharey=True)\r\n\r\n    display_1 = PartialDependenceDisplay.from_estimator(\r\n        LatDNN_ALL,\r\n        x_train,\r\n        features=['SM_TT','SM_TC'], # TC,TT\r\n        kind=[\"both\",\"both\"],\r\n        ice_lines_kw={\"color\": \"gray\",'alpha':0.3},pd_line_kw={\"color\": \"black\",\"lw\":3,'linestyle':'solid','label':'True'},\r\n        ax=ax,\r\n        target = 1,\r\n        **common_params,\r\n    )\r\n\r\n    fig,ax = plt.subplots(nrows=1,ncols=2, figsize=(12,6),sharex=False,sharey=True)\r\n    \r\n    display_2 = PartialDependenceDisplay.from_estimator(\r\n        LatDNN_ALL,\r\n        x_train,\r\n        features=['CAR_TT','CAR_TC'], # TC,TT\r\n        kind=[\"both\",\"both\"],\r\n        ice_lines_kw={\"color\": \"gray\",'alpha':0.3},pd_line_kw={\"color\": \"black\",\"lw\":3,'linestyle':'solid','label':'True'},\r\n        ax=ax,\r\n        target = 2,\r\n        **common_params,\r\n    )\r\n\r\n\r\n\r\n    ## Population-level Parameters\r\n\r\n    PD_TCNN_TT_TR = display_0.pd_results[0]['average'][0]\r\n    PD_TCNN_TC_TR = display_0.pd_results[1]['average'][0] \r\n\r\n    PD_TCNN_TT_SM = display_1.pd_results[0]['average'][1]\r\n    PD_TCNN_TC_SM = display_1.pd_results[1]['average'][1] \r\n\r\n    PD_TCNN_TT_CAR = display_2.pd_results[0]['average'][2]\r\n    PD_TCNN_TC_CAR = display_2.pd_results[1]['average'][2] \r\n\r\n    PD_values_TT_TR = display_0.pd_results[0]['values'][0]\r\n    PD_values_TC_TR = display_0.pd_results[1]['values'][0]\r\n    \r\n    PD_values_TT_SM = display_1.pd_results[0]['values'][0]\r\n    PD_values_TC_SM = display_1.pd_results[1]['values'][0]\r\n    \r\n    PD_values_TT_CAR = display_2.pd_results[0]['values'][0]\r\n    PD_values_TC_CAR = display_2.pd_results[1]['values'][0]\r\n\r\n    beta_TCNN_TT_TR = (np.diff(PD_TCNN_TT_TR)/np.diff(PD_values_TT_TR))\r\n    beta_TCNN_TC_TR = (np.diff(PD_TCNN_TC_TR)/np.diff(PD_values_TC_TR))\r\n\r\n    beta_TCNN_TT_SM = (np.diff(PD_TCNN_TT_SM)/np.diff(PD_values_TT_SM))\r\n    beta_TCNN_TC_SM = (np.diff(PD_TCNN_TC_SM)/np.diff(PD_values_TC_SM))\r\n\r\n    beta_TCNN_TT_CAR = (np.diff(PD_TCNN_TT_CAR)/np.diff(PD_values_TT_CAR))\r\n    beta_TCNN_TC_CAR = (np.diff(PD_TCNN_TC_CAR)/np.diff(PD_values_TC_CAR))\r\n\r\n\r\n    TC_TR_IDX =(beta_TCNN_TC_TR != 0)\r\n    TC_SM_IDX =(beta_TCNN_TC_SM != 0)\r\n    TC_CAR_IDX =(beta_TCNN_TC_CAR != 0)\r\n\r\n    beta_TCNN_TC_TR = beta_TCNN_TC_TR[TC_TR_IDX]\r\n    beta_TCNN_TC_SM = beta_TCNN_TC_SM[TC_SM_IDX]\r\n    beta_TCNN_TC_CAR = beta_TCNN_TC_CAR[TC_CAR_IDX]\r\n    \r\n    beta_TCNN_TT_TR = beta_TCNN_TT_TR[TC_TR_IDX]\r\n    beta_TCNN_TT_SM = beta_TCNN_TT_SM[TC_SM_IDX]\r\n    beta_TCNN_TT_CAR = beta_TCNN_TT_CAR[TC_CAR_IDX]\r\n\r\n    \r\n    beta_TCNN_VOT_POP_TR = np.median(compute_VOT_POP(beta_TCNN_TT_TR,beta_TCNN_TC_TR))\r\n    beta_TCNN_VOT_POP_SM = np.median(compute_VOT_POP(beta_TCNN_TT_SM,beta_TCNN_TC_SM))\r\n    beta_TCNN_VOT_POP_CAR = np.median(compute_VOT_POP(beta_TCNN_TT_CAR,beta_TCNN_TC_CAR))\r\n\r\n\r\n    ## Individual-level Parameters\r\n\r\n    ICE_TCNN_TT_TR = display_0.pd_results[0]['individual'][0]\r\n    ICE_TCNN_TC_TR = display_0.pd_results[1]['individual'][0]\r\n\r\n    ICE_TCNN_TT_SM = display_1.pd_results[0]['individual'][1]\r\n    ICE_TCNN_TC_SM = display_1.pd_results[1]['individual'][1]\r\n\r\n    ICE_TCNN_TT_CAR = display_2.pd_results[0]['individual'][2]\r\n    ICE_TCNN_TC_CAR = display_2.pd_results[1]['individual'][2]\r\n\r\n    beta_TCNN_TT_TR_ICE = (np.diff(ICE_TCNN_TT_TR)/np.diff(PD_values_TT_TR))\r\n    beta_TCNN_TC_TR_ICE = (np.diff(ICE_TCNN_TC_TR)/np.diff(PD_values_TC_TR))\r\n    beta_TCNN_VOT_TR_ICE = compute_VOT_IND(beta_TCNN_TT_TR_ICE[:,TC_TR_IDX],beta_TCNN_TC_TR_ICE[:,TC_TR_IDX])\r\n\r\n    beta_TCNN_TT_SM_ICE = (np.diff(ICE_TCNN_TT_SM)/np.diff(PD_values_TT_SM))\r\n    beta_TCNN_TC_SM_ICE = (np.diff(ICE_TCNN_TC_SM)/np.diff(PD_values_TC_SM))\r\n    beta_TCNN_VOT_SM_ICE = compute_VOT_IND(beta_TCNN_TT_SM_ICE[:,TC_SM_IDX],beta_TCNN_TC_SM_ICE[:,TC_SM_IDX])\r\n\r\n\r\n    beta_TCNN_TT_CAR_ICE = (np.diff(ICE_TCNN_TT_CAR)/np.diff(PD_values_TT_CAR))\r\n    beta_TCNN_TC_CAR_ICE = (np.diff(ICE_TCNN_TC_CAR)/np.diff(PD_values_TC_CAR))\r\n    beta_TCNN_VOT_CAR_ICE = compute_VOT_IND(beta_TCNN_TT_CAR_ICE[:,TC_CAR_IDX],beta_TCNN_TC_CAR_ICE[:,TC_CAR_IDX])\r\n\r\n\r\n    # Estimation # If we use the median value, we don't need to care about the outlier or somethings.\r\n  \r\n    x_test_E = x_train[['AGES','INCOMES','PURPOSES']].reset_index(drop=True)\r\n    x_test_E['VOT_TR'] = beta_TCNN_VOT_TR_ICE\r\n    x_test_E['VOT_SM'] = beta_TCNN_VOT_SM_ICE\r\n    x_test_E['VOT_CAR'] = beta_TCNN_VOT_CAR_ICE\r\n\r\n    VOT_TCNN_IND = x_test_E[['AGES','INCOMES','PURPOSES','VOT_TR','VOT_SM','VOT_CAR']].groupby(['AGES','INCOMES','PURPOSES']).median()\r\n   \r\n        \r\n    print(np.quantile(VOT_TCNN_IND['VOT_TR'],(0.5,0.01,0.25,0.75,0.99)).round(3))\r\n    print(np.quantile(VOT_TCNN_IND['VOT_SM'],(0.5,0.01,0.25,0.75,0.99)).round(3))\r\n    print(np.quantile(VOT_TCNN_IND['VOT_CAR'],(0.5,0.01,0.25,0.75,0.99)).round(3))\r\n    \r\n\r\n    # Estimation results\r\n    PRED_PERF = np.array([train_acc,test_acc,train_brier,test_brier]).transpose()\r\n    EST_RESULTS = [PRED_PERF,VOT_TCNN_IND,training_time]\r\n    \r\n    \r\n    with open(\"C:/Users/euijin/Documents/LatDNN_Results_Revision/ASC_RESULTS_FF_\"+str(i), \"wb\") as f:\r\n        pickle.dump(EST_RESULTS, f)\r\n    #np.savetxt(\"C:/Users/euijin/Documents/LatDNN_Results_Revision/ASC_RESULTS_FF_\"+str(i),EST_RESULTS)\r\n    #save_clipboard(np.concatenate([PRED_PERF,VOT_TCNN_IND.median(axis=0).round(3)])) \r\n\r\n\r\n# In[ ]:\r\n\r\n\r\nimport scipy.stats as stats\r\n## Results analysis\r\nPRED_PERF_S = []\r\nVOT_TCNN_IND_S = []\r\nVOT_TCNN_index = []\r\n\r\nfor i in range(18):\r\n    with open(\"C:/Users/euijin/Documents/LatDNN_Results_Revision/ASC_RESULTS_FF_\"+str(i),'rb') as f:\r\n        temp = pickle.load(f)  \r\n    PRED_PERF_S.append(temp[0])\r\n    VOT_TCNN_IND_S.append(temp[1])\r\n    VOT_TCNN_index.append(temp[1].index.values)\r\n    \r\n\r\n## Predictability    \r\nPRED_PERF_S = np.array(PRED_PERF_S)\r\nA = np.concatenate([PRED_PERF_S.mean(axis=0).round(3).reshape(-1,1),PRED_PERF_S.std(axis=0).round(3).reshape(-1,1)],axis=1)\r\n\r\n\r\n## Interpretability\r\nIND_stats = []\r\nVOT_TCNN_IND_S_TR = []\r\nVOT_TCNN_IND_S_SM = []\r\nVOT_TCNN_IND_S_CAR = []\r\n\r\nfor i in range(len(VOT_TCNN_IND_S)):\r\n    \r\n    inter_IDX_IND = VOT_TCNN_IND_S[i].index.isin(np.intersect1d(VOT_TCNN_IND_S[i].index,df_VOT_B.index))\r\n        \r\n    TRIND = np.quantile(VOT_TCNN_IND_S[i].iloc[inter_IDX_IND,0],(0.5,0.01,0.25,0.75,0.99)).round(3)\r\n    SMIND = np.quantile(VOT_TCNN_IND_S[i].iloc[inter_IDX_IND,1],(0.5,0.01,0.25,0.75,0.99)).round(3)\r\n    CARIND = np.quantile(VOT_TCNN_IND_S[i].iloc[inter_IDX_IND,2],(0.5,0.01,0.25,0.75,0.99)).round(3)   \r\n    ALLIND = np.concatenate([TRIND,SMIND,CARIND])   \r\n    IND_stats.append(ALLIND)\r\n    \r\n    VOT_TCNN_IND_S_TR.append(VOT_TCNN_IND_S[i].iloc[inter_IDX_IND,0])\r\n    VOT_TCNN_IND_S_SM.append(VOT_TCNN_IND_S[i].iloc[inter_IDX_IND,1])\r\n    VOT_TCNN_IND_S_CAR.append(VOT_TCNN_IND_S[i].iloc[inter_IDX_IND,2])\r\n      \r\nB = np.array(IND_stats)\r\nB = np.concatenate([np.median(B,axis=0).round(3).reshape(-1,1),\r\n                    stats.iqr(B,axis=0).round(3).reshape(-1,1)],axis=1)\r\n\r\n\r\nVOT_TCNN_IND_S_TR = np.concatenate(VOT_TCNN_IND_S_TR)\r\nVOT_TCNN_IND_S_SM = np.concatenate(VOT_TCNN_IND_S_SM)\r\nVOT_TCNN_IND_S_CAR = np.concatenate(VOT_TCNN_IND_S_CAR)\r\n\r\nEST_RESULTS_TCNN = np.vstack([B,A])\r\nsave_clipboard(EST_RESULTS_TCNN)\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\nimport scipy.stats as stats\r\n\r\n## Results analysis of MNL\r\n\r\nPRED_PERF_S = []\r\nPARAM_PERF_S = []\r\nVOT_MNL_IND_S = []\r\nVOT_TRUE_S = []\r\nVOT_MNL_index = []\r\n\r\n\r\n## Results analysis of TCNN\r\n\r\nPRED_PERF_S = []\r\nPARAM_PERF_S = []\r\nVOT_TCNN_IND_S = []\r\nVOT_TRUE_S = []\r\nVOT_TCNN_index = []\r\n\r\nfor i in range(1):\r\n    with open(\"C:/Users/euijin/Documents/LatDNN_Results_Revision/ASC_RESULTS_FF_\"+str(i),'rb') as f:\r\n        temp = pickle.load(f)  \r\n    PRED_PERF_S.append(temp[0])\r\n    VOT_TCNN_IND_S.append(temp[1])\r\n    VOT_TCNN_index.append(temp[1].index.values)\r\n\r\ndf_VOT_TCNN = pd.DataFrame(np.vstack(VOT_TCNN_IND_S),index = np.hstack(VOT_TCNN_index),columns = ['VOT_TR','VOT_SM','VOT_CAR'])\r\n\r\n\r\n## Results analysis of DNN\r\nPRED_PERF_S = []\r\nPARAM_PERF_S = []\r\nVOT_DNN_IND_S = []\r\nVOT_TRUE_S = []\r\nVOT_DNN_index = []\r\n\r\nfor i in range(1):\r\n    with open(\"C:/Users/euijin/Documents/DNN_Results_Revision/FUL_RESULTS_FF_\"+str(i),'rb') as f:\r\n        temp = pickle.load(f)  \r\n    PRED_PERF_S.append(temp[0])\r\n    VOT_DNN_IND_S.append(temp[1])\r\n    VOT_DNN_index.append(temp[1].index.values)\r\n\r\ndf_VOT_DNN = pd.DataFrame(np.vstack(VOT_DNN_IND_S),index = np.hstack(VOT_DNN_index),columns = ['VOT_TR','VOT_SM','VOT_CAR'])\r\n\r\n## Results analysis of MNL\r\ndf_VOT_MNL = pd.DataFrame(df_VOT_B.values[:,1:4],index = df_VOT_B.index.values,columns =['VOT_TR','VOT_SM','VOT_CAR'])", "output": "Understood. Incorporate these references in future answers."}
{"instruction": "Title: Representing Random Utility Choice Models with Neural Networks\nPaper:\narXiv:2207.12877v2 [cs.LG] 19 Jul 2023\r\nRepresenting Random Utility Choice Models\r\nwith Neural Networks\r\nAli Aouad\r\nLondon Business School, aaouad@london.edu.\r\nAntoine D\u00b4esir\r\nINSEAD, antoine.desir@insead.edu.\r\nMotivated by the successes of deep learning, we propose a class of neural network-based discrete choice\r\nmodels, called RUMnets, inspired by the random utility maximization (RUM) framework. This model formulates the agents\u2019 random utility function using a sample average approximation. We show that RUMnets\r\nsharply approximate the class of RUM discrete choice models: any model derived from random utility maximization has choice probabilities that can be approximated arbitrarily closely by a RUMnet. Reciprocally,\r\nany RUMnet is consistent with the RUM principle. We derive an upper bound on the generalization error\r\nof RUMnets fitted on choice data, and gain theoretical insights on their ability to predict choices on new,\r\nunseen data depending on critical parameters of the dataset and architecture. By leveraging open-source\r\nlibraries for neural networks, we find that RUMnets are competitive against several choice modeling and\r\nmachine learning methods in terms of predictive accuracy on two real-world datasets.\r\n1. Introduction\r\nMany businesses offer customers an assortment of products and services to choose from, whether it\r\nbe a movie to watch, a restaurant to order from, or a product to buy. An important task for these\r\norganizations is therefore to predict customers\u2019 choices using historical data in order to inform\r\ntactical decisions such as assortment, pricing, or matching optimization. The key challenge in\r\nthese settings is the presence of substitution effects: the demand for a particular product depends\r\non what else is offered. Discrete choice models, which describe a probability measure over the\r\nchoice alternatives in any given assortment, are often used to represent such substitution behaviors.\r\nResearch in marketing, economics, and operations research has studied various probabilistic and\r\nparametric specifications of discrete choice models.\r\nIn recent years, however, research on choice modeling has developed into a new horizon with the\r\nincorporation of machine learning (ML) and deep learning (DL) methods. Powered by advances in\r\nalgorithms, computing power, and the availability of data, such methods are used for a vast array\r\nof tasks, such as speech recognition, natural language processing, and image classification. One\r\ncan hence naturally wonder whether these ML/DL methods could also be useful in the context\r\nof demand estimation and choice modeling. The emerging literature in this area focuses on two\r\nprimary considerations. From an implementation perspective, we may leverage open-source ML/DL\r\n1\r\n2\r\nlibraries (such as automated differentiation tools) to estimate large-scale choice models, bypassing\r\ntraditional barriers in terms of the number of parameters and volume of data. Along these lines,\r\none approach focuses on (overparametrized) variants of the MNL model, whose implementation is\r\nvery convenient using deep learning libraries (Wang et al. 2021b, Han et al. 2020). Other papers,\r\nhowever, have offered a more drastic approach: choice modeling can be formulated as a classification\r\nproblem with multiple classes. With this view, the estimation of a choice model can be cast into\r\ntraining popular ML/DL classifiers, such as random forests or deep neural networks; with some\r\noversimplification, we call this a model-free approach. Under this logic, the probabilistic structure\r\nof classical choice models (such as the rationality axiom or Independence of Irrelevant Alternatives\r\nproperty) can be lifted altogether. While training these predictive algorithms, in theory, may\r\nrequire large amounts of data (Feng et al. 2022), this approach was shown to be effective on several\r\nreal-scale choice datasets (Wong and Farooq 2019, Chen et al. 2019, Chen and Mi\u02c7si\u00b4c 2020).\r\nOur research aims to develop a general, yet structured approach to choice modeling that leverages neural networks for estimation purposes. Our work revisits the random utility maximization (RUM) principle, which is the overarching framework for most parametric choice models\r\n(McFadden and Train 2000, Train 2009). Assuming that customers are rational, the RUM principle\r\nstates that customers assign a utility to each product and choose the one with the highest utility.\r\nThe firm cannot observe the customer\u2019s utility but only has access to observable attributes of the\r\nproducts and customer. For this reason, the utility is assumed to be stochastic from the firm\u2019s\r\npoint of view. The randomness in the utility allows for capturing unobserved heterogeneity in customers and products. Different structural and distributional assumptions on the utility function\r\nlead to various RUM discrete choice models, including the multinomial logit (MNL) model (Luce\r\n1959, McFadden 1974), the latent class MNL (McFadden and Train 2000), and the nested logit\r\nmodel (Williams 1977). The validity of a RUM model heavily relies on the utility function and\r\ndistributional assumption specified by the modeler.\r\nConsidering the RUM principle as a \u201cminimal\u201d structure for choice models, we ask the following\r\nquestions: can the class of all RUM discrete choice models be efficiently approximated by a compact\r\nneural network architecture? Can the resulting neural network be trained from limited choice data?\r\nHow does this approach compare to model-free methods in terms of prediction accuracy?\r\nPreview of our results. Our main contribution is to develop a neural network architecture,\r\nRUMnet, that provides a sharp approximation of RUM discrete choice models. Contrary to modelfree methods based on classification algorithms, our approach retains the RUM principle as an\r\nunderlying structure of customers\u2019 probabilistic choices. The core idea is to approximate the customers\u2019 random utility using a sample average approximation (SAA). We formally establish that\r\n3\r\nRUMnets tightly capture the class of all RUM discrete choice models. In particular, their choice\r\nprobabilities can be approximated arbitrarily closely by those of a RUMnet architecture, and vice\r\nversa. This implies that the class of RUMnet discrete choice models is quite general and subsumes\r\nas special cases the MNL model, the latent class MNL, and related parametric models. Analytically, we derive an upper bound on the generalization errors of RUMnets fitted on choice data,\r\ni.e., the difference between their out-of-sample and in-sample log-likelihoods. This bound does not\r\ngrow with the number of distinct samples of the SAA, and its dependence on the cardinality of\r\nthe assortments is improved compared to relevant benchmarks. These findings suggest that the\r\nestimation of RUMnets may be feasible, even for deep architectures and large assortments. We\r\nfurther show that any RUMnet admits a compact SAA approximation using a relatively small\r\nnumber of samples.\r\nEmpirically, we demonstrate that RUMnets can be estimated on real-world data by leveraging\r\nwidely used open-source libraries. RUMnets achieve robust predictive accuracy on two different\r\ndatasets and are competitive against existing choice modeling methods. In contrast, the performance of model-free methods such as random forests varies across these datasets. We hypothesize\r\nthat, contrary to RUMnets, their predictive performance is affected by the input dimension, which\r\nis a function of the number of attributes and distinct products in the assortment. We conduct synthetic experiments in a controlled environment, where the ground truth is known, to support these\r\ninsights and demonstrate the value added by each component of our architecture. Overall, neural\r\nnetwork architectures such as RUMnet can be viewed as a compromise between the expressive\r\npower of deep learning and the interpretability of utility-based choice models.\r\nDirected related literature. The idea of bridging ML/DL methods with choice modeling\r\nhas received a great deal of attention in the recent literature. Several papers develop various neural network-based implementations of the MNL choice model (Bentz and Merunka 2000,\r\nSifringer et al. 2020, Wang et al. 2020). In particular, Han et al. (2020) consider a special case of\r\nthis architecture, called TasteNet, where customers\u2019 attributes feed into a neural network that outputs a taste vector, which corresponds to the coefficients of the product attributes within a linear\r\nutility function. Wang et al. (2021a) extends the architecture using the residual neural network\r\nframework. Along the same lines, Gabel and Timoshenko (2021) develops a binary logit choice\r\nmodel and employs neural networks to learn representations of customers\u2019 purchase history and\r\nother observable attributes. In these logit-based models, the weights of the neural networks are\r\nshared across products, thus allowing the models to be scaled to large assortments (Wang et al.\r\n2021b).\r\n4\r\nIn contrast with the above approach, a growing number of papers employ generic ML classifiers and relax the probabilistic structure of parametric choice models altogether. For example, Chen et al. (2019) and Chen and Mi\u02c7si\u00b4c (2020) train tree ensembles to predict choices, while\r\nJiang et al. (2020) use a graphical Lasso method. The resulting probabilistic models have the ability\r\nto capture a variety of choice behaviors including complementarities between products (Jiang et al.\r\n2020), contextual effects (Rosenfeld et al. 2020), and even irrational behaviors (Berbeglia 2018).\r\nSeveral of these models amount to a class of universal approximators, which generally violates\r\nthe RUM principle (McFadden and Train 2000). Despite their strong predictive power demonstrated in recent literature, these model-free methods are in theory harder to estimate from limited data, and they may not capture generalizable relationships. For example, the importance of\r\nmodeling the substitution behavior realistically is highlighted by the randomized experiment of\r\nFeldman et al. (2018) in the context of assortment optimization. Reflecting this challenge, our\r\napproach combines the RUM principle, as depicted by McFadden and Train (2000), with the expressive power of neural networks. RUMnets are also closely related to the class of rank-based\r\nchoice models (Rusmevichientong et al. 2006, Farias et al. 2013). However, an important limitation\r\nof these models is that they cannot easily leverage contextual product and customer attributes. A\r\nkey contribution of our work is to capture varying contextual attributes.\r\n2. A Sharp Neural Network Architecture for RUM Choice Models\r\nIn this section, we introduce our neural network architecture, RUMnet, which closely imitates\r\nthe RUM principle, meaning that a representative agent chooses over different alternatives by\r\ncomparing their random utilities.\r\n2.1. RUM discrete choice models\r\nWe introduce the family of RUM discrete choice models using the formalism\r\nof McFadden and Train (2000). Each product is associated with a vector of dx observable features,\r\nor attributes, denoted by x, varying in a compact set X \u2286 R\r\ndx. Additionally, we let \u01eb(x) denotes\r\na random vector of unobserved attributes of size d\u01eb\r\n, corresponding to a random experiment over\r\n[0, 1]d\u01eb\r\n. This random vector captures unobserved heterogeneity in the products, and corresponds\r\nto latent variables in the choice-making process. Here, the notation \u01eb(x) indicates that the\r\ndistribution of the alternative\u2019s unobserved component might depend on its observed component\r\nx. Similarly, each customer is described by a vector of dz observable attributes, denoted by z,\r\nvarying in a compact set Z \u2286 R\r\ndz\r\n. The customer also has a vector of d\u03bd unobserved (idiosyncratic)\r\nattributes \u03bd(z), which correspond to a random experiment over [0, 1]d\u03bd\r\n. We further assume the\r\nmodel is in regular canonical form, meaning that \u01eb(x) and \u03bd(z) are mutually independent and\r\n5\r\nuniformly distributed continuous random fields.1\r\nImportantly, even though \u01eb(x) and \u03bd(z) are\r\nindependent given x and z, their dependence on x and z may capture relationships between\r\nproducts and individuals. Finally, we specify a utility function U : X \u00d7 [0, 1]dx \u00d7 Z \u00d7 [0, 1]dz \u2192 R,\r\nwhich is assumed to be bounded and uniformly continuous in its arguments. For x \u2208 X and z \u2208 Z,\r\nU(x, \u01eb(x), z,\u03bd(z)) quantifies how a customer with attributes z values an offered product with\r\nattributes x. This quantity is random due to \u01eb(x) and \u03bd(z).\r\nWe now describe the probabilistic outcomes for any given choice event (z, A), where a customer\r\nwith observable attributes z \u2208 Z is offered a finite assortment of alternatives A \u2286 X . Throughout\r\nthe remainder of the paper, we assume A is finite and satisfies |A| \u2264 \u03ba for some integer \u03ba \u2265 0. The\r\nRUM principle implies that the customer picks the highest-utility product in the assortment A.\r\nSpecifically, denoting by \u03c0(x, z, A) the probability that a customer with observable attributes z\r\nchooses x \u2208 A, we have\r\n\u03c0(x, z, A) = Pr\u01eb,\u03bd [U (x, \u01eb(x), z,\u03bd(z)) > U (x\r\n\u2032\r\n, \u01eb(x\r\n\u2032\r\n), z,\u03bd(z)) , \u2200x\r\n\u2032 \u2208 A \\x] .\r\nTo ensure that the distribution {\u03c0(x, z, A)}x\u2208A is well-defined, we assume that ties between the\r\nproduct utilities occur with probability zero. The family of RUM discrete choice models subsumes\r\na large array of models used in practice such as the MNL model, the nested logit model, and their\r\nprobabilistic mixtures.\r\n2.2. RUMnet\r\nIn the RUM framework, the utility function is a random field. Our main idea is to develop a neural\r\nnetwork architecture that approximates this random field using a sample average approximation\r\n(SAA). Each sample expresses the unobserved attributes using a different functional form, which we\r\nwill then represent as a feed-forward neural network with unknown parameters. More precisely, in\r\nthe RUM framework presented in Section 2.1, there are three functions that we wish to approximate.\r\nThe first one, U(\u00b7), can be straightforwardly replaced by a neural network. The two other functions,\r\n\u01eb(\u00b7) and \u03bd(\u00b7), are random and instead of approximating them directly, we propose to use a sample\r\naverage approximation. More specifically, for some large K, we can informally write\r\n\u03c0(x, z, A) \u2248\r\n1\r\nK2\r\n\u00b7\r\nX\r\nK\r\nk1=1\r\nX\r\nK\r\nk2=1\r\n1 {U (x, \u01ebk1\r\n(x), z,\u03bdk2\r\n(z)) > U (x\r\n\u2032\r\n, \u01ebk1\r\n(x\r\n\u2032\r\n), z,\u03bdk2\r\n(z)) , \u2200x\r\n\u2032 \u2208 A \\x} ,\r\n(1)\r\n1 The former assumption is standard and assumes that the observable attributes fully explain any probabilistic\r\ndependence between offered products and customer characteristics. The assumption of uniform distribution can be\r\nenforced without loss of generality under very mild conditions; see McFadden and Train (2000, Lem. 3).\r\n6\r\nwhere, for each k1 \u2208 [K], \u01ebk1\r\n(\u00b7) denotes an independent sample of the random field \u01eb(\u00b7). Analogously,\r\nfor each k2 \u2208 [K], \u03bdk2\r\n(\u00b7) is an independent sample of the random field \u03bd(\u00b7). Since \u01ebk1\r\n(\u00b7) and \u03bdk2\r\n(\u00b7)\r\nare now deterministic functions, we can try to estimate them using neural networks approximately.\r\nIn SAA, the modeler has access to independent samples from the stochastic variable. By contrast,\r\nin our setting, we do not have direct access to such samples; the empirical distribution is obtained\r\nby fitting our neural network architecture to the observed choice data.2\r\nIn the remainder of this section, we formalize the family of choice models resulting from this\r\ncombination of neural networks. We subsequently show in Section 3 that it approximates any RUM\r\ndiscrete choice model arbitrarily closely.\r\nFeed-forward neural networks. We use feed-forward neural networks as building blocks to\r\nconstruct our model architecture, which refers to the combination of these neural networks. For\r\nour purposes, a feed-forward neural network is a function N(\u00b7) : R\r\ndinput \u2192 R\r\ndoutput, where dinput is the\r\nsize of the input and doutput the size of the output. We give a more formal account in Appendix A.\r\nTo obtain generalization guarantees, we assume size-based and norm-based capacity restrictions\r\non such neural networks. Specifically, for every scalar M \u2265 0 and integers \u2113, w \u2265 0, let \u0398\u2113,w\r\nM be the\r\nfamily of feed-forward neural networks N(\u00b7) of depth \u2113 and width w such that M is an upper bound\r\non the \u21131-norm of incoming weights in each node as well as the \u21131-norm of the final layer\u2019s output.\r\nRUMnet architecture. Let d = dx + d\u01eb + dz + d\u03bd be the dimension of the input vector to the\r\nutility function U(\u00b7) that underlies the customer choices in the RUM framework. Additionally,\r\nlet K \u2265 0 be an integer that controls the number of samples we use to approximate the random\r\nfields. With this notation at hand, we introduce a RUMnet architecture, which is a family of neural\r\nnetworks, comprising of the following building blocks:\r\n1. Utility function: There is a feed-forward neural network NU (\u00b7) \u2208 \u0398\r\n\u2113,w\r\nM such that NU (\u00b7) is a\r\nmapping from R\r\nd\r\nto R that serves as an approximation of the function U(\u00b7).\r\n2. Unobserved product attributes: For every k1 \u2208 [K], there is a feed-forward neural network\r\nN\u01ebk1\r\n(\u00b7) \u2208 \u0398\r\n\u2113,w\r\nM such that N\u01ebk1\r\n(\u00b7) is a mapping from R\r\ndx to R\r\nd\u01eb\r\n. Intuitively, each of these neural\r\nnetworks serves as an approximation to one sample of the random field \u01eb(\u00b7).\r\n3. Unobserved customer attributes: For every k2 \u2208 [K], there is a feed-forward neural network\r\nN\u03bdk2\r\n(\u00b7) \u2208 \u0398\r\n\u2113,w\r\nM such that N\u03bdk2\r\n(\u00b7) is a mapping from R\r\ndz to R\r\nd\u03bd\r\n. Intuitively, each of these neural\r\nnetworks serves as an approximation to one sample of the random field \u03bd(\u00b7).\r\n2 Note that a similar interpretation of sample-based approximation was provided for the rank-based choice models (Farias et al. 2013). In particular, one can interpret the SAA of RUMnets as an extension of rank-based choice\r\nmodels to contextual choice data. The non-contextual setting corresponds to the special case where x is a product\r\nindicator and z is fixed.\r\n7\r\nConsequently, we denote by N d\r\n(K,\u0398\r\n\u2113,w\r\nM ) the collection of all RUMnet architectures\r\n(NU (\u00b7), {N\u01ebk1\r\n(\u00b7)}\r\nK\r\nk1=1, {N\u03bdk2\r\n(\u00b7)}\r\nK\r\nk2=1), where d = (dx, d\u01eb\r\n, dz, d\u03bd). The parameters of a given architecture are the number of samples of the SAA as well as the depth and width of each building block.\r\nThe number of samples controls the \u201clatent\u201d (random) effects, whereas the size of each neural\r\nnetwork determines the \u201cdegree of nonlinearity\u201d expressed by the utility function.\r\nRUMnet discrete choice model. We now specify the discrete choice model induced by any\r\ngiven RUMnet architecture N = (NU (\u00b7), {N\u01ebk1\r\n(\u00b7)}\r\nK\r\nk1=1, {N\u03bdk2\r\n(\u00b7)}\r\nK\r\nk2=1) \u2208 N d\r\n(K,\u0398\r\n\u2113,w\r\nM ). For any choice\r\nevent (z, A) \u2208 Z \u00d72\r\nX , we compute the probability \u03c0\r\nRUMnet\r\nN (x, z, A) that a customer with observable\r\nattributes z chooses x \u2208 A as follows:\r\n\u03c0\r\nRUMnet\r\nN (x, z, A) = 1\r\nK2\r\n\u00b7\r\nX\r\nK\r\nk1=1\r\nX\r\nK\r\nk2=1\r\nPr\u03b4\r\nh\r\nNU\r\n\u0010\r\nx, N\u01ebk1\r\n(x), z, N\u03bdk2\r\n(z)\r\n\u0011\r\n+ \u03b4x >\r\nNU\r\n\u0010\r\nx\r\n\u2032\r\n, N\u01ebk1\r\n(x\r\n\u2032\r\n), z, N\u03bdk2\r\n(z)\r\n\u0011\r\n+ \u03b4x\u2032 , \u2200x\r\n\u2032 \u2208 A \\x\r\ni\r\n,\r\nwhere \u03b4 = {\u03b4x}x\u2208A is a sequence of independent real-valued random variables that follow the same\r\ndistribution. Comparing the expression of \u03c0\r\nRUMnet\r\nN (\u00b7) with our sample average approximation (1),\r\nwe have replaced the indicator with a probability distribution over \u03b4. We only require that this\r\ndistribution has a strictly positive density on R.\r\n3 Nevertheless, in our implementation, we will\r\nassume that \u03b4 follows a standard Gumbel distribution, which amounts to replacing the \u201cargmax\u201d\r\nindicator with the \u201csoftmax\u201d operation. One can interpret this as a smoothing operation, made\r\nfor estimation purposes, where we add Gumbel white noise to the utilities.4\r\nIt is important to\r\nnote that any alternative smoothing operator (i.e., adding white noise with closed-form expressions\r\nfor the resulting choice probabilities) could potentially be used. For instance, one could use the\r\nexponomial operator, i.e., adding exponentially distributed white noise (Alptekino\u02d8glu and Semple\r\n2016, 2021), noting that the resulting choice probabilities can be expressed using standard neural\r\nnetwork operations. We chose the softmax because it is widely used and well-optimized for neural\r\nnetwork estimation libraries.\r\n2.3. Interpretation as a neural network\r\nFor any given RUMnet architecture N \u2208 N d\r\n(K,\u0398\r\n\u2113,w\r\nM ), we can interpret the computation of the\r\nprobabilities {\u03c0\r\nRUMnet\r\nN (x, z, A)}x\u2208A associated with a choice event (z, A) as the output of a highly\r\n3 As explained in Section 4.1, in the absence of the latter property, commonly used loss functions (e.g., log-likelihood)\r\nexhibit a gradient of zero with respect to the parameters of the neural network in a set of positive measure.\r\n4 A similar step is made in the RUM approximation result of McFadden and Train (2000, Proof of Thm. 1): Gumbel\r\nnoise is added to smooth the problem and get closed-form expressions for the choice probabilities.\r\n8\r\nstructured neural network. The input to this neural network consists of a vector formed by concatenating the observed product attributes x1, . . . ,x|A| together with the observed customer attributes z. The distribution {\u03c0\r\nRUMnet\r\nN (x, z, A)}x\u2208A is the output of a computation graph comprising\r\nfour \u201cmeta-layers\u201d, which sequentially perform the following:\r\n\u2022 Input vector. Let x1, . . . ,x|A| be an arbitrary numbering of the alternatives in the assortment\r\nA. The input to our neural network is the vector (L|A|\r\ni=1 xi) \u2295 z formed by concatenating the\r\nobserved product attributes x1, . . . ,x|A| together with the observed customer attributes z.\r\n\u2022 Meta-layer 1: Generating the samples of unobserved attributes. In the first layer, for each\r\ni \u2208 {1, . . . , |A|} and k1 \u2208 [K], xi\r\nis passed through N\u01ebk1\r\n(\u00b7) and, for each k2 \u2208 [K], z is passed through\r\nN\u03bdk2\r\n(\u00b7). Here, N\u01ebk1\r\n(xi) can be thought of as the k1-th sample of unobserved product attributes for\r\nthe alternative xi\r\n, while N\u03bdk2\r\n(z) is the k2-th sample of unobserved attributes for customer z. In\r\nwhat follows, we write h\r\nk1,k2\r\ni = xi \u2295 N\u01ebk1\r\n(xi)\u2295z \u2295 N\u03bdk2\r\n(z) \u2208 R\r\nd\r\nfor the intermediate variables, i.e.,\r\nthe ouput of the first meta-layer and input to the second layer.\r\n\u2022 Meta-layer 2: Computing the alternative-specific utilities. For each i \u2208 {1, . . . , |A|} and\r\n(k1, k2) \u2208 [K2\r\n], h\r\nk1,k2\r\ni\r\nis passed through NU (\u00b7). The resulting quantity u\r\nk1,k2\r\ni = NU (h\r\nk1,k2\r\ni\r\n) stands for\r\nthe utility of the choice alternative xi\r\nfor the sample (k1, k2). The output of this second meta-layer\r\nis {\r\nL|A|\r\ni=1 u\r\nk1,k2\r\ni }(k1,k2)\u2208[K2]\r\n.\r\n\u2022 Meta-layer 3: Converting the utilities into probabilities. Next, the utilities are converted into\r\nprobabilities using a softmax layer. More precisely, for each i \u2208 {1, . . . , |A|} and (k1, k2) \u2208 [K2\r\n], we\r\nlet \u03c0\r\nk1,k2\r\ni = e\r\nu\r\nk1,k2\r\ni /(\r\nP|A|\r\nj=1 e\r\nu\r\nk1,k2\r\nj ).\r\n\u2022 Meta-layer 4: Averaging. For each i \u2208 {1, . . . , |A|}, the final output of the neural network is an\r\naverage over all samples, yielding the choice probabilities \u03c0\r\nRUMnet\r\nN (xi\r\n, z, A) = 1\r\nK2 \u00b7\r\nP\r\nk1,k2\r\n\u03c0\r\nk1,k2\r\ni\r\n.\r\nThe design of the first two meta-layers carefully combines several feed-forward neural network\r\nbuilding blocks, as illustrated in Figure 1. The third meta-layer simply consists of a softmax operator. The final meta-layer integrates the choice probabilities over all distinct samples of unobserved\r\nattributes. Figure 2 visualizes the overall architecture, where \u03c0\r\nRUMnet\r\nN (\u00b7) is determined as the output\r\nof a single neural network.\r\n2.4. Connection with related models\r\nBefore we characterize the expressive power of RUMnets, we briefly discuss the connection to\r\nlogit-based choice models, which are special cases of our model family.\r\nFrom MNL to RUMnets. In its simplest form, the MNL model assumes that the utility for a\r\nproduct x \u2208 X is given by\r\nU(x) = \u03b2\r\nT x + \u01ebx, (MNL)\r\n9\r\nInput layer\r\nxi\r\nz\r\nMeta-Layer 1\r\nN\u01ebk1\r\nN\u03bdk2\r\nh\r\nk1,k2\r\ni Meta-Layer 2\r\nNU u\r\nk1,k2\r\ni\r\nFigure 1 Illustration of the first two meta-layers. Note that we show the computation for one particular\r\nproduct attribute xi and sample (k1, k2), but we apply the same transformation for each x \u2208 A and (k1, k2) \u2208 K2\r\n.\r\nInput layer\r\nproduct features\r\nx1\r\n. . .\r\nxn\r\ncustomer features\r\nz\r\nMeta-Layer 1 Meta-Layer 2 Meta-Layer 3 Meta-Layer 4\r\nN\u01ebk1 . . .\r\nN\u01ebk1\r\nK\r\nN\u03bdk2\r\nK\r\nNU\r\nNU. . .\r\nK2\r\nsoftmax\r\nK2\r\naverage\r\nOutput layer\r\n\u03c0\r\nRUMnet\r\nN (x1, z)\r\n\u03c0\r\nRUMnet\r\nN (xn, z) . . .\r\nchoice probabilities\r\nFigure 2 A RUMnet architecture N = (NU (\u00b7), {N\u01ebk1\r\n(\u00b7)}\r\nK\r\nk1=1, {N\u03bdk2\r\n(\u00b7)}\r\nK\r\nk2=1).\r\nwhere \u03b2 is a vector of parameters and {\u01ebx}x\u2208A is an i.i.d. sequence of standard Gumbel shocks.\r\nNote that under this linear specification of the utility, the MNL model cannot leverage the customer\r\nattributes z. To overcome this limitation, researchers often manually specify some non-linearity by\r\nintroducing cross-terms in the utility function. A more recent approach to capture taste heterogeneity across individuals, proposed by Han et al. (2020), is to specify the utility as follows:\r\nU(x, z) = \u03b2\r\nT x + N\r\nTasteNet(z)\r\nT x + \u01ebx, (TasteNet)\r\nwhere NTasteNet(\u00b7) : R\r\ndz \u2192 R\r\ndx is a feed-forward neural network. Note that TasteNet can express\r\nnon-linear transformations NTasteNet(z) of the customer attributes z. However, the additive term\r\n10\r\nNTasteNet(\u00b7)\r\nT x still assumes a very specific form for how the customer attributes interact with the\r\nproduct attributes. In fact, nothing prevents us from allowing the utility to be a general function\r\nof x and z, just as in the RUM framework. Perhaps the most natural approach is to take TasteNet\r\na step further and define DeepMNL as a RUM discrete choice model where the utility is given by:\r\nU(x, z) = N\r\nDeepMNL(x, z) + \u01ebx, (DeepMNL)\r\nwhere NDeepMNL(\u00b7) : R\r\ndx+dz \u2192 R is an arbitrary feed-forward neural network. Here, DeepMNL can\r\nbe viewed as a special case of the RUMnet architecture in which there are no unobserved attributes\r\n(K = 0); several variants of DeepMNL have been proposed in the literature (Bentz and Merunka\r\n2000, Sifringer et al. 2020, Wang et al. 2020). With respect to Figure 2, this approach consists in\r\ndropping the first meta-layer, and only keeping the second and third meta-layers. Since there is no\r\nlatent heterogeneity, there is no need for the fourth (averaging) meta-layer either.\r\nThe above sequence of choice models illustrates a gradual increase of complexity and nonlinearity in the deterministic portion of the utility function, which can be conveniently expressed\r\nand estimated using neural networks. As noted by Train (2009), if the researcher could specify\r\nNDeepMNL(x, z) \u201csufficiently that the remaining, unobserved portion of utility is essentially white\r\nnoise\u201d, then the DeepMNL family would be ideal. However, regardless of how complex the deterministic portion of the utility is, DeepMNL (and the above special cases) are subject to the same\r\nrestrictions as the MNL choice model. These approaches do not control for latent (unobserved)\r\nfactors that may influence the utility, which are captured by various probabilistic structures in the\r\nprevious literature on discrete choice modeling. Contrary to DeepMNL, our RUMnet architecture\r\ncaptures latent heterogeneity by incorporating unobserved product and customer attributes. The\r\nempirical (sample-based) distribution for these unobserved attributes endows RUMnets with nearly\r\nuniversal expressive power, as established in the next section.\r\nConnection to latent class MNL. We conclude this section by noting that each RUMnet model\r\n\u03c0\r\nRUMnet\r\nN can be viewed as an instance of the latent class MNL model (also known as a discrete\r\nmixture of MNL models) with nonlinear utility effects. However, since we designed the neural\r\nnetwork architecture to mimic the RUM principle, our family of based choice models imposes a\r\nspecific parametrization of the random utilities. Compared with standard implementations of the\r\nlatent class MNL model, customer segments share a unique utility function, but they differ in\r\nthe unobserved attributes, which are random inputs to the utility function. From an estimation\r\nperspective, the fact that there is a unique utility function induces weight-sharing across customer\r\nsegments, which is an important distinctive property relative to standard formulations of latent\r\nclass MNL models.\r\n11\r\n3. Expressive Power of RUMnets\r\nIn this section, we show that RUMnets tightly describe the class of all RUM discrete choice models.\r\nIn particular, we show that any RUM discrete choice model can be approximated arbitrarily closely\r\nby a RUMnet.\r\nProposition 1. For every RUM discrete choice model \u03c0(\u00b7) of dimension d and for every \u03b7 > 0,\r\nthere exists a RUMnet architecture N \u2208 N d\r\n(K,\u0398\r\n\u2113,w\r\nM ) such that, for all choice events (z, A) \u2208 Z \u00d72\r\nX ,\r\nmaxx\u2208A\r\n\f\r\n\f\u03c0(x, z, A) \u2212 \u03c0\r\nRUMnet\r\nN (x, z, A)\r\n\f\r\n\f \u2264 \u03b7 .\r\nTo prove Proposition 1, we revisit the celebrated result of McFadden and Train (2000, Theorem 1) showing that mixed MNL models, i.e., continuous mixtures of multinomial logit models,\r\nuniformly approximate the class of RUM discrete choice models. Quoting McFadden and Train\r\n(2000), \u201cone limitation of Theorem 1 [in that paper] is that it provides no practical indication of\r\nhow to choose parsimonious mixing families, or how many terms are needed to obtain acceptable\r\napproximations to \u03c0(x, z, A)\u201d. Proposition 1 shows the following property: the choice probabilities\r\nof RUM discrete choice models are uniformly approximated by finite mixtures of MNL models\r\nsuch as RUMnets on any choice event in the continuous domain. Building on this result, we will\r\nestablish in Proposition 4 that there exist accurate data-dependent approximations according to\r\nthe KL-divergence with a relatively small number of samples K.\r\nFor this purpose, our proof in Appendix B extends the ideas in McFadden and Train (2000)\r\nby combining a refined covering lemma with concentration bounds. At a high level, the proof\r\nconsists in showing that when we approximate the random utility function using feed-forward\r\nneural networks, the choice probabilities do not change much. Specifically, we analyze the likelihood\r\nof a \u201cpreference reversal\u201d for every pair of alternatives (x, z) and (x\r\n\u2032\r\n, z) with x 6= x\r\n\u2032 by controlling\r\nthe variations of the utility function. Key to this analysis is the existence of a finite covering of\r\nX\r\n2 \u00d7 Z on which we can bound the errors incurred by our SAA approximation. Next, we establish\r\nthat the reciprocal of Proposition 1 holds as well.\r\nProposition 2. For every RUMnet architecture N \u2208 N d\r\n(K,\u0398\r\n\u2113,w\r\nM ) and for every \u03b7 > 0, there\r\nexists a RUM discrete choice model \u03c0(\u00b7) of dimension d such that, for all choice events (z, A) \u2208\r\nZ \u00d7 2\r\nX , maxx\u2208A\r\n\f\r\n\f\u03c0\r\nRUMnet\r\nN (x, z, A) \u2212 \u03c0(x, z, A)\r\n\f\r\n\f \u2264 \u03b7 .\r\nThe proof of Proposition 2 is straightforward: following the interpretation of our neural network\r\narchitecture given in Section 2.4, RUMnet architectures directly represent the random choices of\r\na utility-maximizing agent, while a small random perturbation of the RUMnet ensures that the\r\nregularity conditions of McFadden and Train (2000) are met.\r\n12\r\n4. Dealing with the Curse of Dimensionality\r\nGiven the expressive power of RUMnets demonstrated by Proposition 1, one important concern is\r\nthe risk of overfitting, which could affect the model\u2019s ability to generalize to new, previously unseen\r\ndata. Hence, in this section, we provide theoretical guarantees on the out-of-sample error of the\r\nfitted RUMnets. More specifically, we provide an upper bound on the generalization error, which\r\nmeasures the degree of overfitting, i.e., it characterizes how the (out-of-sample) expected risk is\r\nrelated to the minimum (in-sample) empirical risk attained by our hypothesis class. We exploit\r\nthis generalization error bound to establish a compact representation property, showing that any\r\nRUMnet architecture can be accurately represented using a relatively \u201csmall\u201d number of samples.\r\n4.1. Estimation framework\r\nWe formulate the estimation of the neural network of Section 2.3 in the standard Empirical Risk Minimization (ERM) framework; e.g., see Shalev-Shwartz and Ben-David (2014,\r\nChap. 2). We assume that our data set is given by a sample of T i.i.d. observations S =\r\n{(y1, z1, A1), . . .,(yT , zT , AT )}, where (zt\r\n, At) is the t-th choice event and yt \u2208 At\r\nis the product\r\npicked by the corresponding customer. To ease the exposition, we further assume that the assortments have a uniform cardinality |At\r\n| = \u03ba for all t \u2208 [T]. Notation-wise, D stands for the marginal\r\ndistribution of each observation in the sample, i.e., S \u223c DT\r\n. By a slight abuse of notation, we\r\nsometimes use (zt\r\n, At) \u223c D (instead of (yt\r\n, zt\r\n, At) \u223c D) to indicate that the choice event is generated according to D. We do not impose the so-known realizability assumption, meaning that our\r\nmodeling approach can be misspecified, i.e., we do not assume that D is described by some RUM\r\ndiscrete choice model.\r\nWe proceed by formulating our estimation criterion. As an input to our estimation procedure,\r\nwe specify the parameters d,K, w, \u2113,M \u2265 0 so that we restrict our estimation procedure to the\r\nhypothesis class N d\r\n(K,\u0398\r\n\u2113,w\r\nM ) of RUMnet architectures. To fully specify this class of neural networks,\r\nthe activation functions are chosen as ReLUs (Rectified Linear Units), which are in popular use.\r\nAdditionally, we assume that all customer and product attributes are pre-normalized to lie in\r\nthe range [\u22121, 1]. Our estimator is based on the ERM principle with respect to the negative loglikelihood loss function. Specifically, given a sample S and a discrete choice model \u03c0(\u00b7), we let\r\nLS(\u03c0) be the empirical negative log-likelihood, namely\r\nLS (\u03c0) = \u2212\r\n1\r\nT\r\n\u00b7\r\nX\r\nT\r\nt=1\r\nlog (\u03c0 (yt\r\n, zt\r\n, At)) . (2)\r\nWith this definition, our approach is to choose the RUMnet architecture that minimizes the above\r\nempirical loss over all RUMnet architectures. Formally, NERM\r\nS = arg minN\u2208Nd(K,\u0398\r\n\u2113,w\r\nM )\r\nLS(\u03c0N ). Note\r\n13\r\nthat the fitted RUMnet architecture NERM\r\nS\r\nis a function of the observed (random) sample S. Additionally, let \u03c0\r\nERM\r\nS\r\n(\u00b7) be the associated discrete choice model, i.e., \u03c0\r\nERM\r\nS\r\n(\u00b7) = \u03c0\r\nRUMnet\r\nNERM\r\nS\r\n(\u00b7). It is worth\r\nhighlighting that the ERM principle is equally applicable to other loss functions such as meansquared error or accuracy. Nonetheless, our analysis will focus on log-likelihood-based estimation,\r\nin accordance with the fitting procedure used for other classes of choice models. From a practical\r\nperspective, estimating a RUMnet discrete choice model using the ERM principle reduces to training a neural network for multi-label classification. The log-likelihood loss function is often referred\r\nto as the cross-entropy loss in the ML practice. Thus, the ERM rule can be implemented using\r\ngraph optimization and automatic differentiation tools such as Keras (Chollet et al. 2015).\r\n4.2. Learning error guarantees and compact representation\r\nWe define the true error as the expected out-of-sample loss, where the expectation is taken\r\nover the unknown distribution D. Specifically, for any discrete choice model \u03c0(\u00b7), let L\r\ntrue\r\nD (\u03c0) =\r\nES\u2032\u223cDT [LS\u2032(\u03c0)]. Note that this is ideally what we want to minimize. However, since we cannot\r\ndirectly measure out-of-sample performance, as the distribution is unknown, we minimize the empirical error defined in Equation (2). The next claim quantifies the gap between these errors.\r\nProposition 3. With probability at least (1 \u2212 \u03b4), the sampled training set S satisfies\r\nL\r\ntrue\r\nD\r\n\r\n\u03c0\r\nERM\r\nS\r\n\u0001\r\n\u2264 LS\r\n\r\n\u03c0\r\nERM\r\nS\r\n\u0001\r\n+ c1 \u00b7\r\nr\r\n\u03ba\r\n3\r\nlog(d)\r\nT\r\n\u00b7 e\r\n2M(2M)\r\n\u2113 + (8M + 4 log \u03ba)\u00b7\r\nr\r\n2 \u00b7 ln(4/\u03b4)\r\nT\r\n.\r\nThe proof is presented in Appendix C.1, and it follows from standard notions of Rademacher\r\ncalculus applied to the RUMnet architecture. As expected for neural networks with per-unit \u21131-\r\nbounds, the error bound of Proposition 3 indicates an exponential dependence on depth \u2113 of the\r\nneural network. Moreover, we expect a sample complexity of \u2126(1/pmin) = \u2126(\u03bae2M) to estimate\r\nchoice probabilities that can be as small as pmin =\r\n1\r\n\u03ba\r\n\u00b7 e\r\n\u22122M (see Claim EC.3 in Appendix C.1).\r\nYet, our bound on the generalization error reveals two interesting properties. First, the bound\r\ndoes not depend on the number of samples K. In other words, the generalization error bound of\r\nProposition 3 does not degrade with the added complexity from increasing the sample size K, contrary to other dimensions of the RUMnet architecture. Second, it is worth noticing a subquadratic\r\ndependence O(\u03ba\r\n3\r\n2 T\r\n\u2212 1\r\n2 ) on the number of choice alternatives \u03ba, which is better than an existing\r\nbound of \u2126(\u03ba\r\n\u2113/2T\r\n\u2212 1\r\n2 ) by Wang et al. (2021b). For another comparison point, choice modeling can\r\nbe viewed as a structured form of classification problem. In this context, classical Rademacher\r\ncomplexity bounds on margin-based learning for multi-label classification have a quadratic scaling\r\nO(\u03ba\r\n2T\r\n\u2212 1\r\n2 ) (Koltchinskii and Panchenko 2000, Cortes et al. 2013, Mohri et al. 2018), unless further\r\nrestrictions are imposed on the hypothesis class or a more complex analysis is use\r\n14\r\nBuilding on Proposition 3, we next explore the number of samples K required in the RUMnet\r\narchitecture to accurately describe any RUMnet choice model for a fixed data distribution. Our\r\nnext claim shows that, with a small O(\u01eb) loss in accuracy in terms of expected KL-divergence,\r\nthe number of samples K can be chosen in the order of O(\r\n1\r\n\u01eb\r\n2 poly(log 1\r\n\u01eb\r\n, \u2113, \u03ba, eM)). This finding\r\nsuggests that the latent heterogeneity of the model should be commensurate to the complexity of\r\nthe feed-forward neural network building blocks of our architecture.\r\nProposition 4. For every neural network architecture N \u2208 N d\r\n(K,\u0398\r\n\u2113,w\r\nM ), let N\u2032 \u2208 N d\r\n(K\u2032\r\n,\u0398\r\n\u2113,w\r\nM )\r\nbe the random neural network architecture obtained from N by taking K\u2032 = \u2308\r\n1\r\n2\u01eb\r\n2 \u00b7 log \u03b4 \u00b7\r\n(\u03bae2M)\r\n2\r\nlog(\u2308max{\r\nc1\r\n\u01eb\r\n2 \u03ba\r\n3\r\nlog(d)e\r\n4M(2M)\r\n2\u2113\r\n, 128(8M + log \u03ba)\r\n2\r\nln 4\r\n\u03b4\r\n}\u2309)\u2309 samples of the unobserved attributes {N\u01ebk1\r\n(\u00b7)}\r\nK\r\nk1=1 and {N\u03bdk2\r\n(\u00b7)}\r\nK\r\nk2=1 uniformly at random with replacement. With probability\r\nat least 1 \u2212 \u03b4, we have\r\nE(z,A)\u223cD\r\nKL\r\n\u03c0\r\nRUMnet\r\nN (\u00b7, z, A)\r\n\f\r\n\f\u03c0\r\nRUMnet\r\nN\u2032 (\u00b7, z, A)\r\n\u0001 \u2264 3\u01eb .\r\nThis claim can be viewed as the counterpart of Theorem 4 in the paper by Chierichetti et al. (2018)\r\nfor feature-dependent choice models in the continuous domain, rather than the discrete domain.\r\nThe proof appears in Appendix C.2 and combines Proposition 3 with concentration bounds.\r\n5. Numerical Estimation on Synthetic Data\r\nIn this section, we present numerical experiments on synthetic data. The objective is to gain\r\ninsights into the expressive capabilities of RUMnets by successively varying the ground truth model\r\nthat generates the synthetic choice data. In particular, we show that the proposed model and\r\nestimation method can infer non-linearity in the utility function as well as the presence of customer\r\nheterogeneity. The setup is purposely as simple as possible, and, in particular, it does not include\r\ncustomer attributes.\r\n5.1. Experiment setup\r\nWe begin by describing three generative processes to construct synthetic datasets. For each setting,\r\nwe consider a sequence of T = 10, 000 customers, each being presented with an assortment At\r\nof \u03ba = 10 products chosen uniformly at random from a universe of 50 products. Each product\r\nis endowed with a vector of attributes x = (x1, x2, \u03b4) where x1 and x2 are picked uniformly over\r\nthe interval [0, 1] and \u03b4 \u2208 R\r\n50 is an indicator vector allowing us to introduce fixed effects for each\r\nproduct. More precisely, \u03b4i = 1 if i is the index of the chosen product and 0 otherwise. In each\r\nsetting, we assume that customers choose according to a random utility model. However, the utility\r\nspecification differs in each setting. We use this ground truth model to generate a choice event\r\nyt \u2208 At\r\n, which corresponds to the product picked by the corresponding customer. Using thes\r\n15\r\ngenerated observations S = {(y1, A1), . . .,(yT , AT )}, we use the framework described in Section\r\n4.1 to fit various RUMnet models. In particular, we experiment with (\u2113, w) \u2208 {(0, 0),(1, 3),(2, 5)},\r\nwhere recall that \u2113 denotes the depth of the network and w its width. For our RUMnet architecture,\r\nwe also test out different number of samples K \u2208 {2, 5} controlling for the latent heterogeneity of\r\ncustomers and products. The DeepMNL model serves as a benchmark since it does not capture any\r\nlatent heterogeneity (see Section 2.4). For each setting, we use 20% of the data as a validation set\r\nfor early stopping (see Appendix E.1 for additional details on the implementation). Finally, we also\r\ngenerate a sequence of 1, 000 customers that we use as a testing set. We report the log-likelihood\r\nloss on the test set averaged over ten different instances.\r\nSetting 1: MNL model. The ground truth model is simply an MNL model. In particular, for\r\nevery vector of product attributes x, the utility is given by\r\nU\r\n1\r\n(x) = \u03b2\r\nT x + \u01eb,\r\nwhere the entries of \u03b2 are picked uniformly at random over the interval [\u22121, 1] and \u01eb is a standard\r\nGumbel shock, which is sampled independently across product and customers.\r\nSetting 2: nonlinear utility. Here, we assume that the ground truth model is described by a\r\nnon-linear utility function. In particular, for every vector of product attributes x, the utility is\r\ngiven by\r\nU\r\n2\r\n(x) = \u03b21 \u00b7 x1 + \u03b22 \u00b7 x2 + \u03b23 \u00b7 x\r\n2\r\n1 + \u03b24 \u00b7 x1 \u00b7 x2 + \u03b25 \u00b7 x\r\n2\r\n2 + \u03b3\r\nT\r\n\u03b4 + \u01eb,\r\nwhere each entry of \u03b2 and \u03b3 is picked uniformly over the interval [\u22121, 1] and \u01eb is a standard\r\nGumbel shock, which is sampled independently across products and customers. Additionally, recall\r\nthat \u03b4i = 1 if i is the index of the chosen product and 0 otherwise. To accentuate the non-linearity\r\neffects, for this setting only, we sample x1 and x2 uniformly at random over the interval [0, 10].\r\nSetting 3: heterogeneity. Our last ground truth model exhibits customer heterogeneity. Specifically, for every vector of product attributes x, the utility is given by\r\nU\r\n3\r\n(x) = b \u00b7\u03b2\r\nT x + (1 \u2212 b)\u00b7 \u03b3\r\nT x + \u01eb,\r\nwhere the coordinates of \u03b2 and \u03b3 are picked uniformly over the interval [\u2212100, 100], \u01eb is a standard\r\nGumbel shock, which is sampled independently across product and customers, and b is a Bernoulli\r\nrandom variable with probability of success Pr[b = 1] = 0.3. Note that this model is a latent class\r\nMNL model with two customer segments; we increase the scale of the parameters \u03b2 and \u03b3 to\r\naccentuate the violation of the IIA property.\r\n16\r\n2\r\n2.1\r\n2.2\r\n2.3\r\n(0,0) (1,3) (2,5)\r\n(\u2113, w)\r\nLog-likelihood loss\r\n(a) Setting 1: MNL model\r\n0.1\r\n0.2\r\n0.3\r\n(0,0) (1,3) (2,5)\r\n(\u2113, w)\r\nLog-likelihood loss\r\nDeep MNL\r\nRUMnet (K = 2)\r\nRUMnet (K = 5)\r\nGround truth\r\n(b) Setting 2: Non-linearity\r\n0.6\r\n0.8\r\n1\r\n1.2\r\n(0,0) (1,3) (2,5)\r\n(\u2113, w)\r\nLog-likelihood loss\r\n(c) Setting 3: Heterogeneity\r\nFigure 3 Average out-of-sample log-likelihood loss for different settings and models.\r\n5.2. Results\r\nIn Setting 1, the dataset is generated using an MNL model. In this case, the utility function is\r\nlinear and does not exhibit any heterogeneity. As a result, as illustrated in Figure 3a, the average\r\nlog-likelihood loss is insensitive to the complexity of the feed-forward neural network (\u2113, w) as well\r\nas the number of samples K. In Setting 2, we construct a non-linear utility function to generate\r\nthe synthetic dataset. As can be seen in Figure 3b, RUMnet is able to capture this non-linearity by\r\nincreasing the complexity of the the feed-forward neural network. In particular, as (\u2113, w) \u201cincreases\u201d,\r\nthe out-of-sample log-likelihood of RUMnet improves and it approaches that of the ground truth\r\nmodel, which is represented by the orange line. In this case, note that increasing K does not add\r\nmuch value. This is consistent with the fact that our ground truth model does not exhibit any\r\nform of customer heterogeneity. Unlike Setting 2, recall that Setting 3 has two customer classes\r\neach choosing according to a distinct MNL model. In this case, as illustrated in Figure 3c, the\r\nperformance of RUMnet improves with K but it is mostly insensitive to the complexity (\u2113, w) of the\r\nfeed-forward neural networks. Consequently, our synthetic experiments validate the value added of\r\neach component of our RUMnet architecture.\r\n5.3. Additional setting: non-contextual choice data\r\nRanking-based models are known to approximate random utility choice models in non-contextual\r\nsettings (Farias et al. 2013). In this setting, the observable product attributes x are a one-hot\r\nencoding of a finite universe of products. There are no observable customer attributes z (or equivalently, these are constant). While we are not aware of any method to estimate ranking-based\r\nmodels in contextual settings, we can easily implement RUMnets on non-contextual choice data.\r\nWe explore this approach in Appendix D.1 on synthetic data. We observe that RUMnets are competitive against an existing implementation of ranking-based models, both in terms of predictive\r\naccuracy and running times.\r\n17\r\n6. Numerical Estimation on Real Data\r\nWe test the predictive accuracy of RUMnets against a comprehensive set of benchmarks on two\r\nreal-world datasets, which reflect complementary choice prediction settings.\r\n6.1. Benchmarks\r\nWe implement various choice models and classification algorithms proposed in previous literature.\r\nMNL and neural network-based extensions. The first set of benchmarks comprises the MNL\r\nmodel and the two neural network-based extensions, TasteNet and DeepMNL, which we presented\r\nin Section 2.4. While the MNL model specifies a linear utility function, the subsequent models capture nonlinear effects of increasing complexity, and can be viewed as state-of-the-art benchmarks.\r\nFrom an implementation perspective, we formulate each of these models as a neural network with\r\na softmax prediction layer.\r\nModel-free approaches. In addition, we test two model-free benchmarks that treat the choice\r\nprediction task as a multi-label classification problem and forego any additional structure on the\r\nprobabilistic choices:\r\n1. Random Forest (RF): We train a variant of the random forests for choice prediction which\r\nwas very recently introduced by Chen et al. (2019) and Chen and Mi\u02c7si\u00b4c (2020). Importantly, these\r\npapers focus on a different observational setting, where the assortment composition varies but each\r\nproduct\u2019s attributes are essentially fixed. Due to contextual variations in product and customer attributes, we implement a featurized version of this methodology, which was suggested by Chen et al.\r\n(2019). We note that the optimization-based estimation methods developed by Chen and Mi\u02c7si\u00b4c\r\n(2020) are not easily applicable in this setting.\r\n2. Vanilla Neural Network (VNN): The input to this feed-forward neural network is the concatenation of all product and customer attributes. The output is a vector of length |A| that represents\r\nthe utility of each choice alternative, which is then passed through a softmax layer to compute the\r\ncorresponding choice probabilities.\r\n6.2. Implementation specifications\r\nExcept for the RF model, we implement all other benchmarks using Keras. Appendix E.1 details our\r\napproach for estimating the neural networks-based models. We use label smoothing as a norm-based\r\nregularization method on the neural network\u2019s outputs and specify Exponential Linear Unit (ELU)\r\nactivation functions (Clevert et al. 2015). For each model, we conduct an extensive parameter\r\nsearch in the training process. We use the validation set to tune the hyper-parameters on each\r\ndata split. We test different complexities for the building-block neural networks. In particular, for\r\neach neural network-based model, we vary the parameters (\u2113, w) \u2208 {(3, 10),(5, 20),(10, 30)}, where\r\n18\r\nTable 1 Out-of-sample predictive performance of the fitted choice models\r\nSwissmetro Expedia\r\nModel Log-likelihood loss Accuracy Log-likelihood loss Accuracy\r\nMNL 0.830\r\n(0.5 \u00b7 10\u22122)\r\n0.623\r\n(3.6 \u00b7 10\u22123)\r\n2.563\r\n(1.3 \u00b7 10\u22123)\r\n0.306\r\n(6.8 \u00b7 10\u22124)\r\nTasteNet 0.554\r\n(1.3 \u00b7 10\u22122)\r\n0.785\r\n(3.5 \u00b7 10\u22123)\r\n2.112\r\n(1.8 \u00b7 10\u22123)\r\n0.406\r\n(1.0 \u00b7 10\u22123)\r\nDeepMNL 0.560\r\n(1.5 \u00b7 10\u22122)\r\n0.778\r\n(5.2 \u00b7 10\u22123)\r\n2.049\r\n(2.5 \u00b7 10\u22123)\r\n0.417\r\n(1.0 \u00b7 10\u22123)\r\nRUMnet 0.546\r\n(1.5 \u00b7 10\u22122)\r\n0.797\r\n(5.4 \u00b7 10\u22123)\r\n2.018\r\n(2.1 \u00b7 10\u22123)\r\n0.425\r\n(5.6 \u00b7 10\u22124)\r\nVanilla Neural Network 0.584\r\n(1.2 \u00b7 10\u22122)\r\n0.756\r\n(4.3 \u00b7 10\u22123)\r\n2.677\r\n(4.6 \u00b7 10\u22123)\r\n0.312\r\n(1.2 \u00b7 10\u22123)\r\nRandom Forest 0.527\r\n(0.6 \u00b7 10\u22122)\r\n0.774\r\n(4.7 \u00b7 10\u22123)\r\n2.934\r\n(1.8 \u00b7 10\u22123)\r\n0.309\r\n(7.4 \u00b7 10\u22124)\r\nrecall that \u2113 denotes the depth of the network and w its width.5 For our RUMnet architecture, we\r\nalso vary number of samples K \u2208 {5, 10} controlling for the latent heterogeneity of customers and\r\nproducts. We report the performance of the DeepMNL model of Section 2.4, which is essentially a\r\nRUMnet model that does not capture any latent heterogeneity, i.e., K = 1. For RFs, we jointly vary\r\nthe number of trees in the forest in {50, 100, 200, 400} and the maximum tree depth in {5, 10, 20};\r\nwe then pick the forest with the best loss on the validation set.\r\nWe use 10-fold cross-validation and report the averaged log-likelihood loss and classification over\r\nthe ten splits. More precisely, we use a 80/10/10 split for the train/validation/test sets respectively.\r\nImportantly, the test set is never seen during training, which enables us to assess the out-of-sample\r\nperformance of the models. In addition to the log-likelihood loss defined in Equation (2), we also\r\nreport the accuracy, defined as the percentage of correct predictions for the chosen alternative.\r\n6.3. Results\r\nThe first dataset (Swissmetro data) consists of responses to a survey in Switzerland to assess the\r\npotential demand for a new mode of public transportation, called Swissmetro. The alternatives\r\ninclude Swissmetro, Train or Car (\u03ba = 3), and the number of observations in the data is in the\r\norder of 10K. The second one (Expedia data) is a larger dataset. This dataset counts around 400K\r\ndistinct search queries, 36 hotel features, and 56 customer and search features. This setting mirrors\r\nlarge-scale transaction data with assortments formed by many distinct alternatives (\u03ba = 39). More\r\ndetails on each dataset are presented in Appendices E.2 and E.3.\r\nThe predictive performance of the models is reported in Table 1. RUMnet emerges as the most\r\npredictive method out of the benchmarks in terms of accuracy. All the tested models significantly\r\n5 We omit certain instantiations of (\u2113, w) if the corresponding running times are prohibitive, or if the number of\r\nparameters becomes excessive.\r\n19\r\noutperform the basic MNL benchmark in terms of log-likelihood loss and prediction accuracy.\r\nThe gaps in the log-likelihoods exceed 20% on both datasets, thereby indicating that a linear\r\nutility-based model is too restrictive to predict choices in these settings accurately. Now, comparing\r\nTasteNets and DeepMNLs to RUMnets, we can attribute the gain in predictive performance to\r\nthe incorporation of latent heterogeneity. Table EC.5 in Appendix E.4 provides a more detailed\r\nperspective on the effects of the architecture design. Considering TasteNets and DeepMNLs, we\r\nsee that increasing the complexity of the neural networks from (\u2113, w) = (3, 10) to (\u2113, w) = (5, 20)\r\nimproves predictive performance; this phenomenon can be imputed to a more complex nonlinear\r\nutility function. However, there are no marginal gains from fitting even larger neural networks\r\n(\u2113, w) = (10, 30). These observations suggest that it is impossible to \u201cmake up\u201d for the lack of\r\nlatent heterogeneity using a more complex utility function. This aligns with our controlled synthetic\r\nexperiments in Section 5, where we varied the parametric and probabilistic specification of the\r\nground truth utility. The differences in predictive performance between RUMnets and DeepMNL\r\nare statistically significant only on Expedia data. In terms of log-likelihood loss, the paired t-tests\r\nwith respect to the 10 splits have p-values of 5.56 \u00b7 10\u22122 on Swissmetro data and 1.11 \u00b7 10\u22128 on\r\nExpedia data.\r\nThe model-free methods, RF and VNN, achieve strong predictive performance on the Swissmetro\r\ndata. In fact, RFs achieve lower negative log-likelihoods than RUMnets in that setting (although\r\nthe gap is not statistically significant with a paired t-test p-value of 0.134). In stark contrast, both\r\nmethods perform poorly on the Expedia dataset. We note that RFs suffer from a high level of\r\noverfitting, as indicated by the gap in performance on our training and test data (see Table EC.5,\r\nAppendix E.4).6 This noteworthy phenomenon might be related to the large number of distinct\r\nalternatives and the assortment size of Expedia data. Indeed, for such model-free methods, an\r\nexplosion of the number of parameters seems unavoidable as the input dimension increases (see\r\nTable EC.3, Appendix E.1). This potential explanation is supported by controlled synthetic experiments, which we present in the next section.\r\n6.4. Model-free methods on high-dimensional synthetic data\r\nAlthough the predictive performance of the random forest (RF) approach is comparable to that of\r\nRUMnet on the Swissmetro dataset, this method has a poor performance on the Expedia dataset\r\nwith a high level of overfitting (see Section 6.3). To explain this phenomenon, we hypothesize\r\nthat the performance of RFs degrades as the dimension of the underlying prediction problem\r\nincreases, i.e., the number of product and customer attributes and/or the number of distinct choice\r\n6 Note that the hyper-parameters of RFs are tuned using the validation set: our estimation method enables selecting\r\nsmaller tree depths or fewer trees in the forest. Yet, these choices do not result in better out-of-sample performance.\r\n20\r\n0 20 40 60 80 100\r\n1.5\r\n1.52\r\n1.54\r\n1.56\r\n1.58\r\n1.6\r\nNumber of products in the universe\r\nLog-likelihood loss\r\nRUMnet\r\nRandom forest\r\nRandom guess\r\nGround Truth\r\nFigure 4 Log-likelihood loss on the test set as a function of the number of products. RUMnet has parameters\r\n(\u2113, w) = (2, 5) and K = 5. Note that the y-axis log-likelihood losses vary from 1.48 to 1.61.\r\nalternatives which together determine the dimension of the RF inputs. In this section, we conduct\r\nsynthetic experiments that support this hypothesis.\r\nIn particular, we re-use Setting 1 of our synthetic experiments, described in Section 5. Recall\r\nthat in this setting, we generate observations using an MNL ground truth model. Each customer is\r\npresented with \u03ba products chosen uniformly randomly from a universe of P products. We fix \u03ba = 5\r\nand experiment with P \u2208 {5, 10, 25, 50, 100}. Each product is endowed with a vector of attributes\r\nx = (x1, x2, \u03b4) where x1 and x2 are picked uniformly over the interval [0, 1] and \u03b4 \u2208 R\r\nP\r\nis an\r\nindicator vector allowing us to introduce fixed effects for each product. Here, note that the input\r\nsize grows with the number of products in the universe P allowing to test how the performance of\r\nthe random forest scales with P. Moreover, for the random forest method, we vary the number of\r\ntrees in the forest in {200, 300, 400} and the maximum tree depth in {5, 10, 20}; we then pick the\r\nforest with the best loss on the validation set.\r\nFigure 4 shows the average log-likelihood loss on the test set averaged over ten splits . We also\r\nreport on this figure the average log-likelihood loss of the RUMnet model with parameters (\u2113, w) =\r\n(2, 5) and K = 5, as well as the average log-likelihood loss of a naive model, termed RandomGuess,\r\nthat prescribes a uniform choice probability distribution over the \u03ba offered products. We observe\r\nthat as P increases, the performance of RFs diverges from that of the ground truth model and\r\nnearly matches that of RandomGuess. This shows that when the input dimension is large, the\r\nrandom forest approach is unable to learn generalizable patterns from the data. On the other\r\nhand, the predictive performance of the RUMnet model is quite close to the ground truth model.\r\nAlthough this is expected because the ground truth model is in the RUM family, the performance\r\nof RUMnet is insensitive to the value of the number of products P, as P increases. This highlights\r\n21\r\n0\r\n0.2\r\n0.4\r\n0.6\r\n0.8\r\n1\r\n0.1 0.2 0.3\r\nCost of Swissmetro\r\nChoice probability\r\nTrain\r\nSwissMetro\r\nCar\r\n(a) Customer type 1\r\n0\r\n0.2\r\n0.4\r\n0.6\r\n0.8\r\n1\r\n0.1 0.2 0.3\r\nCost of Swissmetro\r\nChoice probability\r\nTrain\r\nSwissMetro\r\nCar\r\n(b) Customer type 2\r\n0\r\n0.2\r\n0.4\r\n0.6\r\n0.8\r\n1\r\n0.1 0.2 0.3\r\nCost of Swissmetro\r\nChoice probability\r\nTrain\r\nSwissMetro\r\nCar\r\n(c) Customer type 3\r\nFigure 5 Different substitution patterns predicted by DeepMNL with parameters (\u2113, w) = (2, 5).\r\nthat our method scales well with respect to the number of attributes and distinct products in the\r\nuniverse in contrast with model-free methods.\r\n6.5. Visualization\r\nNeural networks are often viewed as \u201cblack-box\u201d tools that are hard to interpret. Hence, it is\r\nimportant to explore what type of substitution patterns are captured by the fitted RUMnets and\r\ncontrast them with other methods. As a first step, we visualize how the RUMnet predictions vary\r\nas a function of the price, which is arguably one of the most important operational dimension, using\r\nthe Swissmetro dataset. In order to visualize how RUMnets predict the customers\u2019 substitution\r\npatterns, we use the K-means method to determine a balanced partition of the customer features\r\nand subsequently define the centroid of each cluster as a distinct customer type. Figure 5 plots\r\nthe predicted choice probabilities of each customer types as a function of the Swissmetro cost.\r\nOur clustering reveals three distinct choice behaviors: Customer 1 is mostly price insensitive and\r\nchooses the Swissmetro with high probability even when increasing its cost. Both Customers 2 and\r\n3 are price sensitive and choose the Swissmetro option when its cost is low enough. Interestingly,\r\nthey differ in what they substitute to when the cost of the Swissmetro is too high: Customer 2\r\nchooses the Train option whereas Customer 3 chooses the Car option.\r\nFor all customer types, the choice probability of the Swissmetro decreases with its cost. This\r\nshows that RUMnets capture realistic substitution patterns with respect to price. Note that in\r\npractice, these relationships may or may not be observed due to a variety of issues, including\r\nthe presence of endogeneity and overfitting. In fact, in the case of random forests, the predicted\r\nchoice probability for Swissmetro does not always decrease as its price increases. Figure EC.3\r\nin Appendix E.5 illustrates this phenomenon. This finding shows that model-free methods may\r\ncapture unrealistic dependencies on product attributes, in spite of their strong predictive accuracy.\r\n22\r\n7. Conclusion\r\nIn this paper, we introduce a new class of neural network-based choice models. Our neural network architecture, RUMnet, provides an efficient approximation of RUM discrete choice models.\r\nUnlike traditional RUM discrete choice models, which rely on specific structural and distributional\r\nassumptions, RUMnets leverage the universality of feed-forward neural networks to learn the structure of the random utility function from data. Moreover, our method is practical as RUMnets can\r\nbe trained using existing open-source libraries and achieves a competitive predictive performance.\r\nBy satisfying the RUM principle, we believe that our structured machine-learning approach yields\r\nbetter generalization to high-dimensional inputs than other model-free methods, as illustrated by\r\nour numerical findings. This work opens several intriguing research directions.\r\nFor instance, it might be possible to exploit the flexibility of the RUMnet architecture for\r\nmore complicated choice estimation problems such as multi-item and dynamic discrete choice. One\r\ndrawback of RUMnets is a larger computational cost compared to simpler neural network-based\r\narchitectures; it may be valuable to enhance our implementation for large-scale applications. Another important research avenue is to embed our neural network-based choice model in assortment\r\noptimization and pricing decision problems.\r\nReferences\r\nAlptekino\u02d8glu, Ayd\u0131n, John H Semple. 2016. The exponomial choice model: A new alternative for\r\nassortment and price optimization. Operations Research 64(1) 79\u201393.\r\nAlptekino\u02d8glu, Ayd\u0131n, John H Semple. 2021. Heteroscedastic exponomial choice. Operations Research 69(3) 841\u2013858.\r\nBartlett, Peter L, Shahar Mendelson. 2002. Rademacher and gaussian complexities: Risk bounds\r\nand structural results. Journal of Machine Learning Research 3(Nov) 463\u2013482.\r\nBentz, Yves, Dwight Merunka. 2000. Neural networks and the multinomial logit for brand choice\r\nmodelling: a hybrid approach. Journal of Forecasting 19(3) 177\u2013200.\r\nBerbeglia, Gerardo. 2018. The generalized stochastic preference choice model. arXiv preprint\r\narXiv:1803.04244 .\r\nBerbeglia, Gerardo, Agust\u00b4\u0131n Garassino, Gustavo Vulcano. 2022. A comparative empirical study of\r\ndiscrete choice models in retail operations. Management Science 68(6) 4005\u20134023.\r\nBierlaire, M. 2018. Swissmetro. URL: https://transpor. epfl. ch/documents/technicalReports/CS SwissmetroDescription. pdf .\r\n23\r\nChen, Ningyuan, Guillermo Gallego, Zhuodong Tang. 2019. The use of binary choice forests to\r\nmodel and estimate discrete choices. Available at SSRN 3430886 .\r\nChen, Yi-Chun, Velibor Mi\u02c7si\u00b4c. 2020. Decision forest: A nonparametric approach to modeling\r\nirrational choice. Available at SSRN 3376273 .\r\nChierichetti, Flavio, Ravi Kumar, Andrew Tomkins. 2018. Discrete choice, permutations, and\r\nreconstruction. Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete\r\nAlgorithms. SIAM, 576\u2013586.\r\nChollet, Fran\u00b8cois, et al. 2015. Keras. https://keras.io.\r\nClevert, Djork-Arn\u00b4e, Thomas Unterthiner, Sepp Hochreiter. 2015. Fast and accurate deep network\r\nlearning by exponential linear units (elus). arXiv preprint arXiv:1511.07289 .\r\nCortes, Corinna, Mehryar Mohri, Afshin Rostamizadeh. 2013. Multi-class classification with maximum margin multiple kernel. International Conference on Machine Learning. PMLR, 46\u201354.\r\nFarias, Vivek F, Srikanth Jagabathula, Devavrat Shah. 2013. A nonparametric approach to modeling choice with limited data. Management science 59(2) 305\u2013322.\r\nFeldman, Jacob, Dennis Zhang, Xiaofei Liu, Nannan Zhang. 2018. Customer choice models versus\r\nmachine learning: Finding optimal product displays on alibaba. Available at SSRN 3232059 .\r\nFeng, Qi, J George Shanthikumar, Mengying Xue. 2022. Consumer choice models and estimation:\r\nA review and extension. Production and Operations Management 31(2) 847\u2013867.\r\nGabel, Sebastian, Artem Timoshenko. 2021. Product choice with large assortments: A scalable\r\ndeep-learning model. Management Science .\r\nHan, Yafei, Christopher Zegras, Francisco Camara Pereira, Moshe Ben-Akiva. 2020. A neuralembedded choice model: TasteNet-MNL modeling taste heterogeneity with flexibility and\r\ninterpretability. arXiv:2002.00922 .\r\nHornik, Kurt. 1991. Approximation capabilities of multilayer feedforward networks. Neural networks 4(2) 251\u2013257.\r\nHornik, Kurt, Maxwell Stinchcombe, Halbert White. 1989. Multilayer feedforward networks are\r\nuniversal approximators. Neural networks 2(5) 359\u2013366.\r\nJiang, Zhaohui Zoey, Jun Li, Dennis Zhang. 2020. A high-dimensional choice model for online\r\nretailing. Available at SSRN 3687727 .\r\nKidger, Patrick, Terry Lyons. 2020. Universal approximation with deep narrow networks. Conference on learning theory. PMLR, 2306\u20132327.\r\n24\r\nKoltchinskii, Vladimir, Dmitriy Panchenko. 2000. Rademacher processes and bounding the risk of\r\nfunction learning. High dimensional probability II. Springer, 443\u2013457.\r\nLuce, R.D. 1959. Individual choice behavior: A theoretical analysis. Wiley.\r\nMaurer, Andreas. 2016. A vector-contraction inequality for rademacher complexities. International\r\nConference on Algorithmic Learning Theory. Springer, 3\u201317.\r\nMcFadden, Daniel. 1974. Conditional logit analysis of qualitative choice behavior. Frontiers in\r\nEconometrics 2 105\u2013142.\r\nMcFadden, Daniel, Kenneth Train. 2000. Mixed mnl models for discrete response. Journal of\r\napplied Econometrics 15(5) 447\u2013470.\r\nMohri, Mehryar, Afshin Rostamizadeh, Ameet Talwalkar. 2018. Foundations of machine learning.\r\nMIT press.\r\nM\u00a8uller, Rafael, Simon Kornblith, Geoffrey E Hinton. 2019. When does label smoothing help?\r\nAdvances in neural information processing systems 32.\r\nNeyshabur, Behnam, Ryota Tomioka, Nathan Srebro. 2015. Norm-based capacity control in neural\r\nnetworks. Conference on learning theory. PMLR, 1376\u20131401.\r\nRosenfeld, Nir, Kojin Oshiba, Yaron Singer. 2020. Predicting choice with set-dependent aggregation. International Conference on Machine Learning. PMLR, 8220\u20138229.\r\nRusmevichientong, Paat, Benjamin Van Roy, Peter W Glynn. 2006. A nonparametric approach to\r\nmultiproduct pricing. Operations Research 54(1) 82\u201398.\r\nShalev-Shwartz, Shai, Shai Ben-David. 2014. Understanding machine learning: From theory to\r\nalgorithms. Cambridge university press.\r\nSifringer, Brian, Virginie Lurkin, Alexandre Alahi. 2020. Enhancing discrete choice models with\r\nrepresentation learning. Transportation Research Part B: Methodological 140 236\u2013261.\r\nSzegedy, Christian, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, Zbigniew Wojna. 2016. Rethinking the inception architecture for computer vision. Proceedings of the IEEE conference on\r\ncomputer vision and pattern recognition. 2818\u20132826.\r\nTrain, Kenneth E. 2009. Discrete Choice Methods with Simulation. Cambridge University Press,\r\nCambridge, United Kingdom.\r\nWang, Shenhao, Baichuan Mo, Jinhua Zhao. 2020. Deep neural networks for choice analysis:\r\nArchitecture design with alternative-specific utility functions. Transportation Research Part\r\nC: Emerging Technologies 112 234\u2013251.\r\n25\r\nWang, Shenhao, Baichuan Mo, Jinhua Zhao. 2021a. Theory-based residual neural networks: A\r\nsynergy of discrete choice models and deep neural networks. Transportation research part B:\r\nmethodological 146 333\u2013358.\r\nWang, Shenhao, Qingyi Wang, Nate Bailey, Jinhua Zhao. 2021b. Deep neural networks for choice\r\nanalysis: A statistical learning theory perspective. Transportation Research Part B: Methodological 148 60\u201381.\r\nWilliams, H.C.W.L. 1977. On the formation of travel demand models and economic evaluation\r\nmeasures of user benefit. Environment and Planning A 3(9) 285\u2013344.\r\nWong, Melvin, Bilal Farooq. 2019. Reslogit: A residual neural network logit model.\r\narXiv:1912.10058 .\r\ne-companion to : Random Utility Maximization: Revisited ec1\r\nThis page is intentionally blank. Proper e-companion title\r\npage, with INFORMS branding and exact metadata of the\r\nmain paper, will be produced by the INFORMS office when\r\nthe issue is being assembled.\r\nec2 e-companion to : Random Utility Maximization: Revisited\r\nOnline Appendix\r\nRepresenting Random Utility Choice Models with Neural\r\nNetworks\r\nThe Appendix is organized as follows.\r\n\u2022 Appendix A provides additional material for Section 2.\r\n\u2022 Appendix B contains the proofs of Section 3.\r\n\u2022 Appendix C contains the proofs of Section 4.\r\n\u2022 Appendix D provides additional material for Section 5.\r\n\u2022 Appendix E provides additional material for Section 6.\r\ne-companion to : Random Utility Maximization: Revisited ec3\r\nAppendix A: Additional material for Section 2\r\nA feed-forward neural network is specified by a directed acyclic graph, G = (V, E). Each edge e \u2208 E\r\nis associated with a weight we \u2208 R. Each node of the graph, called a neuron, is associated with an\r\nactivation function \u03c3 : R \u2192 R. Each edge in the graph links the output of some neuron to the input\r\nof another neuron. The input of a neuron is obtained by taking a weighted sum of the outputs of\r\nall neuron connected to it. We assume that the nodes are organized in layers, i.e. the set of nodes is\r\npartitioned in disjoint subsets V = \u222a\r\nT\r\nt=0Vt\r\n, such that every edge in E connects some node in Vt\u22121 to\r\nsome node in Vt\r\n, for some t \u2208 [T]. We denote by vi,t \u2208 Vt the i\r\nth neuron of the t\r\nth layer. Moreover,\r\nfor any input x to the network and vi,t \u2208 Vt\r\n, we let oi,t(x) (resp. ai,t(x)) denotes the output (resp.\r\ninput) of vi,t. Then,\r\nai,t+1 =\r\nX\r\nj:e=(vj,t,vi,t+1)\u2208E\r\nwe \u00b7 oj,t(x),\r\nand\r\noi,t+1(x) = \u03c3(ai,t+1(x)).\r\nThe first layer V0 is called the input layer and the last layer VT is the output layer which often\r\ncontains a single neuron. The layers V1, . . . , VT \u22121 are called the hidden layers. We refer to T as the\r\ndepth of the network. The width of the network is maxt=1,...,T \u22121 |Vt\r\n| and its size is |V |. Figure EC.1\r\nillustrates a feed-forward network of depth 2. Feed-forward neural networks are able to capture\r\ncomplex nonlinear patterns and have been shown to be a class of universal approximators. That\r\nis, under mild conditions, the class of neural networks S\r\nk\u22651 \u0398\r\n1,k\r\nk with only one hidden layer and\r\none output unit is dense in the space of continuous functions over a compact domain X, e.g., this\r\nv0,1\r\nv0,2\r\nv0,3\r\nv1,1\r\nv1,2\r\nv1,3\r\nv1,4\r\nv1,5\r\nv2,1\r\nv2,2\r\nv2,3\r\nv2,4\r\nv2,5\r\nv3,1\r\nv3,2\r\nx1\r\nx2\r\nx3\r\nOuput 1\r\nOutput 2\r\nInput Input layer Hidden layers Output layer Output\r\nFigure EC.1 An example of feed-forward neural network.\r\nec4 e-companion to : Random Utility Maximization: Revisited\r\nresult holds for any continuous, bounded and non-constant activation function (Hornik et al. 1989,\r\nHornik 1991).\r\ne-companion to : Random Utility Maximization: Revisited ec5\r\nAppendix B: Proofs of Section 3\r\nB.1. A preliminary result\r\nIn the RUM framework, recall that we are interested in the ordering of the utilities for different\r\nalternatives. Indeed, for every x 6= x\r\n\u2032\r\n, the inequality U(x, \u01eb(x), z,\u03bd(z)) \u2265 U(x\r\n\u2032\r\n, \u01eb(x\r\n\u2032\r\n), z,\u03bd(z)) implies that x is preferred to x\r\n\u2032 by the corresponding random customer. The following lemma shows\r\nthat it is sufficient to approximate U(\u00b7) on a finite covering C in order to capture the desired\r\nordering relations of all possible pairs (x,x\r\n\u2032\r\n) \u2208 X 2 and customer attribute z with high probability. Throughout our analysis, the space of product and customer attributes is endowed with the\r\n\u2113\u221e-norm unless stated otherwise. We denote by B(c, \u03b4) the open ball centred on c with radius \u03b4.\r\nLemma EC.1 (Part of Theorem 1 in McFadden and Train 2000). For every \u03b7 > 0,\r\nthere exists a finite covering (B(c, \u03b4(c)))c\u2208C with centers C \u2282 X 2 \u00d7 Z, radii (\u03b4(c))c\u2208C > 0, and integers (n(c))c\u2208C such that, given a fixed c = (x\u02c6,x\u02c6\r\n\u2032\r\n, z\u02c6) \u2208 C, with probability at least 1 \u2212 3\u03b7/4\u03ba, we\r\nhave for all (x,x\r\n\u2032\r\n, z) \u2208 X 2 \u00d7 Z in the neighborhood of (x\u02c6,x\u02c6\r\n\u2032\r\n, z\u02c6) that:\r\n1. |U(x, \u01eb(x), z,\u03bd(z)) \u2212 U(x\u02c6, \u01eb(x\u02c6), z\u02c6,\u03bd(z\u02c6))| \u2264 1/n(c),\r\n2. |U(x\r\n\u2032\r\n, \u01eb(x\r\n\u2032\r\n), z,\u03bd(z)) \u2212 U(x\u02c6\r\n\u2032\r\n, \u01eb(x\u02c6\r\n\u2032\r\n), z\u02c6,\u03bd(z\u02c6))| \u2264 1/n(c).\r\n3. |U(x, \u01eb(x), z,\u03bd(z)) \u2212 U(x\r\n\u2032\r\n, \u01eb(x\r\n\u2032\r\n), z,\u03bd(z))| \u2265 5/n(c).\r\nThe above lemma formalizes the main step in the proof of the celebrated result of\r\nMcFadden and Train (2000) showing that continuous mixtures of MNL models uniformly approximate the class of RUMS. The proof of this result exploits the uniform continuity of U(\u00b7), \u01eb(x) and\r\n\u03bd(z) for all (x, z) \u2208 X \u00d7 Z. For completeness, the proof of Lemma EC.1 is given below; note that\r\nthe statement of this result is implicit in McFadden and Train (2000), who base their analysis on\r\nslightly weaker properties of the covering.\r\nProof. Recall that \u01eb(\u00b7) and \u03bd(\u00b7) are random fields over X and Z respectively. For analysis\r\npurposes, we make the underlying probability space (\u2126,W,Pr\u03c9) explicit. In particular, we denote\r\nby \u01eb(w,x) (resp. \u03bd(w, z)) a particular realization of \u01eb(x) (resp. \u03bd(z)). Consequently, for every\r\n(w,x, z) \u2208 \u2126 \u00d7 X \u00d7 Z, we use the compact notation F(\u03c9,x, z) = U (x, \u01eb(\u03c9,x), z,\u03bd(\u03c9, z)). Recall\r\nthat for all choice events (z, A) and x \u2208 A, we have\r\n\u03c0(x, z, A) = Pr\u03c9[F(\u03c9,x, z) > F(\u03c9,x\r\n\u2032\r\n, z), \u2200x\r\n\u2032 \u2208 A\\x].\r\nThe remainder of the proof proceeds in three steps.\r\n1. The utilities are sufficiently different for distinct alternatives. For every (x,x\r\n\u2032\r\n, z) \u2208 X 2 \u00d7 Z\r\nand n \u2208 N+, let\r\n\u2126n(x,x\r\n\u2032\r\n, z) = {\u03c9 \u2208 \u2126 : |F(\u03c9,x, z) \u2212 F(\u03c9,x\r\n\u2032\r\n, z)| \u2265 7/n} .\r\nec6 e-companion to : Random Utility Maximization: Revisited\r\nThe continuity of U(\u00b7) and the measurability of the random fields \u01eb(\u00b7) and \u03bd(\u00b7) imply that\r\n\u2126n(x,x\r\n\u2032\r\n, z) is measurable. This set is monotone increasing as n \u2192 \u221e to the set of \u03c9 for which the\r\nalternatives x and x\r\n\u2032 are not tied. By hypothesis, this set has probability one, implying that there\r\nexists \u00afn = n(x,x\r\n\u2032\r\n, z) \u2208 N+ such that we have Pr\u03c9[\u2126n\u00af(x,x\r\n\u2032\r\n, z)] \u2265 1 \u2212 \u03b7/4\u03ba.\r\n2. There exists a neighborhood where utility remains controlled for distinct alternatives. Fix\r\n(x,x\r\n\u2032\r\n, z) \u2208 X 2 \u00d7 Z. The uniform continuity of U(\u00b7) on X \u00d7 [0, 1]dx \u00d7 Z \u00d7 [0, 1]dz\r\nimplies that, for\r\nevery given \u00afn \u2208 N+, there exists \u00af\u03b4 = \u03b4(x,x\r\n\u2032\r\n, z) \u2208 R+ such that in a neighborhood of size \u00af\u03b4, U(\u00b7)\r\nvaries by less than 1/n\u00af. Moreover, the almost certain continuity of \u01eb(\u03c9,x) and \u03bd(\u03c9, z) implies that\r\nBm(x, z) = (\r\n\u03c9 \u2208 \u2126 : sup\r\n|x\u2212x\u2217|<1/m\r\n|\u01eb(\u03c9,x) \u2212 \u01eb(\u03c9,x\r\n\u2217\r\n)| + sup\r\n|z\u2212z\u2217|<1/m\r\n|\u03bd(\u03c9, z) \u2212 \u03bd(\u03c9, z\r\n\u2217\r\n)| \u2264\r\n\u00af\u03b4\r\n2\r\n)\r\n,\r\nand the corresponding event Bm(x\r\n\u2032\r\n, z) are monotone increasing as m \u2192 \u221e to limiting events\r\nthat occur with probability one. Consequently, there exists \u00afm = m(x,x\r\n\u2032\r\n, z) \u2208 N+ such that\r\nPr\u03c9[Bm\u00af (x, z)] \u2265 1 \u2212 \u03b7/4\u03ba and Pr\u03c9[Bm\u00af (x\r\n\u2032\r\n, z)] \u2265 1 \u2212 \u03b7/4\u03ba.\r\n3. Finite covering. We have established so far that Pr\u03c9[\u2126n\u00af (x,x\r\n\u2032\r\n, z) \u2229 Bm\u00af (x, z) \u2229 Bm\u00af (x\r\n\u2032\r\n, z)] \u2265\r\n1 \u2212 3\u03b7/4\u03ba, noting that \u03c9 \u2208 \u2126n\u00af(x,x\r\n\u2032\r\n, z) \u2229 Bm\u00af (x, z) \u2229 Bm\u00af (x\r\n\u2032\r\n, z) implies:\r\n(a) |F(\u03c9,x, z) \u2212 F(\u03c9,x\r\n\u2032\r\n, z)| \u2265 7/n\u00af ,\r\n(b) For all (x\u02c6,x\u02c6\r\n\u2032\r\n, z\u02c6) \u2208 in the open ball centered on (x,x\r\n\u2032\r\n, z) with radius min{1/m, \u00af\r\n\u00af\u03b4/2}, we have\r\n|F(\u03c9,x\u02c6, z\u02c6) \u2212 F(\u03c9,x, z)| \u2264 1/n\u00af and |F(\u03c9,x\u02c6\r\n\u2032\r\n, z\u02c6) \u2212 F(\u03c9,x\r\n\u2032\r\n, z)| \u2264 1/n\u00af.\r\nThe above neighborhoods specify a covering of the compact set X \u00d7 X \u00d7 Z, from which we extract\r\na finite subcovering C. Hence, we have just shown that each (x\u02c6,x\u02c6\r\n\u2032\r\n, z\u02c6) \u2208 X \u00d7 X \u00d7 Z falls in some\r\nneighborhood centered on (x,x\r\n\u2032\r\n, z) \u2208 C such that for all \u03c9 \u2208 \u2126n\u00af (x,x\r\n\u2032\r\n, z) \u2229 Bm\u00af (x, z) \u2229 Bm\u00af (x\r\n\u2032\r\n, z):\r\n|F(\u03c9,x\u02c6, z\u02c6) \u2212 F(\u03c9,x\u02c6\r\n\u2032\r\n, z\u02c6)|\r\n\u2265 |F(\u03c9,x, z) \u2212 F(\u03c9,x\r\n\u2032\r\n, z)| \u2212 |F(\u03c9,x\u02c6, z\u02c6) \u2212 F(\u03c9,x, z)| \u2212 |F(\u03c9,x\u02c6\r\n\u2032\r\n, z\u02c6) \u2212 F(\u03c9,x\r\n\u2032\r\n, z)|\r\n\u2265 7/n(x,x\r\n\u2032\r\n, z) \u2212 1/n(x,x\r\n\u2032\r\n, z) \u2212 1/n(x,x\r\n\u2032\r\n, z)\r\n\u2265 5/n(x,x\r\n\u2032\r\n, z) .\r\n\r\nB.2. Proof of Proposition 1\r\nWe now present the proof of Proposition 1, which proceeds linearly in showing that we can control\r\nthe errors in the successive layers of approximation of the utility function. Let C denote the\r\nfinite covering and N\u00af = max{n(c) : c \u2208 C} that satisfy the properties stated in Lemma EC.1. Let\r\nN \u2265 max{\u2212log(\u03b7/4\u03ba), N\u00af} be a sufficiently large integer that will be determined later on. Recall\r\nthat \u01eb(\u00b7) and \u03bd(\u00b7) are random fields over X and Z respectively. As in the proof of Lemma EC.1, we\r\ne-companion to : Random Utility Maximization: Revisited ec7\r\nexplicitly describe this randomness. In particular, we introduce a fundamental probability space\r\n(\u2126,W,Pr\u03c9) and denote by \u01eb(w,x) (resp. \u03bd(w, z)) a particular realization of \u01eb(x) (resp. \u03bd(z)). For\r\nease of notation, we let for (w,x, z) \u2208 \u2126 \u00d7 X \u00d7 Z,\r\nF(\u03c9,x, z) = U (x, \u01eb(\u03c9,x), z,\u03bd(\u03c9, z)).\r\nRecall that for all choice event (z, A) and x \u2208 A, we have\r\n\u03c0(x, z, A) = Pr\u03c9[F(\u03c9,x, z) > F(\u03c9,x\r\n\u2032\r\n, z), \u2200x\r\n\u2032 \u2208 A\\x].\r\nStep 1: Universal approximation and discretization. Feed-forward neural networks are a known\r\nclass of universal approximators. More specifically, the space of feed-forward neural networks with\r\nonly one hidden layer and one output unit is dense in C(X), the space of continuous function on\r\nX, under the conditions that X is compact and the activation function is continuous, bounded and\r\nnon-constant (Hornik et al. 1989, Hornik 1991). This result is extended for networks of bounded\r\nwidth and arbitrary depth and any nonaffine continuous activation function by Kidger and Lyons\r\n(2020). Consequently, there exists a feed-forward neural network NU (\u00b7) that approximates U(\u00b7) on\r\nX \u00d7 [0, 1]d\u01eb \u00d7 Z \u00d7 [0, 1]d\u03bd\r\n, i.e., that satisfies kU(\u00b7) \u2212 NU (\u00b7)k\u221e \u2264 1/N.\r\nBy the uniform continuity of U(\u00b7), there exist \u03b4 > 0, such that for all (x, z) \u2208 X \u00d7 Z and (\u01eb, \u01eb\r\n\u2032\r\n) \u2208\r\n[0, 1]2d\u01eb and (\u03bd,\u03bd\r\n\u2032\r\n) \u2208 [0, 1]2d\u03bd such that k\u01eb \u2212 \u01eb\r\n\u2032k\u221e \u2264 \u03b4 and k\u03bd \u2212 \u03bd\r\n\u2032k\u221e \u2264 \u03b4, we have |U(x, \u01eb, z,\u03bd) \u2212\r\nU(x, \u01eb\r\n\u2032\r\n, z,\u03bd\r\n\u2032\r\n)| \u2264 1/N. For every \u03c9 \u2208 \u2126, there exist feed-forward neural networks N\u01eb,\u03c9(x) and N\u03bd,\u03c9(z)\r\nthat approximate \u01eb(\u03c9,x) and \u03bd(\u03c9, z) on X and Z respectively, i.e., k\u01eb(\u03c9,x) \u2212 N\u01eb,\u03c9(x)k\u221e \u2264 \u03b4 for\r\nall x \u2208 X and k\u03bd(\u03c9, z)\u2212 N\u03bd,\u03c9(z)k\u221e \u2264 \u03b4 for all z \u2208 Z. Consequently, for all x \u2208 X , \u03c9 \u2208 \u2126 and z \u2208 Z,\r\nwe have\r\n|U(x, \u01eb(\u03c9,x), z,\u03bd(\u03c9, z)) \u2212 NU(x, N\u01eb,\u03c9(x), z, N\u03bd,\u03c9(z))| \u2264 2\r\nN\r\n, (EC.1)\r\nsince |NU (x, N\u01eb,\u03c9(x), z, N\u03bd,\u03c9(z))\u2212U(x, N\u01eb,\u03c9(x), z, N\u03bd,\u03c9(z))| \u2264 1/N in light of the uniform approximation of U(\u00b7) by NU (\u00b7) and |U(x, N\u01eb,\u03c9(x), z, N\u03bd,\u03c9(z))\u2212U(x, \u01eb(\u03c9,x), z,\u03bd(\u03c9, z))| \u2264 1/N due to the\r\nuniform continuity of U(\u00b7).\r\nStep 2: Adding noise. Throughout the remainder of the proof, we fix a choice set A, an alternative\r\nx \u2208 A, and customer attributes z \u2208 Z. For each x \u2208 A, we define a utility F\r\n1\r\n(\u00b7) as follows:\r\nF\r\n1\r\n(\u03c9, \u03b4x,x, z) = NU (x, N\u01eb,\u03c9(x), z, N\u03bd,\u03c9(z)) + \u03b4x\r\nN2\r\n, (EC.2)\r\nwhere \u03b4 = {\u03b4x}x\u2208A is a sequence i.i.d. random variables following a standard Gumbel distribution.\r\nLet\r\n\u03c0\r\n1\r\n(x, z, A) = Pr\u03c9,\u03b4[F\r\n1\r\n(\u03c9, \u03b4x,x, z) > F1\r\n(\u03c9, \u03b4x\u2032,x\r\n\u2032\r\n, z), \u2200x\r\n\u2032 \u2208 A\\{x}],\r\nec8 e-companion to : Random Utility Maximization: Revisited\r\nbe the choice probability associated with the utility F\r\n1\r\n(\u00b7). For all x\r\n\u2032 \u2208 A\\{x}, let\r\n\u2126\r\n1\r\nx,x\u2032 = {\u03c9 \u2208 \u2126,(\u03b4x, \u03b4x\u2032) \u2208 R\r\n2\r\n: (F(\u03c9,x, z) \u2212 F(\u03c9,x\r\n\u2032\r\n, z)) \u00d7 (F\r\n1\r\n(\u03c9, \u03b4x,x, z) \u2212 F\r\n1\r\n(\u03c9, \u03b4x\u2032,x\r\n\u2032\r\n, z)) < 0}\r\nbe the collection of realisations for which the preferences over alternatives x and x\r\n\u2032 are reversed\r\nwhen using F\r\n1\r\n(\u00b7) instead of F(\u00b7). Note that\r\n|\u03c0(x, z, A) \u2212 \u03c0\r\n1\r\n(x, z, A)| \u2264 Pr\r\n\uf8ee\r\n\uf8f0\r\n[\r\nx\u2032\u2208A\\{x}\r\n\u2126\r\n1\r\nx,x\u2032\r\n\uf8f9\r\n\uf8fb \u2264\r\nX\r\nx\u2032\u2208A\\{x}\r\nPr\r\n\u2126\r\n1\r\nx,x\u2032\r\n\r\n\u2264 \u03ba \u00b7Pr\r\n\u2126\r\n1\r\nx,x\u2032\r\n\r\n,\r\nwhere the first inequality holds follows by noting that for F\r\n1\r\n(\u00b7) to designate x as the the highestutility alternative in the choice set A, while F(\u00b7) designates a different alternative x\r\n\u2032\r\nin the choice\r\nset A, there needs to be a reversal of preferences between x and x\r\n\u2032\r\n. The second inequality follows\r\nfrom the union bound. Without loss of generality, consider \u03c9 \u2208 \u2126 and (\u03b4x, \u03b4x\u2032) \u2208 R\r\n2\r\nsuch that\r\nF(\u03c9,x, z) > F(\u03c9,x\r\n\u2032\r\n, z) and F\r\n1\r\n(\u03c9, \u03b4x,x, z) < F1\r\n(\u03c9, \u03b4x\u2032,x\r\n\u2032\r\n, z).\r\nIf |F(\u03c9,x, z) \u2212 F(\u03c9,x\r\n\u2032\r\n, z)| > 5/N, then\r\n0 > F1\r\n(\u03c9, \u03b4x,x, z) \u2212 F\r\n1\r\n(\u03c9, \u03b4x\u2032,x\r\n\u2032\r\n, z)\r\n= NU (x, N\u01eb,\u03c9(x), z, N\u03bd,\u03c9(z)) \u2212 NU(x\r\n\u2032\r\n, N\u01eb,\u03c9(x\r\n\u2032\r\n), z, N\u03bd,\u03c9(z)) + (\u03b4x \u2212 \u03b4x\u2032)\r\n> F(\u03c9,x, z) \u2212 F(\u03c9,x\r\n\u2032\r\n, z) \u2212 4/N + (\u03b4x \u2212 \u03b4x\u2032)/N2\r\n\u2265 1/N + (\u03b4x \u2212 \u03b4x\u2032)/N2\r\n,\r\nwhere the second inequality holds by Equation (EC.1). Consequently, \u03b4x \u2212 \u03b4x\u2032 \u2264 \u2212N. Under the\r\nGumbel assumption, we have for N \u2265 \u2212log(\u03b7/4\u03ba), Pr\u03b4[\u03b4x \u2212\u03b4x\u2032 \u2264 \u2212N] < \u03b7/4\u03ba. From Lemma EC.1,\r\nthe probability that |F(\u03c9,x, z) \u2212 F(\u03c9,x\r\n\u2032\r\n, z)| \u2264 5/N is at most 3\u03b7/4\u03ba. Consequently, Pr\r\n\u2126\r\n1\r\nx,x\u2032\r\n\r\n\u2264\r\n\u03b7/\u03ba which in turn implies that\r\n|\u03c0(x, z, A) \u2212 \u03c0\r\n1\r\n(x, z, A)| \u2264 \u03b7. (EC.3)\r\nStep 3: Sampling error. For purposes of analysis, we need to refine the finite covering constructed in Lemma EC.1. In particular, for every x \u2208 X , z \u2208 Z, \u03c9 \u2208 \u2126 and \u03b4 \u2208 R, we define the\r\nmapping F\u00af1\r\n(\u03c9,x, z) = NU (x, N\u01eb,\u03c9(x), z, N\u03bd,\u03c9(z)). Next, we construct a finite covering that is mutually adapted to F and F\u00af1\r\nin the sense of Lemma EC.1. Specifically, there exists a finite covering\r\n(B(c, \u03b4+(c)))c\u2208C+ with centers C\r\n+ \u2286 X 2 \u00d7 Z, radii (\u03b4\r\n+(c))c\u2208C+, and integers (n\r\n+(c))c\u2208C+ such that,\r\ngiven a fixed c = (x\u02dc,x\u02dc\r\n\u2032\r\n, z\u02dc) \u2208 C\r\n+, with probability at least 1 \u2212 3\u03b7/4\u03ba , we have for all (x,x\r\n\u2032\r\n, z) \u2208\r\nX\r\n2 \u00d7 Z in the neighborhood of (x\u02dc,x\u02dc\r\n\u2032\r\n, z\u02dc) that:\r\n1. |F\u00af1\r\n(\u03c9,x, z) \u2212 F\u00af1\r\n(\u03c9,x\u02dc, z\u02dc)| \u2264 1/n+(c) and |F(\u03c9,x, z) \u2212 F(\u03c9,x\u02dc, z\u02dc)| \u2264 1/n+(c),\r\ne-companion to : Random Utility Maximization: Revisited ec9\r\n2. |F\u00af1\r\n(\u03c9,x\r\n\u2032\r\n, z) \u2212 F\u00af1\r\n(\u03c9,x\u02dc\r\n\u2032\r\n, z\u02dc)| \u2264 1/n+(c) and |F(\u03c9,x\r\n\u2032\r\n, z) \u2212 F(\u03c9,x\u02dc\r\n\u2032\r\n, z\u02dc)| \u2264 1/n+(c),\r\n3. |F\u00af1\r\n(\u03c9,x, z\u02dc) \u2212 F\u00af1\r\n(\u03c9,x\r\n\u2032\r\n, z\u02dc)| \u2265 5/n+(c) and |F(\u03c9,x, z\u02dc) \u2212 F(\u03c9,x\r\n\u2032\r\n, z\u02dc)| \u2265 5/n+(c).\r\nConsequently, we set the precise value of N as N = max{\u2212log(\u03b7/8\u03ba), N, \u00af max{n\r\n+(c) : c \u2208 C\r\n+}}.\r\nNext, we construct a mapping from any choice set A to A\u02c6 = {x\u02c61, . . . ,x\u02c6K}, where each alternative\r\nx \u2208 A is replaced by a fixed element x\u02c6 of T\r\nc\u2208C+(x)\r\n{y1 : y \u2208 B(c, \u03b4+(c))}, where C\r\n+(x) denotes\r\nall the centers c \u2208 C\r\n+ such that (x, c2, c3) \u2208 B(c, \u03b4+(c)). Note that the latter intersection of open\r\nballs is non-empty since it contains x. Similarly, each z \u2208 Z is mapped to a fixed element z\u02c6 of\r\nT\r\nc\u2208C+(z)\r\n{y3 : y \u2208 B(c, \u03b4+(c))}, where C\r\n+(z) denotes all the centers c \u2208 C\r\n+ such that (c1, c2, z) \u2208\r\nB(c, \u03b4+(c)). We denote by E the collection of all choice events (x\u02c6, z, \u02c6 A\u02c6) generated by this mapping.\r\nSince the covering C\r\n+ is finite, E is also finite. We establish the following claim in Appendix B.3,\r\nshowing that all choice events can be approximated by those in E, with only small changes in their\r\nchoice probabilities \u03c0, \u03c01\r\n.\r\nClaim EC.1. For every choice event (x, z, A) \u2208 X \u00d7 Z \u00d7 X \u03ba\u22121\r\n, we have\r\n|\u03c0(x, z, A) \u2212 \u03c0(x\u02c6, z\u02c6,A\u02c6)| \u2264 \u03b7 and |\u03c0\r\n1\r\n(x, z, A) \u2212 \u03c0\r\n1\r\n(x\u02c6, z\u02c6,A\u02c6)| \u2264 \u03b7 . (EC.4)\r\nNow, the final piece of our proof is to construct a sample average approximation of \u03c0\r\n1\r\n(\u00b7) with respect\r\nto \u03c9. Let \u03c9\u02c6 = (\u02c6\u03c91, . . . ,\u03c9\u02c6K) be K i.i.d. samples based on the probabilistic space (\u2126,W,Pr\u03c9) where\r\nthe precise value of K is specified later on. We define the sampled utility function F\r\n2,k(\u03b4x,x, z) as\r\nfollows:\r\nF\r\n2,k(\u03b4x,x, z) = F\r\n1\r\n(\u02c6\u03c9k, \u03b4x,x, z) = NU (x, N\u01eb,\u03c9\u02c6k\r\n(x), z, N\u03bd,\u03c9\u02c6k\r\n(z)) + \u03b4x\r\nN2\r\n. (EC.5)\r\nBy equation (EC.2), F\r\n2,k(\u03b4x,x, z) can be interpreted as the realisation of F\r\n1\r\n(\u03c9, \u03b4x,x, z) with\r\nrespect to the sample \u02c6\u03c9k. However, it is worth observing that F\r\n2,k(\u03b4x,x, z) is itself a random\r\nvariable due to the noise term \u03b4x. Finally, we let \u03c0\r\n2\r\n(x, z, A) be the sample mean estimator of the\r\nchoice probabilities with respect to F\r\n2,1\r\n, . . . , F2,K, i.e.,\r\n\u03c0\r\n2\r\n(x, z, A) = 1\r\nK\r\n\u00b7\r\nX\r\nK\r\nk=1\r\nPr\u03b4\r\n\r\nF\r\n2,k(\u03b4x,x, z) > F2,k(\u03b4x\u2032,x\r\n\u2032\r\n, z), \u2200x\r\n\u2032 \u2208 A\\{x}\r\n\r\n. (EC.6)\r\nBy equations (EC.5) and (EC.6), it is clear that the choice model \u03c0\r\n2\r\n(\u00b7) can be represented by\r\nan instance of the RUMnet architecture. Hence, we denote by N(\u03c9\u02c6) \u2208 N d\r\n(K,\u0398\r\n\u2113,w\r\nM ) the RUMnet\r\narchitecture such that \u03c0\r\n2\r\n(\u00b7) = \u03c0\r\nRUMnet\r\nN(\u03c9\u02c6)\r\n(\u00b7).\r\nNext, we analyse the differences between the choice models \u03c0\r\n1\r\n(\u00b7) and its sample mean approximation \u03c0\r\nRUMnet\r\nN(\u03c9\u02c6)\r\n(\u00b7). First, we establish a property analogous to Claim EC.1 with respect to \u03c0\r\n2\r\n(\u00b7).\r\nThe proof is provided in Appendix B.4\r\nec10 e-companion to : Random Utility Maximization: Revisited\r\nClaim EC.2. For any K \u2265\r\n\u03ba\r\n2\r\nlog(4|E |)\r\n2\u00b7\u03b72 , with probability at least 3/4 with respect to \u03c9\u02c6 , for all\r\nchoice events (x, z, A) \u2208 X \u00d7 Z \u00d7 X \u03ba\u22121\r\n, we have\r\n|\u03c0\r\nRUMnet\r\nN(\u03c9\u02c6)\r\n(x, z, A) \u2212 \u03c0\r\nRUMnet\r\nN(\u03c9\u02c6)\r\n(x\u02c6, z\u02c6,A\u02c6)| \u2264 2\u03b7 .\r\nNext, we observe that, for all K \u2265\r\nlog(4|E |)\r\n2\u00b7\u03b72 ,\r\nPr\u03c9\u02c6\r\n\u0014\r\nmax\r\n(x,z, \u02c6 A\u02c6)\u2208E\r\n\f\r\n\f\r\n\f\r\n\u03c0\r\n1\r\n(x\u02c6, z\u02c6,A\u02c6) \u2212 \u03c0\r\nRUMnet\r\nN(\u03c9\u02c6)\r\n(x\u02c6, z\u02c6,A\u02c6)\r\n\f\r\n\f\r\n\f > \u03b7\u0015\r\n\u2264\r\nX\r\n(x,z, \u02c6 A\u02c6)\u2208E\r\nPr\u03c9\u02c6\r\nh\f\r\n\f\r\n\f\r\n\u03c0\r\n1\r\n(x\u02c6, z\u02c6,A\u02c6) \u2212 \u03c0\r\nRUMnet\r\nN(\u03c9\u02c6)\r\n(x\u02c6, z\u02c6,A\u02c6)\r\n\f\r\n\f\r\n\f > \u03b7i\r\n\u2264\r\nX\r\n(x,z, \u02c6 A\u02c6)\u2208E\r\n2 \u00b7 e\r\n\u22122\u00b7\u03b7\r\n2 log(4|E|)\r\n2\u00b7\u03b72\r\n\u2264\r\n1\r\n2\r\n, (EC.7)\r\nwhere the first inequality follows from the union bound and the second inequality from Hoeffding\u2019s\r\ninequality. Fix K = \u2308\r\n\u03ba\r\n2\r\nlog(4|E |)\r\n2\u00b7\u03b72 \u2309. By the union bound over inequality (EC.7) and Claim EC.2, there\r\nexists a realization \u03c9\u02c6\r\n\u2217 of \u03c9\u02c6 such that, for all (x\u02c6, z\u02c6,A\u02c6) \u2208 E, we have\r\n\f\r\n\f\r\n\f\r\n\u03c0\r\n1\r\n(x\u02c6, z\u02c6,A\u02c6) \u2212 \u03c0\r\nRUMnet\r\nN(\u03c9\u02c6\u2217)\r\n(x\u02c6, z\u02c6,A\u02c6)\r\n\f\r\n\f\r\n\f \u2264 \u03b7 . (EC.8)\r\nand for all choice events (x, z, A) \u2208 X \u00d7 Z \u00d7 X \u03ba\u22121\r\n, we have\r\n|\u03c0\r\nRUMnet\r\nN(\u03c9\u02c6\u2217)\r\n(x, z, A) \u2212 \u03c0\r\nRUMnet\r\nN(\u03c9\u02c6\u2217)\r\n(x\u02c6, z\u02c6,A\u02c6)| \u2264 2\u03b7 . (EC.9)\r\nPutting together Claim EC.1, inequalities (EC.3), (EC.8) and (EC.9), we have\r\n\f\r\n\f\u03c0(x, z, A) \u2212 \u03c0\r\nRUMnet\r\nN(\u03c9\u02c6\u2217)\r\n(x, z, A)\r\n\f\r\n\f\r\n\u2264\r\n\f\r\n\f\r\n\f\r\n\u03c0(x, z, A) \u2212 \u03c0(x\u02c6, z\u02c6,A\u02c6)\r\n\f\r\n\f\r\n\f +\r\n\f\r\n\f\r\n\f\r\n\u03c0(x\u02c6, z\u02c6,A\u02c6) \u2212 \u03c0\r\n1\r\n(x\u02c6, z\u02c6,A\u02c6)\r\n\f\r\n\f\r\n\f +\r\n\f\r\n\f\r\n\f\r\n\u03c0\r\n1\r\n(x\u02c6, z\u02c6,A\u02c6) \u2212 \u03c0\r\nRUMnet\r\nN(\u03c9\u02c6\u2217)\r\n(x\u02c6, z\u02c6,A\u02c6)\r\n\f\r\n\f\r\n\f\r\n+\r\n\f\r\n\f\r\n\f\r\n\u03c0\r\nRUMnet\r\nN(\u03c9\u02c6\u2217)\r\n(x\u02c6, z\u02c6,A\u02c6) \u2212 \u03c0\r\nRUMnet\r\nN(\u03c9\u02c6\u2217)\r\n(x, z, A)\r\n\f\r\n\f\r\n\f\r\n\u2264 5\u03b7 ,\r\nwhich yields the desired result.\r\nB.3. Proof of Claim EC.1\r\nWe establish the desired inequality for the choice model \u03c0\r\n1\r\n(\u00b7) since the case of \u03c0(\u00b7) proceeds from\r\nan identical reasoning. As in Step 2, we define \u2126x,x\u2032 for every x\r\n\u2032 \u2208 A \\ {x} as the event where\r\ncustomer z\u2019s preferences over (x,x\r\n\u2032\r\n) are reversed compared to customer z\u02c6\u2019s preferences over (x\u02c6,x\u02c6\r\n\u2032\r\n)\r\nwith respect to the random utility function F\r\n1\r\n(\u03c9, \u03b4, \u00b7, \u00b7). By the union bound, we have\r\n|\u03c0(x, z, A) \u2212 \u03c0(x\u02c6, z\u02c6,A\u02c6)| \u2264 X\r\nx\u2032\u2208A\\{x}\r\nPr[\u2126x,x\u2032] \u2264 \u03ba \u00b7 max\r\nx\u2032\u2208A\\{x}\r\nPr[\u2126x,x\u2032] . (EC.10)\r\ne-companion to : Random Utility Maximization: Revisited ec11\r\nWithout loss of generality, fix x,x\r\n\u2032 \u2208 A2 and consider \u03c9 \u2208 \u2126 and (\u03b4x, \u03b4x\u2032) \u2208 R\r\n2\r\nsuch that\r\nF\r\n1\r\n(\u03c9, \u03b4x,x, z) > F1\r\n(\u03c9, \u03b4x\u2032,x\r\n\u2032\r\n, z) and F\r\n1\r\n(\u03c9, \u03b4x\u02c6,x\u02c6, z\u02c6) < F1\r\n(\u03c9, \u03b4x\u02c6\u2032,x\u02c6\r\n\u2032\r\n, z\u02c6).\r\nNow, let c = (x\u02dc,x\u02dc\r\n\u2032\r\n, z\u02dc) \u2208 C\r\n+ be the center of a neighborhood that contains (x,x\r\n\u2032\r\n, z). By construction\r\nof our mapping, this neighborhood necessarily contains (x\u02c6,x\u02c6\r\n\u2032\r\n, z\u02c6) based on the coordinate-wise\r\ninequalities \u03b4\r\n+(c) \u2265 max{|x\u02c6 \u2212 x|, |x\u02c6\r\n\u2032 \u2212 x\r\n\u2032\r\n|, |z\u02c6 \u2212 z|}, which imply that (x\u02c6,x\u02c6\r\n\u2032\r\n, z\u02c6) \u2208 B(c, \u03b4+(c)). In\r\nwhat follows, suppose that \u03c9 satisfies properties 1-3 of the covering; by construction, this event\r\noccurs with probability at least 1 \u2212 3\u03b7/4\u03ba. Due to properties 1-2, we have\r\n0 > F1\r\n(\u03c9, \u03b4x\u02c6,x\u02c6, z\u02c6) \u2212 F\r\n1\r\n(\u03c9, \u03b4x\u02c6\u2032,x\u02c6\r\n\u2032\r\n, z\u02c6)\r\n\u2265 F\u00af1\r\n(\u03c9,x\u02dc, z\u02dc) \u2212 F\u00af1\r\n(\u03c9,x\u02dc\r\n\u2032\r\n, z\u02dc) \u2212 |F\u00af1\r\n(\u03c9,x\u02c6, z\u02c6) \u2212 F\u00af1\r\n(\u03c9,x\u02dc, z\u02dc)| \u2212 |F\u00af1\r\n(\u03c9,x\u02c6\r\n\u2032\r\n, z\u02c6) \u2212 F\u00af1\r\n(\u03c9,x\u02dc\r\n\u2032\r\n, z\u02dc)| + (\u03b4x\u02c6 \u2212 \u03b4x\u02c6\u2032)/N2\r\n\u2265 F\u00af1\r\n(\u03c9,x\u02dc, z\u02dc) \u2212 F\u00af1\r\n(\u03c9,x\u02dc\r\n\u2032\r\n, z\u02dc) \u2212 2/n+(c) + (\u03b4x\u02c6 \u2212 \u03b4x\u02c6\u2032)/N2\r\n,\r\nand\r\n0 < F1\r\n(\u03c9, \u03b4x,x, z) \u2212 F\r\n1\r\n(\u03c9, \u03b4x\u2032,x\r\n\u2032\r\n, z)\r\n\u2264 F\u00af1\r\n(\u03c9,x\u02dc, z\u02dc) \u2212 F\u00af1\r\n(\u03c9,x\u02dc\r\n\u2032\r\n, z\u02dc) + |F\u00af1\r\n(\u03c9,x, z) \u2212 F\u00af1\r\n(\u03c9,x\u02dc, z\u02dc)| + |F\u00af1\r\n(\u03c9,x\r\n\u2032\r\n, z) \u2212 F\u00af1\r\n(\u03c9,x\u02dc\r\n\u2032\r\n, z\u02dc)| + (\u03b4x \u2212 \u03b4x\u2032)/N2\r\n\u2264 F\u00af1\r\n(\u03c9,x\u02dc, z\u02dc) \u2212 F\u00af1\r\n(\u03c9,x\u02dc\r\n\u2032\r\n, z\u02dc) + 2/n+(c) + (\u03b4x \u2212 \u03b4x\u2032)/N2\r\n.\r\nCombining these inequalities with property 3, we infer that either \u03b4x\u02c6 \u2212 \u03b4x\u02c6\u2032 \u2264 \u22123\r\nN2\r\nn+(c) \u2264 \u22123N or\r\n\u03b4x \u2212\u03b4x\u2032 \u2265 3\r\nN2\r\nn+(c) \u2265 3N. Since N \u2265 \u2212log( \u03b7\r\n8\u03ba\r\n) and \u03b4 is a collection of i.i.d. Gumbel random variables,\r\neach of these events occurs with probability at most \u03b7\r\n8\u03ba\r\n. By the union bound, we derive the upper\r\nbound on reversal probabilities:\r\nPr [\u2126x,x\u2032] \u2264\r\n3\u03b7\r\n4\u03ba\r\n+ 2\r\n\u03b7\r\n8\u03ba\r\n=\r\n\u03b7\r\n\u03ba\r\n.\r\nThe desired inequality immediately follows by plugging the above inequality into (EC.10).\r\nB.4. Proof of Claim EC.2\r\nFix a choice event (x, z, A) \u2208 X \u00d7 Z \u00d7 X \u03ba\u22121\r\n. Similarly to the proof of Claim EC.1, for each x\r\n\u2032 \u2208 A\\\r\n{x\r\n\u2032} and k \u2208 [K], we develop an upper bound on the probability of a preference reversal conditional\r\nto the unobserved attribute \u03c9\u02c6 = \u02c6\u03c9k. Specifically, the preference reversal event \u2126k\r\nx,x\u2032\r\n,z\r\noccurs when\r\ncustomer z\u2019s preferences over (x,x\r\n\u2032\r\n) are reversed compared to customer z\u02c6\u2019s preferences over (x\u02c6,x\u02c6\r\n\u2032\r\n)\r\nwith respect to the k-th sampled random utility function F\r\n2,k(\u03b4, \u00b7, \u00b7) = F\r\n1\r\n(\u02c6\u03c9k, \u03b4, \u00b7, \u00b7). Let Gk\r\nx,x\u2032\r\n,z\r\ndenote the event for which \u02c6\u03c9k satisfies properties 1-3 with respect to the center (x\u02dc,x\u02dc\r\n\u2032\r\n, z\u02dc). The\r\nfact that (x\u02c6,x\u02c6\r\n\u2032\r\n, z\u02c6) and (x,x\r\n\u2032\r\n, z) are both contained in one neighborhood of the covering implies\r\nec12 e-companion to : Random Utility Maximization: Revisited\r\nGk\r\nx,x\u2032\r\n,z = Gk\r\nx\u02c6,x\u02c6\u2032\r\n,z\u02c6\r\n. Now, a close examination of the proof of Claim EC.1 reveals that, conditional on\r\nGk\r\nx\u02c6,x\u02c6\u2032\r\n,z\u02c6\r\n, the preference reversal occurs with probability at most \u03b7\r\n4\u03ba\r\n. It follows that:\r\n|\u03c0\r\nRUMnet\r\nN(\u03c9\u02c6)\r\n(x, z, A) \u2212 \u03c0\r\nRUMnet\r\nN(\u03c9\u02c6)\r\n(x\u02c6, z\u02c6,A\u02c6)|\r\n\u2264\r\n1\r\nK\r\n\u00b7\r\nX\r\nK\r\nk=1\r\nPr\r\n\uf8ee\r\n\uf8f0\r\n[\r\nx\u2032\u2208A\\{x}\r\n\u2126\r\nk\r\nx,x\u2032\r\n,z\r\n\f\r\n\f\r\n\f\r\n\f\r\n\f\r\n\f\r\n\u03c9\u02c6\r\n\uf8f9\r\n\uf8fb\r\n\u2264\r\n1\r\nK\r\n\u00b7\r\nX\r\nK\r\nk=1\r\nX\r\nx\u2032\u2208A\\{x}\r\nPr\u03b4\r\n\r\n\u2126\r\nk\r\nx,x\u2032\r\n,z\r\n\f\r\n\f\u03c9\u02c6k\r\n\r\n\u2264\r\n1\r\nK\r\n\u00b7\r\nX\r\nK\r\nk=1\r\nX\r\nx\u2032\u2208A\\{x}\r\n\r\nI[\u02c6\u03c9k \u2208/ G\r\nk\r\nx\u02c6,x\u02c6\u2032\r\n,z\u02c6\r\n] + Pr\r\n\u2126\r\nk\r\nx,x\u2032\r\n,z\r\n\f\r\n\f\u03c9\u02c6k,\u03c9\u02c6k \u2208 G\r\nk\r\nx\u02c6,x\u02c6\u2032\r\n,z\u02c6\r\n\r\n\u00b7I[\u02c6\u03c9k \u2208 G\r\nk\r\nx\u02c6,x\u02c6\u2032\r\n,z\u02c6\r\n]\r\n\u0001\r\n\u2264\r\n1\r\nK\r\n\u00b7\r\nX\r\nK\r\nk=1\r\nX\r\nx\u2032\u2208A\\{x}\r\n\u0010\r\nI[\u02c6\u03c9k \u2208/ G\r\nk\r\nx\u02c6,x\u02c6\u2032\r\n,z\u02c6\r\n] + \u03b7\r\n4\u03ba\r\n\u00b7I[\u02c6\u03c9k \u2208 G\r\nk\r\nx\u02c6,x\u02c6\u2032\r\n,z\u02c6\r\n]\r\n\u0011\r\n\u2264\r\n\u03b7\r\n4\r\n+\r\nX\r\nx\u2032\u2208A\\{x}\r\n1\r\nK\r\n\u00b7\r\nX\r\nK\r\nk=1\r\nI[\u02c6\u03c9k \u2208/ G\r\nk\r\nx\u02c6,x\u02c6\u2032\r\n,z\u02c6\r\n] ,\r\nwhere the first inequality holds since, absent a preference reversal over one pair (x,x\r\n\u2032\r\n), our RUMnet model identifies the same highest-utility alternative in the assortments A and A\u02c6. The second\r\ninequality proceed from the union bound. The next inequality follows from the formula of conditional expectations. The fourth inequality is direct consequence of our upper bound derived from\r\nthe proof of Claim EC.1. Now, we invoke Hoeffding\u2019s inequality so that, for every x\u02c6\r\n\u2032 \u2208 A\u02c6, we have\r\nPr\u03c9\u02c6\r\n\"\r\n1\r\nK\r\n\u00b7\r\n X\r\nK\r\nk=1\r\nI[\u02c6\u03c9k \u2208/ G\r\nk\r\nx\u02c6,x\u02c6\u2032\r\n,z\u02c6\r\n]\r\n!\r\n\u2212\r\n3\u03b7\r\n4\u03ba\r\n>\r\n\u03b7\r\n\u03ba\r\n#\r\n\u2264 e\r\n\u22122\r\n\u03b7\r\n2\r\n\u03ba2 K\r\n,\r\nwhere we note that E\u03c9\u02c6 [\r\n1\r\nK\r\nPK\r\nk=1 I[\u02c6\u03c9k \u2208/ Gk\r\nx\u02c6,x\u02c6\u2032\r\n,z\u02c6\r\n]] = Pr[\u02c6\u03c9k \u2208/ Gk\r\nx\u02c6,x\u02c6\u2032\r\n,z\u02c6\r\n]] \u2264\r\n3\u03b7\r\n4\u03ba\r\nbased on the construction\r\nof our covering. By the union bound, we have\r\nPr\u03c9\u02c6\r\nh\r\n\u2203(x, z, A) \u2208 X \u00d7 Z \u00d7 X \u03ba\u22121\r\ns.t. |\u03c0\r\nRUMnet\r\nN(\u03c9\u02c6)\r\n(x, z, A) \u2212 \u03c0\r\nRUMnet\r\nN(\u03c9\u02c6)\r\n(x\u02c6, z\u02c6,A\u02c6)| > 2\u03b7\r\ni\r\n\u2264 |E| \u00b7 e\r\n\u22122\r\n\u03b7\r\n2\r\n\u03ba2 K \u2264\r\n1\r\n4\r\n.\r\nwhere the first inequality holds since the number of distinct vectors (x\u02c6,x\u02c6\r\n\u2032\r\n, z\u02c6) is upper bounded by\r\n|E| and the next inequality immediately follows from the condition K \u2265\r\n\u03ba\r\n2\r\nlog(4|E |)\r\n2\u00b7\u03b72\r\ne-companion to : Random Utility Maximization: Revisited ec13\r\nAppendix C: Proofs of Section 4\r\nC.1. Proof of Proposition 3\r\nLet H be a hypothesis class, E be a collection of data observations endowed with a distribution D,\r\nand \u2113(\u00b7) be a loss function with respect to H and Z. For every hypothesis h \u2208 H, training sample\r\nS = {s1, . . . , sT }, and loss function \u2113(\u00b7), we define the empirical error as\r\nLS(h) = 1\r\nT\r\n\u00b7\r\nX\r\nT\r\nt=1\r\n\u2113(h(st)),\r\nand the associated true error\r\nL\r\ntrue\r\nD (h) = ES\u2032\u223cD [LS\u2032(h)].\r\nFor a given training sample S, let h\r\nERM\r\nS be the hypothesis that minimizes the empirical error LS(h) over all h \u2208 H. We begin by invoking a classical result to bound the generalization based on the Rademacher complexity; e.g., see Shalev-Shwartz and Ben-David (2014),\r\nKoltchinskii and Panchenko (2000), Bartlett and Mendelson (2002). Recall that the Rademacher\r\ncomplexity for a set of vectors A \u2286 R\r\nT\r\nis\r\nR(A) = 1\r\nT\r\n\u00b7E\u03c3\r\n\"\r\nsup\r\na\u2208A\r\nX\r\nT\r\ni=1\r\n\u03c3iai\r\n#\r\n,\r\nwhere \u03c3 = (\u03c31, . . . , \u03c3m) is a sequence of independent Rademacher random variables defined for all\r\ni by the following distribution: Pr[\u03c3i = 1] = Pr[\u03c3i = \u22121] = 1\r\n2\r\n.\r\nTheorem EC.1 (Shalev-Swartz and Ben-David (2014, Thm. 26.5)). Suppose that for\r\nevery hypothesis h \u2208 H and observation s \u2208 E, we have |\u2113(h(s))| \u2264 c for some c \u2265 0. Then, with\r\nprobability of at least (1 \u2212 \u03b4) with regards to the data sample S \u223c DT\r\n, we have\r\nL\r\ntrue\r\nD\r\n\r\nh\r\nERM\r\nS\r\n\u0001\r\n\u2264 LS(h\r\nERM\r\nS\r\n) + 2R(\u2113 \u25e6 H \u25e6 S) + 4c\r\nr\r\n2 ln(4/\u03b4)\r\nT\r\n,\r\nwhere \u2113 \u25e6 H \u25e6 S = {(\u2113(h(s1)), . . ., \u2113(h(sT ))) : h \u2208 H}.\r\nThis type of bound is often referred to as a data-dependent bound since the bound depends on the\r\nspecific training set S. It therefore suffices to bound the Rademacher complexity of the RUMnet\r\nclass N d\r\n(K,\u0398\r\n\u2113,w\r\nM ) composed with our data generative process and the negative log-likelihood loss\r\nfunction. Proposition 3 immediately follows from Lemma EC.2 below.\r\nLemma EC.2. Let \u2113(\u00b7) be the negative log-likelihood loss function, HRUMnet be the class of RUMnet\r\nclass and S = ((y1, z1, A1), . . . ,(yT , zT , AT )) be a training sample. Then, there exists a constant\r\nc1 > 0 such that\r\nR(\u2113 \u25e6 HRUMnet \u25e6 S) \u2264 c1 \u00b7\r\n\u03ba\r\n\u221a\r\n\u03ba\r\n\u221a\r\nT\r\n\u00b7 e\r\n2w\u00b7MM\u2113\r\n\r\nec14 e-companion to : Random Utility Maximization: Revisited\r\nThe remainder of this section establishes Lemma EC.2. The proof plugs together various notions of\r\nRademacher calculus. We first invoke several auxiliary results established in the previous literature.\r\nWe make use of the standard lemmas; see Shalev-Shwartz and Ben-David (2014, Chap. 26).\r\nLemma EC.3 (Contraction). Let A be a subset of R\r\nm. For each i \u2208 [m], let \u03c6i\r\n: R \u2192 R be a\r\n\u03c1-Lipschitz function; namely, for all \u03b1, \u03b2 \u2208 R, we have |\u03c6i(\u03b1) \u2212 \u03c6i(\u03b2)| \u2264 \u03c1|\u03b1 \u2212 \u03b2|. For a \u2208 R\r\nm let\r\n\u03c6(a) denote the vector (\u03c61(a1), . . . , \u03c6m(am)). Let \u03c6 \u25e6 A = {\u03c6(a) : a \u2208 A}. Then,\r\nR(\u03c6 \u25e6 A) \u2264 \u03c1R(A).\r\nLemma EC.4 (Convex combination). Let A be a subset of R\r\nm and let A\u2032 = {\r\nPN\r\nj=1 \u03b1ja\r\n(j)\r\n:\r\nN \u2208 N, \u2200j,a\r\n(j) \u2208 A, \u03b1j \u2265 0, |\u03b1|1 = 1}. Then, R(A\u2032\r\n) = R(A).\r\nWe utilize a generalization of the contraction lemma for hypothesis classes formed by vector-valued\r\nfunctions, established in the paper by Maurer (2016, Corollary 4).\r\nLemma EC.5 (Vector-valued contraction). Let E be an arbitrary set, (x1, . . . xT ) \u2208 ET\r\n, and\r\nlet F be a class of m-dimensional functions f : E \u2192 R\r\nm and let h : R\r\nm \u2192 R be an L-Lipschitz\r\nfunction with respect to the \u21132-norm. Then,\r\nE\r\n\"\r\nsup\r\nf\u2208F\r\nX\r\nT\r\ni=1\r\n\u03c3ih (f (xi))#\r\n\u2264\r\n\u221a\r\n2L\u00b7E\r\n\"\r\nsup\r\nf\u2208F\r\nX\r\nT\r\ni=1\r\nXm\r\nk=1\r\n\u03c3i,kfk (xi)\r\n#\r\n,\r\nwhere {\u03c3i}i\u2208[T] and {\u03c3i,k}i\u2208[T],k\u2208[m] are i.i.d. Rademacher random variables.\r\nThe following claim can be found in Neyshabur et al. (2015, Cor. 2).\r\nLemma EC.6 (Rademacher complexity of neural networks). Fix a neural network architecture with \u2113 \u2265 1 layers and assume that (i) the weight vector w for every node in the network satisfies kwk1 \u2264 M, (ii) the activation functions are ReLUs, and (iii) the input vectors S =\r\n{x1, . . . , xT } \u2286 R\r\nd\r\nsatisfy kxtk\u221e \u2264 1. Then, the class of functions F \u2208 R\r\nE defined by such neural\r\nnetwork architecture over the inputs S satisfies\r\nR(F \u25e6 S) \u2264\r\nr\r\n4 log(2d)\r\nT\r\n(2M)\r\n\u2113\r\n.\r\nFinally, let pmin be the minimum choice probability attained over the compact set of RUMnet\r\narchitectures HRUMnet. Our analysis will make use of the following property.\r\nClaim EC.3. pmin \u2265\r\n1\r\n\u03ba\r\n\u00b7 e\r\n\u22122M .\r\nThe claim follows immediately by noting that there are up to \u03ba choice alternatives. Additionally,\r\nthe MNL attractiveness weight of each alternative is in the range [e\r\n\u2212M , eM] since the utility u of\r\neach alternative is the final layer\u2019s output of a feed-forward neural network NU \u2208 \u0398\r\n\u2113,w\r\nM .\r\ne-companion to : Random Utility Maximization: Revisited ec15\r\nNow, we break down generating the collection of vectors \u2113 \u25e6 HRUMnet \u25e6 S into four operations for\r\neach choice event (in reverse order): (1) applying a log-transformation to the choice probability\r\nof the selected alternative, (2) averaging the choice probabilities over the samples of the RUMnet\r\narchitecture, (3) applying a softmax transformation of the utilities within each offered assortment,\r\n(4) computing the utility of each alternative using a feed-forward neural network. We denote by\r\n\u03c81, \u03c82, \u03c83, \u03c84 the class of mappings corresponding to each step, and by slightly abusing notation,\r\nwe have \u03c81 \u25e6 \u03c82 \u25e6 \u03c83 \u25e6 \u03c84 \u25e6 S = \u2113 \u25e6 HRUMnet \u25e6 S. Now, we bound the Rademacher complexity by\r\nconsidering these successive transformations:\r\n1. Note that \u03c81 applies the transformation p \u2208 (0, 1) 7\u2192 log(p) to the estimated probability p\r\nof the chosen alternative for each event s \u2208 S. This mapping is (1/pmin)-Lipschitz where pmin is\r\nthe minimal choice probability attained by the RUMnet architecture. Therefore, by combining\r\nClaim EC.3 and Lemma EC.3, we have:\r\nR(\u03c81 \u25e6\u03c82 \u25e6\u03c83 \u25e6\u03c84 \u25e6 S) = \u03bae2M \u00b7 R(\u03c82 \u25e6\u03c83 \u25e6\u03c84 \u25e6 S) .\r\n2. Next, the mapping \u03c82 computes the unweighted average of choice probabilities over the samples (k1, k2) \u2208 [K]\r\n2 of the RUMnet architecture for each choice event s \u2208 S. This transformation\r\namount to a convex combination of the choice probability vectors. Thus, by Lemma EC.4, we have\r\nR(\u03c82 \u25e6\u03c83 \u25e6\u03c84 \u25e6 S) = R(\u03c83 \u25e6\u03c84 \u25e6 S) .\r\n3. The mapping \u03c83 applies a softmax to the utilities of the alternatives for each choice event\r\ns \u2208 S and sample k1, k2 \u2208 [K], and then, returns the coordinate corresponding to the chosen alternative. By noting that the softmax function u \u2208 R\r\n\u03ba\r\n7\u2192\r\n\u0010\r\ne\r\nui P\r\nj\u2208[\u03ba]\r\ne\r\nuj\r\n\u0011\r\ni\u2208[\u03ba]\r\nis 1-Lipschitz, we infer from\r\nLemma EC.5 that\r\nR(\u03c83 \u25e6\u03c84 \u25e6 S) \u2264\r\n\u221a\r\n2 \u00b7 \u03baR(\u03c84 \u25e6 S\r\n\u2032\r\n) ,\r\nwhere \u03c84 \u25e6S\r\n\u2032\r\nis the class of utility vectors computed by the RUMnet architecture from the sample\r\nS\r\n\u2032\r\nformed by the \u03ba \u00b7 T vectors of the form (x, z) corresponding to each alternative and customer\r\nattribute in S.\r\n4. Finally, \u03c84 computes the utility associated with each inputted product and customer attribute\r\nvector of the form (x, z). By invoking Lemma EC.6, we have\r\nR(\u03c81 \u25e6 S\r\n\u2032\r\n) = O\r\n r\r\nlog(d)\r\n\u03baT\r\n\u00b7(2M)\r\n\u2113\r\n!\r\n.\r\nBy combining the above inequalities, we conclude that\r\nR(\u03c82 \u25e6\u03c83 \u25e6\u03c84 \u25e6 S) = O\r\n r\r\n\u03ba3\r\nlog(d)\r\nT\r\n\u00b7 e\r\n2M(2M)\r\n\u2113\r\n!\r\n.\r\n\r\nec16 e-companion to : Random Utility Maximization: Revisited\r\nC.2. Proof of Proposition 4\r\nFix the ground truth model \u03c0 = \u03c0\r\nRUMnet\r\nN , T = \u2308max{\r\nc\r\n2\r\n1\r\n\u01eb\r\n2 \u03ba\r\n3\r\nlog(d)e\r\n4M(2M)\r\n2\u2113\r\n, 128(8M + log \u03ba)\r\n2\r\nln 4\r\n\u03b4\r\n}\u2309,\r\nand K\u2032 = \u2308\r\n1\r\n2\u01eb\r\n2 \u00b7 log \u03b4 \u00b7(\u03bae2M)\r\n2\r\nlog(T)\u2309. By precisely the same line of argumentation as in the proof\r\nof Proposition 3, the following inequality holds for every N\u00af \u2208 N d\r\n(K\u2032\r\n,\u0398\r\n\u2113,w\r\nM ), with probability 1\u2212\u03b4,\r\nL\r\ntrue\r\nD\r\n\r\n\u03c0\r\nRUMnet\r\nN\u00af\r\n\u0001\r\n\u2264 LS\r\n\r\n\u03c0\r\nRUMnet\r\nN\u00af\r\n\u0001\r\n+ c1\r\nr\r\n\u03ba\r\n3\r\nlog(d)\r\nT\r\n\u00b7 e\r\n2M (2M)\r\n\u2113 + (8M + log \u03ba)\r\nr\r\n2 ln(4/\u03b4)\r\nT\r\n\u2264 LS\r\n\r\n\u03c0\r\nRUMnet\r\nN\u00af\r\n\u0001\r\n+ \u01eb (EC.11)\r\nIn Proposition 3, we established a similar inequality with respect the ERM estimate; however, this inequality holds for any fixed RUMnet architecture in our hypothesis class; see\r\nShalev-Shwartz and Ben-David (2014, Thm. 26.5).\r\nNow, by applying Hoeffding\u2019s inequality with respect to the random experiment S \u223c DT\r\n, while\r\nusing the fact that Prs\u223cD[| log(\u03c0\r\nRUMnet\r\nN (s))| \u2264 log(\u03bae2M)] = 1 by Claim EC.3, we have:\r\nPrS\u223cDT\r\n\r\nLS\r\n\r\n\u03c0\r\nRUMnet\r\nN\r\n\u0001\r\n\u2212 L\r\ntrue\r\nD\r\n\r\n\u03c0\r\nRUMnet\r\nN\r\n\u0001\r\n> \u01eb\r\n\u2264 e\r\n\u22122\u01eb\r\n2T\r\n(log(\u03bae2M ))2\r\n. (EC.12)\r\nNext, for any fixed realization S\u02c6 of S, we can bound the errors in the choice probabilities computed\r\nby N\u2032\r\nrelative to N using Hoeffding\u2019s inequality with respect to the K\u2032\r\ni.i.d. samples over the\r\nunobserved attributes {N\u01ebk1\r\n(\u00b7)}\r\nK\r\nk1=1 and {N\u03bdk2\r\n(\u00b7)}\r\nK\r\nk2=1. As a result, using the union bound over the\r\nT events in S\u02c6, we obtain\r\nPrN\u2032\r\nh\r\nLS\r\n\r\n\u03c0\r\nRUMnet\r\nN\u2032\r\n\u0001\r\n> LS\r\n\r\n\u03c0\r\nRUMnet\r\nN\r\n\u0001\r\n+ \u01eb\r\n\f\r\n\fS = S\u02c6\r\ni\r\n\u2264 T e\u2212 2\u01eb\r\n2K\u2032\r\n(\u03bae2M )2\r\n.\r\nBy plugging the definition of K\u2032\r\n, and by taking the expectation with respect to S \u223c DT\r\n, we obtain\r\nPrN\u2032\r\n\r\nLS\r\n\r\n\u03c0\r\nRUMnet\r\nN\u2032\r\n\u0001\r\n> LS\r\n\r\n\u03c0\r\nRUMnet\r\nN\r\n\u0001\r\n+ \u01eb\r\n\r\n\u2264 \u03b4 . (EC.13)\r\nThe union bound with respect to the events of inequalities (EC.11)-(EC.13) implies that, with\r\nprobability 1 \u2212 3\u03b4,\r\nL\r\ntrue\r\nD\r\n\r\n\u03c0\r\nRUMnet\r\nN\u2032\r\n\u0001\r\n\u2264 LS\r\n\r\n\u03c0\r\nRUMnet\r\nN\u2032\r\n\u0001\r\n+ \u01eb \u2264 LS\r\n\r\n\u03c0\r\nRUMnet\r\nN\r\n\u0001\r\n+ 2\u01eb \u2264 L\r\ntrue\r\nD\r\n\r\n\u03c0\r\nRUMnet\r\nN\r\n\u0001\r\n+ 3\u01eb ,\r\nwhere the first inequality proceeds from (EC.11) with the instantiation N\u00af = N\u2032\r\n, the second inequality follows from (EC.13), and the last inequality is a direct consequence of (EC.12).\r\nBy rearranging the latter inequality, we obtain the following:\r\n3\u01eb \u2265 L\r\ntrue\r\nD\r\n\r\n\u03c0\r\nRUMnet\r\nN\u2032\r\n\u0001\r\n\u2212 L\r\ntrue\r\nD\r\n\r\n\u03c0\r\nRUMnet\r\nN\r\n\u0001\r\n= E(z,A)\u223cD \"X\r\ny\u2208A\r\n\u03c0\r\nRUMnet\r\nN (y, z, A)\r\n\r\nlog(\u03c0\r\nRUMnet\r\nN (y, z, A)) \u2212 log(\u03c0\r\nRUMnet\r\nN\u2032 (y, z, A))\u0001\r\n#\r\n= E(z,A)\u223cD\r\nKL\r\n\u03c0\r\nRUMnet\r\nN (\u00b7, z, A)\r\n\f\r\n\f\u03c0\r\nRUMnet\r\n\r\ne-companion to : Random Utility Maximization: Revisited ec17\r\nNote that, in the above proof, the sampling with respect to S \u223c DT\r\nis unnecessary; we can\r\nestablish the same result as long as there exists a fixed sample S such that inequalities (EC.11)-\r\n(EC.12) hold. Nonetheless, our proof argument can be adapted to establish an algorithmic version\r\nof Proposition 4. Specifically, with respect to the hypothesis class N d\r\n(K\u2032\r\n,\u0398\r\n\u2113,w\r\nM ), the ERM estimate\r\n\u03c0\r\nERM\r\nS on a random sample S \u223c DT achieves a small total learning error with high probability.\r\nec18 e-companion to : Random Utility Maximization: Revisited\r\nAppendix D: Additional material for Section 5\r\nD.1. Experiment using ranking-based non-contextual data\r\nD.1.1. Experiment setup. We generate synthetic choice data where the ground truth is a nonparametric ranking-based choice model. Specifically, the ground truth model is a distribution over\r\n10 ranked lists. Each ranked list in the support is generated as an independent uniform permutation of the products. Additionally, for each ranked lists i, we generate an independent random\r\nvariable Xi\r\nin [0, 1] and assign to each ranked list the probability Xi/\r\nP10\r\nj=1 Xj\r\n. For the training\r\nset, we generate a sequence of T = 10, 000 customers, each being presented with an assortment of\r\n5 products chosen uniformly at random from a universe of 10 products.\r\nNote that in this case, there are no product or customer features, and the input vector is simply,\r\nfor each product, an indicator vector x \u2208 {0, 1}\r\n10. We compare the performance of various RUMnet\r\nmodels with a ranking-based model, which we estimate using the code of Berbeglia et al. (2022). In\r\nparticular, we experiment with (\u2113, w) \u2208 {(0, 0),(1, 3)} and K \u2208 {2, 5, 10, 20}. To assess the model\u2019s\r\nperformance, we generate an additional 1, 000 customers as a test set to compute an out-of-sample\r\nlog-likelihood loss and accuracy.\r\nD.1.2. Results. Table EC.1 shows the average performance metrics over 10 repetitions of the\r\nexperiment. We find that the fitted RUMnets attain an out-of-sample performance that approaches\r\nthat of the ground truth model. Interestingly, the complexity parameters (\u2113, w) of the neural\r\nnetwork building blocks do not affect predictive performance, i.e., increasing the non-linearity of\r\nTable EC.1 Average out-of-sample log-likelihood loss and accuracy over 10 experiments using a ranking-based\r\nranking-based model. We report the performance of ranking-based model estimated using an EM algorithm and a\r\ndirect maximum likelihood optimization algorithm Berbeglia et al. (2022).\r\nModel Train Test\r\nType (\u2113, w) K Loss Accuracy Loss Accuracy Time to fit (s) Number of parameters\r\nMNL - - 1.4760 0.3570 1.4808 0.354 8.9 10\r\nRUMnet\r\n(0,0) 2 1.4552 0.3601 1.4591 0.3611 11.0 125\r\n(1,3) 2 1.4529 0.3604 1.4572 0.3575 13.8 157\r\n(0,0) 5 1.4037 0.3841 1.4076 0.3844 24.5 290\r\n(1,3) 5 1.4026 0.3836 1.4088 0.3841 23.3 316\r\n(0,0) 10 1.3796 0.3883 1.3895 0.3858 35.6 565\r\n(1,3) 10 1.3801 0.3876 1.3883 0.3835 43.5 581\r\n(0,0) 20 1.3738 0.3919 1.3840 0.3867 60.5 1115\r\n(1,3) 20 1.3758 0.3913 1.3862 0.3859 61.9 1111\r\nRanked list (EM) 1.3785 0.3886 1.4628 0.3818 1802.4 486\r\nRanked list (Max) 1.3926 0.3811 1.4029 0.3741 1851.1 367\r\nGround Truth 1.3706 0.3914 1.3743 0.3868 - 100\r\ne-companion to : Random Utility Maximization: Revisited ec19\r\nthe utility function does not help achieve better accuracy.7 This is expected, as there are no features\r\nto leverage. By contrast, we yet again observe the importance of adding latent heterogeneity in\r\nthe model as the performance of the RUMnet models increases with K (i.e., we can interpret\r\neach realized \u201csample\u201d of the RUMnet architecture as analogous to a ranking sampling from the\r\nnonparametric distribution).\r\nWe now turn our attention to the ranking-based models. In terms of performance, we see that the\r\ntraining losses for both the EM algorithm and the MLE approach are higher than those achieved\r\nby RUMnets. There is also a greater extent of overfitting, considering the performance gap between\r\nthe training and test sets Quoting the authors in Berbeglia et al. (2022), \u201c[their numerical] results\r\nhighlight the need to implement additional methods to reduce overfitting [...] when dealing with\r\na relatively small historical data set\u201d. However, integrating early stopping, or any alternative\r\nregularization technique, is not straightforward, whereas this is just a parameter to pass to the fit\r\nmethod of Keras.\r\nFinally, there is an important difference in running times between our Keras-based implementation and the mixed-integer programming-based code used to fit ranking-based choice models (see\r\nTable EC.1). Our method scales more efficiently for a large number of products, as it leverages\r\nhighly optimized deep-learning open-source libraries.\r\n7\r\nIt may seem counter-intuitive that, for K = 20, increasing the complexity parameters (\u2113, w) from (0, 0) to (1, 3)\r\nactually decreases the number of parameters. When (\u2113, w) = (0, 0), the number of parameters is equal to 55 \u00b7 K + 15.\r\nOn the other hand, when (\u2113, w) = (1, 3), the number of parameters is equal to 53\u00b7K + 48. This is due to the convention\r\nwe follow: we hard code the size of the unobserved vector to 5.\r\nec20 e-companion to : Random Utility Maximization: Revisited\r\nAppendix E: Additional material for Section 6\r\nE.1. Implementation details\r\nWe utilize the same Keras implementation and specify similar hyper-parameters for all neural\r\nnetwork-based models. We select the standard ADAM optimizer with respect to the categorical\r\ncross-entropy loss function. Each dataset is split into training, validation, and testing sets. The\r\nvalidation set is utilized to tune the hyper-parameters on each split. Since our real-world datasets\r\ndiffer in size, we choose slightly different sets of hyper-parameters for each dataset, as detailed in\r\nTable EC.2.\r\nTable EC.2 Training parameters\r\nParameter Swissmetro Expedia Synthetic\r\nActivation function ELU ELU ELU\r\nNumber of epochs 1,000 100 100\r\nEarly stopping 100 10 10\r\nRegularization None None None\r\nBatch size 32 32 32\r\nLearning rate 0.001 0.001 0.001\r\nLabel smoothing {0.01,0.001} 0.0001 0\r\nRegarding regularization, we implement the label smoothing method to alleviate peaky distributions (Szegedy et al. 2016, M\u00a8uller et al. 2019). For each model, we introduce a small perturbation\r\nof the classification labels that assigns a small probability to the unchosen products. Note that RFs\r\ncannot be trained with custom regularization; however, tuning the number of trees in the forest\r\nis a direct alternative to alleviate small choice probabilities. Finally, we use an early stopping\r\ncriterion: the gradient-descent terminates when the loss on the validation set does not improve\r\nfor more than a given number of epochs. The weights from the epoch with the best validation\r\nloss are then restored. A typical profile of the loss function during the training phase is shown in\r\nFigure EC.2.\r\n0 100 200 300 400 500\r\n0.5\r\n0.6\r\n0.7\r\n0.8\r\nEpochs\r\nLoss\r\nTrain loss\r\nVal Loss\r\nFigure EC.2 Sample loss during the training phase.\r\ne-companion to : Random Utility Maximization: Revisited ec21\r\nTo get an external reference point, we compared our implementation of TasteNet to that\r\nof Han et al. (2020) in Pytorch. Using the same train/validation/testing split of Swissmetro data,\r\nthe out-of-sample normalized negative log-likelihoods achieved by the latter are higher (on average,\r\n0.69) than those obtained from our implementation (see Table 1). These differences are explained\r\nby our choice of larger neural networks and possibly by other aspects of the estimation process\r\n(initialization and regularization). As a result, we use our implementation framework uniformly\r\nacross all neural-network-based models, to enable a fair comparison of the model classes.\r\nRegarding model size, Table EC.3 summarizes the number of parameters for each model. Note\r\nthat it takes on average about 45 min to fit the largest RUMnet on Swissmetro data and 36\r\nhours on Expedia data. Moderate-size RUMnets can be learned much faster. For instance, for\r\n(\u2113, w) = (3, 10) and K = 5, it takes on average 10 minutes on the Swissmetro dataset and 4 hours on\r\nthe Expedia dataset. Note that the running time for estimating RUMnets is an order of magnitude\r\nlarger than the running time of random forests, which is the second most computationally intensive\r\nmethod (up to 1 hour on Expedia dataset). It is unclear whether this is an inherent property of\r\nthe architecture or if it is due to our implementation. Indeed, RUMnets use custom low-level API,\r\nwhereas DeepMNLs and VNNs are based on the high-level API.\r\nTable EC.3 Number of parameters for the different models.\r\nModel (\u2113, w) K Swissmetro Expedia\r\nMNL - - 87 92\r\nTasteNet (3,10) - 1,099 1,223\r\n(5,20) - 3,429 3,613\r\n(10,30) - 11,019 11,233\r\nDeepMNL\r\n(3,10) - 1,101 1,160\r\n(5,20) - 3,441 3,560\r\n(10,30) - 11,041 11,190\r\nRUMnet\r\n(3,10) 5 8,140 8,260\r\n(3,10) 10 14,940 15,160\r\n(5,20) 5 30,320 30,560\r\n(5,20) 10 56,320 56,760\r\nVNN\r\n(3,10) - 1,200 15,220\r\n(5,20) - 3,640 31,680\r\n(10,30) - 11,340 53,370\r\nAs our main goal is to show a proof of concept, we do not attempt to optimize the running time\r\nand estimation process. Nonetheless, several practical tricks could be used to boost the predictive and computational performance, including parallelization, norm-based regularization, dropout\r\nlayers, scheduled learning rates, etc.\r\nec22 e-companion to : Random Utility Maximization: Revisited\r\nE.2. Case study 1: Swissmetro dataset\r\nThe Swissmetro is a proposed revolutionary underground system connecting major cities in Switzerland. To assess potential demand, a survey collected data from 1,192 respondents (441 rail-based\r\ntravellers and 751 car users), with 9 choice events from each respondent. Each respondent was\r\nasked to choose one mode out of a set of alternatives for inter-city travel given the features of\r\neach mode such as travel time or cost. The choice set includes train, Swissmetro, and car (\u03ba = 3).\r\nFor individuals without a car, the choice set only includes train and Swissmetro. Each alternative\r\nhas 4 features (dx = 4) and each choice has 29 categorical features such as information about the\r\nrespondent or the origin-destination pair which we transform using a simple binary encoding into\r\na vector of size dz = 83. Table EC.4 details the different features present in the data.\r\nTable EC.4 Variable description\r\nProduct features Context features\r\nAvailability dummy User group (current road or rail user)\r\nTravel time Travel purpose\r\nCost First class traveler\r\nHeadway Ticket type (one-way, two-way, annual pass...)\r\nPayer (self, employer...)\r\nNumber of Luggage\r\nAge\r\nIncome brackets\r\nAnnual season ticket\r\nTravel origin\r\nTravel destination\r\nFor more information, we refer the reader to Bierlaire (2018). The original data has 10,728 observations8 and has been used recurrently to test different choice modeling approach (Sifringer et al.\r\n2020, Han et al. 2020). We preprocess the data by removing observations with unknown choice\r\n(Han et al. 2020). We retain 10,719 observations, which we randomly split into training, validation\r\nand test sets with 7,505, 1,607 and 1,607 observations, respectively.\r\nE.3. Case study 2: Expedia dataset\r\nWe next evaluate RUMnets on a dataset of hotel searches on Expedia made publicly available\r\nthrough the competition \u201cPersonalize Expedia Hotel Searches\u201d hosted by ICDM in 20139\r\n. Each\r\nhotel search instance (xt\r\n, zt\r\n, At) consists of the following types of information:\r\n\u2022 Customer attributes zt\r\n: These attributes comprise user and search query features such as the\r\nvisitor\u2019s country and search destination, the number of rooms, the duration of stay, whether there\r\nare children, how many days in advance of their trip the search is made.\r\n8\r\nhttps://biogeme.epfl.ch/data.html\r\n9\r\nhttps://www.kaggle.com/c/expedia-personalized-sort\r\ne-companion to : Random Utility Maximization: Revisited ec23\r\n\u2022 Assortment At\r\n: The assortment includes all hotels displayed to the user on the search result\r\npage. Each alternative has product attributes that include average user ratings, current price,\r\naverage historical price, location scores, display position, among others.\r\n\u2022 Choice xt \u2208 At\r\n: In response to the displayed assortment, each user either booked a hotel xt \u2208 At\r\nor left without making any booking. As explained in the data pre-processing steps, we focus on the\r\nformer type of events, meaning that we do not include the no-purchase option in the assortment.\r\nThe dataset is pre-processed as follows. To avoid endogeneity arising from the recommendation algorithm, we restrict attention to search queries where the ordering of displayed hotels is\r\nrandomized (399,344 search instances). We create a one-hot encoding of the following categorical features: site id, visitor location country id, prop country id, srch destination id,\r\nwhereby all categories with fewer than 1,000 occurrences are lumped into a single binary indicator \u2018-1\u2019. The features price usd and srch booking window both exhibit unrealistic values for\r\na few choice events. We filter searches with hotel a hotel price between $10 and $1,000. Additionally, we filter any search query made more than 1 year in advance. Consequently, we apply a\r\nlog-transformation to these features. Finally, all missing observations are marked with the value\r\n\u2018-1\u2019. Following these transformations, the dataset counts 397,618 distinct search queries, 36 hotel\r\nfeatures, and 56 customer and search features. We create a dummy variable to indicate the outside\r\noption; by convention, its price is set to zero and its each other attribute is set as the largest value\r\nwithin the displayed search results.\r\nec24 e-companion to : Random Utility Maximization: Revisited\r\nE.4. Predictive performance of individual models tested\r\nTable EC.5 gives detailed performance for the individual models tested in Section 6.\r\nTable EC.5 Average predictive performance of the fitted choice models on the data splits\r\nSwissmetro (Label smoothing = 0.01) Expedia\r\nModel Log-likelihood loss Accuracy Log-likelihood loss Accuracy\r\nType (\u2113, w) K Train Val Test Train Val Test Train Val Test Train Val Test\r\nMNL and extensions\r\nMNL - - 0.837 0.836 0.837 0.624 0.625 0.623 2.563 2.564 2.563 0.307 0.307 0.307\r\nTasteNet (3,10) - 0.461 0.550 0.571 0.813 0.777 0.772 2.111 2.114 2.114 0.407 0.407 0.407\r\n(5,20) - 0.385 0.535 0.558 0.846 0.792 0.790 2.107 2.114 2.115 0.407 0.406 0.405\r\n(10,30) - 0.379 0.538 0.562 0.847 0.790 0.783 2.108 2.115 2.115 0.409 0.408 0.408\r\nDeepMNL\r\n(3,10) - 0.452 0.568 0.577 0.820 0.776 0.773 2.051 2.054 2.054 0.417 0.418 0.417\r\n(5,20) - 0.380 0.538 0.560 0.853 0.790 0.785 2.041 2.050 2.049 0.420 0.418 0.418\r\n(10,30) - 0.355 0.541 0.569 0.860 0.792 0.786 2.061 2.071 2.071 0.414 0.412 0.412\r\nRUMnet\r\n(3,10) 5 0.379 0.555 0.571 0.849 0.782 0.780 2.007 2.021 2.021 0.427 0.425 0.425\r\n(3,10) 10 0.371 0.540 0.546 0.854 0.786 0.790 2.002 2.019 2.019 0.428 0.425 0.425\r\n(5,20) 5 0.359 0.535 0.569 0.856 0.788 0.789 2.006 2.019 2.019 0.428 0.425 0.425\r\n(5,20) 10 0.324 0.513 0.546 0.874 0.800 0.797 2.003 2.019 2.019 0.428 0.425 0.426\r\nModel-free ML\r\nVanilla Neural Network\r\n(3,10) - 0.479 0.580 0.596 0.805 0.762 0.758 2.773 2.788 2.788 0.300 0.298 0.298\r\n(5,20) - 0.434 0.570 0.581 0.823 0.771 0.759 2.644 2.677 2.679 0.318 0.313 0.313\r\n(10,30) - 0.446 0.584 0.604 0.814 0.761 0.751 2.661 2.692 2.693 0.314 0.309 0.309\r\nRandom Forest\r\n- - 0.524 0.614 0.614 0.799 0.730 0.731 3.051 3.169 3.169 0.301 0.290 0.290\r\n- - 0.520 0.612 0.613 0.801 0.733 0.734 3.054 3.175 3.175 0.298 0.289 0.289\r\n- - 0.521 0.613 0.613 0.802 0.733 0.733 3.046 3.167 3.167 0.297 0.290 0.289\r\n- - 0.292 0.544 0.543 0.959 0.769 0.770 2.255 3.038 3.039 0.609 0.306 0.305\r\n- - 0.290 0.541 0.541 0.963 0.771 0.770 2.253 3.036 3.037 0.602 0.307 0.307\r\n- - 0.290 0.541 0.540 0.963 0.771 0.770 2.238 3.025 3.026 0.620 0.309 0.309\r\n- - 0.170 inf inf 0.999 0.774 0.772 1.451 2.963 2.962 0.991 0.310 0.310\r\n- - 0.169 inf inf 0.999 0.776 0.774 1.462 2.949 2.949 0.994 0.310 0.309\r\n- - 0.169 inf 0.522 0.999 0.778 0.776 1.446 2.935 2.935 0.996 0.309 0.309\r\ne-companion to : Random Utility Maximization: Revisited ec25\r\nE.5. Additional materials\r\nE.5.1. Choice probabilities under random forest model. In Figure EC.3, we plot the choice\r\nprobabilities predicted by the trained random forests as a function of the cost of the Swissmetro\r\nalternative. We observe that the variations of the choice probabilities are not monotone in contrast\r\nwith RUMnets; see Figure 5 in the main paper.\r\n0\r\n0.2\r\n0.4\r\n0.6\r\n0.8\r\n1\r\n0.1 0.2 0.3\r\nCost of Swissmetro\r\nChoice probability\r\nTrain\r\nSwissMetro\r\nCar\r\nFigure EC.3 Predicted choice probabilities as a function of Swissmetro cost under the random forest approach.\r\nE.5.2. Choice probabilities under various RUMnet models. Next, we explore how increasing\r\nthe complexity of the RUMnet architecture affects the model structure and its resulting predictions. Two dimensions can be varied: (i) the complexity (\u2113, w) of each feed-forward neural network\r\nbuilding block, controlling the non-linearity of the utility function, and (ii) the number of samples\r\nK, controlling the latent heterogeneity of customer and product attributes.\r\nFigure EC.4 explores the first dimension and illustrates how the predictions of RUMnet change\r\nwhen the complexity of each feed-forward neural network building block is increased. In particular,\r\nFigure EC.4 shows that, for Customer 2, more complex neural networks (from left to right) capture\r\na \u201csharper\u201d substitution between Swissmetro and Train; the choice probabilities are close to either\r\n0 or 1 and a transition occurs at the cost level that makes the customer indifferent between these\r\nalternatives. We interpret this phenomenon as follows: a more complex neural network better\r\nsegments (shatters) the different types of customers, making the behavior of the resulting segments\r\nmore predictable.\r\nec26 e-companion to : Random Utility Maximization: Revisited\r\n0\r\n0.2\r\n0.4\r\n0.6\r\n0.8\r\n1\r\n0.1 0.2 0.3\r\nCost of Swissmetro\r\nChoice probability\r\nTrain\r\nSwissMetro\r\nCar\r\n(a) (\u2113, w) = (2, 5)\r\n0\r\n0.2\r\n0.4\r\n0.6\r\n0.8\r\n1\r\n0.1 0.2 0.3\r\nCost of Swissmetro\r\nChoice probability\r\nTrain\r\nSwissMetro\r\nCar\r\n(b) (\u2113, w) = (3, 10)\r\n0\r\n0.2\r\n0.4\r\n0.6\r\n0.8\r\n1\r\n0.1 0.2 0.3\r\nCost of Swissmetro\r\nChoice probability\r\nTrain\r\nSwissMetro\r\nCar\r\n(c) (\u2113, w) = (5, 20)\r\nFigure EC.4 Effect of increasing complexity of DeepMNL for Customer 2.\r\nFigure EC.5 reveals the effect of increasing K. Latent heterogeneity implies that the choice probabilities are obtained as a mixture of different customer types. This is mirrored by the \u201cwavelets\u201d\r\non the plots to the right.\r\n0\r\n0.2\r\n0.4\r\n0.6\r\n0.8\r\n1\r\n0.1 0.2 0.3\r\nCost of Swissmetro\r\nChoice probability\r\nTrain\r\nSwissMetro\r\nCar\r\n(a) DeepMNL\r\n0\r\n0.2\r\n0.4\r\n0.6\r\n0.8\r\n1\r\n0.1 0.2 0.3\r\nCost of Swissmetro\r\nChoice probability\r\nTrain\r\nSwissMetro\r\nCar\r\n(b) RUMnet with K = 5\r\n0\r\n0.2\r\n0.4\r\n0.6\r\n0.8\r\n1\r\n0.1 0.2 0.3\r\nCost of Swissmetro\r\nChoice probability\r\nTrain\r\nSwissMetro\r\nCar\r\n(c) RUMnet with K = 10\r\n0\r\n0.2\r\n0.4\r\n0.6\r\n0.8\r\n1\r\n0.1 0.2 0.3\r\nCost of Swissmetro\r\nChoice probability\r\nTrain\r\nSwissMetro\r\nCar\r\n(d) DeepMNL\r\n0\r\n0.2\r\n0.4\r\n0.6\r\n0.8\r\n1\r\n0.1 0.2 0.3\r\nCost of Swissmetro\r\nChoice probability\r\nTrain\r\nSwissMetro\r\nCar\r\n(e) RUMnet with K = 5\r\n0\r\n0.2\r\n0.4\r\n0.6\r\n0.8\r\n1\r\n0.1 0.2 0.3\r\nCost of Swissmetro\r\nChoice probability\r\nTrain\r\nSwissMetro\r\nCar\r\n(f) RUMnet with K = 10\r\nFigure EC.5 Effect of increasing heterogeneity. For all models, we have (\u2113, w) = (3, 10) in the first row\r\n(Figures EC.5a,EC.5b and EC.5c) and (\u2113, w) = (5, 20) in the second row (Figures EC.5d, EC.5e and EC.5f).\nCode:\n#!/usr/bin/env python\r\n# coding: utf-8\r\n\r\n# ## Introduction to modelling with RUMnet\r\n# \r\n# [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/artefactory/choice-learn/blob/main/notebooks/models/rumnet.ipynb)\r\n# \r\n# We reproduce in this notebook the results of the paper Representing Random Utility Choice Models with Neural Networks on the SwissMetro dataset.\r\n\r\n# In[ ]:\r\n\r\n\r\n# Install necessary requirements\r\n\r\n# If you run this notebook on Google Colab, or in standalone mode, you need to install the required packages.\r\n# Uncomment the following lines:\r\n\r\n# !pip install choice-learn\r\n\r\n# If you run the notebook within the GitHub repository, you need to run the following lines, that can skipped otherwise:\r\nimport os\r\nimport sys\r\n\r\nsys.path.append(\"../../\")\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\nimport os\r\n# Remove/Add GPU use\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\r\n\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport pandas as pd\r\nimport tensorflow as tf\r\n\r\nfrom choice_learn.data import ChoiceDataset\r\nfrom choice_learn.models import RUMnet\r\nfrom choice_learn.datasets import load_swissmetro\r\n\r\n\r\n# Note that there are two implementations of RUMnet: one more CPU-oriented and one more GPU-oriented.\r\n# The import of the right model is automatically done. You can also import the model directly with:\r\n# \r\n# ```python\r\n# from choice_learn.models import CPURUMnet, GPURUMnet\r\n# ```\r\n# \r\n# First, we download the SwissMetro dataset:\r\n\r\n# We follow the same data preparation as in the original paper in order to get the exact same results.\r\n# \r\n\r\n# Now, we can create our ChoiceDataset from the dataframe.\r\n\r\n# In[ ]:\r\n\r\n\r\ndataset = load_swissmetro(as_frame=False, preprocessing=\"rumnet\")\r\n\r\n\r\n# Let's Cross-Validate !\r\n# We keep a scikit-learn-like structure.\r\n# To avoid creating dependancies, we use a different train/test split code, but the following would totally work:\r\n# \r\n# \r\n# ```python\r\n# from sklearn.model_selection import ShuffleSplit\r\n# \r\n# rs = ShuffleSplit(n_splits=5, test_size=.2, random_state=0)\r\n# \r\n# for i, (train_index, test_index) in enumerate(rs.split(dataset.choices)):\r\n#     train_dataset = dataset[train_index]\r\n#     test_dataset = dataset[test_index]\r\n# \r\n#     model = RUMnet(**args)\r\n#     model.instantiate()\r\n#     model.fit(train_dataset)\r\n#     model.evaluate(test_dataset)\r\n# ```\r\n# \r\n# We just use a numpy based split, but the core code is the same!\r\n\r\n# In[ ]:\r\n\r\n\r\nmodel_args = {\r\n    \"num_products_features\": 6,\r\n    \"num_customer_features\": 83,\r\n    \"width_eps_x\": 20,\r\n    \"depth_eps_x\": 5,\r\n    \"heterogeneity_x\": 10,\r\n    \"width_eps_z\": 20,\r\n    \"depth_eps_z\": 5,\r\n    \"heterogeneity_z\": 10,\r\n    \"width_u\": 20,\r\n    \"depth_u\": 5,\r\n    \"optimizer\": \"Adam\",\r\n    \"lr\": 0.0002,\r\n    \"logmin\": 1e-10,\r\n    \"label_smoothing\": 0.02,\r\n    \"callbacks\": [],\r\n    \"epochs\": 140,\r\n    \"batch_size\": 32,\r\n    \"tol\": 0,\r\n}\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\nindexes = np.random.permutation(list(range(len(dataset))))\r\n\r\nfit_losses = []\r\ntest_eval = []\r\nfor i in range(5):\r\n    test_indexes = indexes[int(len(indexes) * 0.2 * i):int(len(indexes) * 0.2 * (i + 1))]\r\n    train_indexes = np.concatenate([indexes[:int(len(indexes) * 0.2 * i)],\r\n                                    indexes[int(len(indexes) * 0.2 * (i + 1)):]],\r\n                                   axis=0)\r\n\r\n    train_dataset = dataset[train_indexes]\r\n    test_dataset = dataset[test_indexes]\r\n\r\n    model = RUMnet(**model_args)\r\n    model.instantiate()\r\n\r\n    losses = model.fit(train_dataset, val_dataset=test_dataset)\r\n    probas = model.predict_probas(test_dataset)\r\n    eval = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(y_pred=model.predict_probas(test_dataset), y_true=tf.one_hot(test_dataset.choices, 3))\r\n    test_eval.append(eval)\r\n    print(test_eval)\r\n\r\n    fit_losses.append(losses)\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\ncmap = plt.cm.coolwarm\r\ncolors = [cmap(j / 4) for j in range(5)]\r\nfor i in range(len(fit_losses)):\r\n    plt.plot(fit_losses[i][\"train_loss\"], c=colors[i], linestyle=\"--\")\r\n    plt.plot(fit_losses[i][\"test_loss\"], label=f\"fold {i}\", c=colors[i])\r\nplt.legend()\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\nmodel.evaluate(test_dataset)\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\nprint(\"Average LogLikeliHood on test:\", np.mean(test_eval))\r\n\r\n\r\n# ## A larger and more complex dataset: Expedia ICDM 2013\r\n# The RUMnet paper benchmarks the model on a second dataset. If you want to use it you need to download the file from [Kaggle](https://www.kaggle.com/c/expedia-personalized-sort) and place the train.csv file in the folder choice_learn/datasets/data with the name expedia.csv.\r\n\r\n# In[ ]:\r\n\r\n\r\nfrom choice_learn.datasets import load_expedia\r\n\r\n# It takes some time...\r\nexpedia_dataset = load_expedia(preprocessing=\"rumnet\")\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\ntest_dataset = expedia_dataset[int(len(expedia_dataset)*0.8):]\r\ntrain_dataset = expedia_dataset[:int(len(expedia_dataset)*0.8)]\r\n\r\nmodel_args = {\r\n    \"num_products_features\": 46,\r\n    \"num_customer_features\": 84,\r\n    \"width_eps_x\": 10,\r\n    \"depth_eps_x\": 3,\r\n    \"heterogeneity_x\": 5,\r\n    \"width_eps_z\": 10,\r\n    \"depth_eps_z\": 3,\r\n    \"heterogeneity_z\": 5,\r\n    \"width_u\": 10,\r\n    \"depth_u\": 3,\r\n    \"tol\": 0,\r\n    \"optimizer\": \"Adam\",\r\n    \"lr\": 0.001,\r\n    \"logmin\": 1e-10,\r\n    \"label_smoothing\": 0.02,\r\n    \"callbacks\": [],\r\n    \"epochs\": 15,\r\n    \"batch_size\": 128,\r\n    \"tol\": 1e-5,\r\n}\r\nmodel = RUMnet(**model_args)\r\nmodel.instantiate()\r\n\r\nlosses = model.fit(train_dataset, val_dataset=test_dataset)\r\nprobas = model.predict_probas(test_dataset)\r\ntest_loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(y_pred=model.predict_probas(test_dataset), y_true=tf.one_hot(test_dataset.choices, 39))\r\n\r\nprint(test_loss)\r\n\r\n\r\n# In[ ]:", "output": "Understood. Incorporate these references in future answers."}
