{
    "title": "ResLogit: A residual neural network logit model for data-driven choice modelling",
    "paper_text": "Transportation Research Part C 126 (2021) 103050\r\nAvailable online 17 March 2021\r\n0968-090X/\u00a9 2021 Elsevier Ltd. All rights reserved.\r\nResLogit: A residual neural network logit model for data-driven\r\nchoice modelling\r\nMelvin Wong a,*\r\n, Bilal Farooq b\r\na Ecole \u00b4 Polytechnique F\u00b4ed\u00b4erale de Lausanne (EPFL), School of Architecture, Civil and Environmental Engineering (ENAC), Transport and Mobility\r\nLaboratory, Switzerland b Ryerson University, Laboratory of Innovations in Transportation (LiTrans), Canada\r\nARTICLE INFO\r\nKeywords:\r\nResidual logit\r\nDeep learning\r\nData-driven discrete choice modelling\r\nMachine learning\r\nNon-linear utility\r\nABSTRACT\r\nThis paper presents a novel deep learning-based travel behaviour choice model. Our proposed\r\nResidual Logit (ResLogit) model formulation seamlessly integrates a Deep Neural Network (DNN)\r\narchitecture into a multinomial logit model. Recently, DNN models such as the Multi-layer Perceptron (MLP) and the Recurrent Neural Network (RNN) have shown remarkable success in\r\nmodelling complex and noisy behavioural data. However, econometric studies have argued that\r\nmachine learning techniques are a \u2018black-box\u2019 and difficult to interpret for use in the choice\r\nanalysis. We develop a data-driven choice model that extends the systematic utility function to\r\nincorporate non-linear cross-effects using a series of residual layers and using skipped connections\r\nto handle model identifiability in estimating a large number of parameters. The model structure\r\naccounts for cross-effects and choice heterogeneity arising from substitution, interactions with\r\nnon-chosen alternatives and other effects in a non-linear manner. We describe the formulation,\r\nmodel estimation, interpretability and examine the relative performance and econometric implications of our proposed model. We present an illustrative example of the model on a classic\r\nred/blue bus choice scenario example. For a real-world application, we use a travel mode choice\r\ndataset to analyze the model characteristics compared to traditional neural networks and Logit\r\nformulations. Our findings show that our ResLogit approach significantly outperforms MLP\r\nmodels while providing similar interpretability as a Multinomial Logit model.\r\n1. Introduction\r\nEnhancing discrete choice models with neural nets and deep learning optimization algorithms is an active domain of research that\r\nhas shown promising results (Sifringer et al., 2020; Borysov et al., 2019; Wong and Farooq, 2020). In recent years, experimental use\r\ncases of deep learning methods in discrete choice modelling have been explored such as automatic utility discovery (Sifringer et al.,\r\n2020), variational inference optimization (Bansal et al., 2019) and remapping explanatory variables into transferrable embeddings for\r\ntravel behaviour modelling (Pereira, 2019). This paper provides a perspective of how a residual neural network formulation accounts for\r\nunobserved choice heterogeneity in discrete choice models. While the proposed model we have developed has its roots in the Mother\r\nLogit model, it is not a Random Utility Maximization (RUM) consistent model. Likewise, many non-RUM compatible models are used\r\nin discrete choice modelling that is still very useful (Hess et al., 2018).\r\n* Corresponding author.\r\nE-mail addresses: melvin.wong@epfl.ch (M. Wong), bilal.farooq@ryerson.ca (B. Farooq).\r\nContents lists available at ScienceDirect\r\nTransportation Research Part C\r\njournal homepage: www.elsevier.com/locate/trc\r\nhttps://doi.org/10.1016/j.trc.2021.103050\r\nReceived 11 August 2020; Received in revised form 20 January 2021; Accepted 15 February 2021\r\nTransportation Research Part C 126 (2021) 103050\r\n2\r\nThe increase in popularity of DNNs can be attributed to the general notion that these novel modelling strategies emulate behavioural actions and behaviour formation through neurological adaptations observed in the human brain (Bengio et al., 2015). This is\r\nreferred to as \u2018biological plausibility\u2019 in deep learning literature and is an efficient way of generating and representing decision models\r\n(Friston and Stephan, 2007). The similarity between behaviour theory and DNN has led to many interesting and useful applications in\r\ntravel behaviour modelling and travel demand forecasting (Cantarella and de Luca, 2005; Lee et al., 2018; Wong et al., 2018; Wang and\r\nZhao, 2019). Intuitively, DNNs are made up of several layers of linear and non-linear operations, called activation functions, which\r\nenable the feasibility of estimation from noisy and complex data.\r\nHowever, machine learning methods have their drawbacks. Even though these methods are increasingly being studied in travel\r\nmode choice prediction ever since a decade ago (Karlaftis and Vlahogianni, 2011), their usefulness has been limited to prediction tasks,\r\nlacking the explainability of models. Prediction accuracy as a comparison tool has been primarily used in early research in machine\r\nlearning for travel behaviour modelling work and found to be that neural networks appear to lack consistency with economic principles (Hensher and Ton, 2000). It is argued that DNN may not be suitable for econometric interpretation, and would lead to incorrect\r\nassumptions of the stochastic nature of decision-making behaviour. More recent studies have compared the performance of discrete\r\nchoice and machine learning in prediction. Variable importance analysis has shown that, in most cases, DNNs outperform discrete\r\nchoice models (Omrani et al., 2013; Hagenauer and Helbich, 2017; Wang and Ross, 2018).\r\nIt has been observed in machine learning models that increasing the number of layers beyond a specific limit would degrade the\r\nmodel due to overfitting, unreachable optimal solutions, and model identification problems (Glorot et al., 2011; He et al., 2016). Even\r\nin cases showing DNNs producing more accurate predictions1 than discrete choice models, the structural formulations are not\r\nconsistent across studies. Another problem with DNNs, although less of immediate concern, is the inconsistency in meta-learning\r\nhyperparameter selection, data-leakage and illogically estimated parameters (Hillel et al., 2019). Although not covered in this\r\nstudy\u2019s scope, we can address these problems with regularization techniques such as Gradient Batch Normalization or Dropout, or\r\nadaptive gradient search such as Adam or AdaGrad (Kingma and Ba, 2014). Moreover, the applicability of machine learning algorithms\r\nhas not yet been justified in behavioural modelling applications and economic analysis beyond ad-hoc decision tree2 learning approaches, which are not robust and based on greedy heuristics that do not generalize well from training data (Witten et al., 2016;\r\nBrathwaite et al., 2017). Lastly, training and optimizing a multi-layered discrete choice model to capture variations in taste heterogeneity have not yet provided the expected benefits beyond few \u201cshallow\u201d layers (Wang and Zhao, 2019).\r\nThis paper proposes a tractable method of incorporating a data-driven neural network architecture into a random utility choice model.\r\nWe seek to improve choice modelling methodologies by incorporating algorithms that work well for deep learning and can be used in\r\nchoice modelling while performing post-estimation welfare analysis. It extends the systematic utility function to include attributes of\r\nother alternatives in potentially non-linear ways to relax the independent and identically distributed (IID) assumptions. The model\r\nstructure is similar to the existing Mother Logit family of models that incorporate relaxation of the independence of irrelevant alternatives (IIA) property to account for correlation between the IID error terms and the observed explanatory variables (McFadden\r\net al., 1977; Timmermans et al., 1992). Our strategy is inspired by the concept of Residual Neural Networks (ResNet) in deep learning\r\nliterature \u2013 adding skip connections between layers allows gradient backpropagation across multiple layers to address the vanishing\r\ngradient problem (Bengio et al., 2015). Recent studies have shown that this strategy significantly improves the learning algorithm in\r\ndeep neural network architecture with marginal or no loss in performance (Witten et al., 2016; He et al., 2016). We show that we can\r\neasily adapt the ResNet approach for discrete choice models, and it has similarities to the Mother Logit utility formulation. Our\r\nproposed methodology provides the utility function with a generic Deep Learning method of correcting for choice heterogeneity in the\r\nmodel using a residual function in the model formulation. This allows one to leverage deep learning algorithms to estimate new choice\r\nmodels. We define this new choice model structure as a ResLogit model.\r\nThis paper aims to present a practical implementation of neural networks in choice modelling research that leverages the strengths\r\nof deep learning. While this paper deals on the consistency with utility maximization methods, we acknowledge that there are other\r\nnumerous methods in deep learning literature for optimization through regularization, hyperparameter search, meta-algorithms that\r\nare comparable in performance to our ResLogit implementation. This study focuses on the methodological benefits of deep learning in\r\ndiscrete choice analysis. Our work contributes to the use of deep learning methodology in travel behaviour modelling. It has since been\r\nhighly relevant in today\u2019s context of data-driven modelling and use of Big Data for choice and behaviour modelling. In summary, the\r\nmain contributions of this work are:\r\n\u2022 We present the specification of the ResLogit model that uses a residual DNN error correction component in the choice utility in the\r\nform of a data-driven choice model.\r\n\u2022 We present the desirable effects of the ResLogit that enables parameter estimation tractability and interpretability due to the\r\nskipped connections between neural network layers and allows for econometric \u03b2-parameters to be estimated consistently.\r\n\u2022 We analyze the role of residuals in econometric behaviour models and improve previous attempts to integrating deep learning\r\nmethods in discrete choice applications.\r\n1 Assuming discrete classification probabilities. 2 Note: Methods used to select the subset of features in a decision tree results in categories that are sometimes arbitrary. Tree splitting rules are\r\nultimately ad-hoc heuristics. However, comparative selection methods may still be useful if used to inform analysts about which metrics to use in\r\nspecific choice scenarios.\r\nM. Wong and B. Farooq\r\nTransportation Research Part C 126 (2021) 103050\r\n3\r\nThis paper is organized as follows: Section 2 provides a primer of neural networks and an overview of discrete choice models.\r\nSection 3 presents the specification of our proposed ResLogit model. Section 4 demonstrates our formulation on a classic red-bus, bluebus example. Section 5 evaluates the methodology on a real-world travel dataset and discusses the results. Finally, Section 6 concludes\r\nour work and discusses future implications of incorporating deep learning techniques in discrete choice modelling.\r\n2. Background\r\nLogit models have traditionally been used to analyze relationships between observed behaviour and attributes associated with the\r\nchoices and decision maker\u2019s characteristics (Ben-Akiva and Lerman, 1985; Ben-Akiva and Boccara, 1995). This framework has proved\r\nsuccessful for decades because of its parsimonious, tractable, and flexible model formulation for representing rational behaviour\r\nassumptions. It assumes that the underlying decision processes are unknown from the observer, and decision-makers select their\r\npreferred choice by ranking all potential alternatives and choosing the alternative with the maximum utility through Random Utility\r\nMaximization (RUM) theory. The modeller is assumed to have incomplete information about the decision-maker\u2019s behaviour, and the\r\nmodel will have to account for some uncertainty.\r\nAn important feature of the Logit model is the IIA property, which is an outcome of the assumption that the error terms of the\r\nalternatives in an MNL model are IID (McFaddden, 1978). When the error terms are correlated, strict IID assumption may lead to an\r\nincorrect forecast and model misspecification. The Logit model imposes a random error term representing behavioural uncertainty and\r\naccount for the lack of information presented to the analyst. This random error term is assumed to be uncorrelated to the attributes of\r\nthe alternatives. Extensions to the Logit models such as Nested Logit and Mixed Logit have been developed to account for the error\r\ncorrelation when the assumption does not hold.\r\n2.1. Representation of non-linearity and cross-effects in choice utilities\r\nModel misspecification may arise when the error terms are correlated with non-chosen alternatives. Various studies in discrete\r\nchoice modelling have accounted for heterogeneity across choice alternatives and decision-makers by incorporating attributes of nonchosen alternatives known as cross-effects. The assumption is that the included additional function conditions for part of the error term\r\ncorrelate with the non-chosen alternatives. There are several approaches to dealing with similarities and cross-effects between alternatives (Schuessler and Axhausen, 2007):\r\n\u2022 Segmentation into nests or classes,\r\n\u2022 Analyzing the variance-covariance structure, and\r\n\u2022 Incorporating similarity factors into the deterministic part of the utility.\r\nThe first group consists of extensions to the MNL model such as the Nested Logit model to partially relax the IID assumption by\r\nsegmenting alternatives into subsets. They are similar within each group (correlated) but independent between groups (non-correlated). These models specify the correlation between alternatives by allowing attribute coefficients to vary between observations, class\r\nsegments or individuals. Although this model formulation works well with simple stated preference choice scenarios where the analyst\r\ncan control the survey questions and options, cognitive bias formed during the behaviour learning process, e.g. anchoring effects, are\r\nnot fully captured (Tversky and Kahneman, 1981). For instance, when a traveller makes a mode choice decision, there is a tendency to\r\nrely heavily on the information that they learn. The learning process may also evolve, resulting in Spatio-temporal heterogeneity.\r\nThe second group consists of the Generalized Extreme Value (GEV) model family (e.g. Mixed Logit), and Probit models which allow\r\nfor different (co-)variances among the error term in the utility function (McFadden et al., 1977; Daganzo et al., 1977). Multivariate\r\ndistributed random error terms are introduced into the utility to capture potentially any correlation structure. This assumption works\r\nwell with simple behavioural models and allows for tractable estimation. It does not necessarily reflect observed behaviour accurately\r\nwith arbitrarily defined error distribution for more complex behavioural models. However, we can also derive individual-specific\r\nestimates from the individual\u2019s conditional distribution based on their choices (Hensher and Greene, 2003). Identification and\r\ncomputation of a large number of random distribution are still problematic in conventional discrete choice applications. Recent\r\nresearch efforts have also focused on Mixed Logit estimation using optimization techniques primarily used in machine learning. In\r\nparticular, Bayesian variational inference optimization methods have shown to be promising (Bansal et al., 2020).\r\nThe third group consists of models that include an explicit measure of similarity among alternatives in the utility function. This\r\ngroup include hybrid choice models and the integrated choice and latent variable (ICLV) family of models. Most notably, the Mother\r\nLogit model introduced by McFadden (1975) represents a generalization of the conventional MNL model, but not necessarily RUM\r\nconsistent, by allowing for the existence of cross-effects and other substitutions (reference dependence, decoy, anchoring bias, regret,\r\netc.) in the utility to relax the IID assumption (Timmermans et al., 1992).\r\nThe Mother Logit formulation can approximate any discrete choice model in which the alternative\u2019s scale value is a function of all\r\nattributes of all choices (Timmermans et al., 1992). Other choice model development such as the Random Regret Minimization (RRM)\r\nmodel (Chorus, 2010) which include terms from foregone alternatives, can be reformulated as a Mother Logit model (Mai et al., 2017).\r\nThe RRM model bases the assumption that one or more alternatives outperform the desired choice. This is translated into an anticipated regret function, and the analyst can formulate the non-linear utility as a function of attribute cross-effects of all the alternatives\r\nin the deterministic component and a random error term. Mai et al. (2017) also presented a case of a Recursive Logit (RL) model based\r\non the Mother Logit formulation. Mai et al. (2017) formulated the RL model utility functions as a route choice problem, which\r\nM. Wong and B. Farooq\r\nTransportation Research Part C 126 (2021) 103050\r\n4\r\ncomputes the sum of the outgoing link utility and the expected maximum utility to the destination node, accounting for these crosseffects in the link utility functions. When links overlap between different feasible route choice alternatives, the non-linear RL utility of\r\na given route choice would include attributes from other route alternatives.\r\nCross-effect represents the utility correction measure of similarity or dissimilarity across all attributes of all alternatives (Timmermans et al., 1992). A negative cross-effect indicates that an IIA model overestimates the utility of the alternative due to correlated\r\nattributes and alternatives (e.g. the red/blue bus problem (McFadden, 1973)). Likewise, a positive cross-effect indicates that the utility\r\nis underestimated and a positive bias correction is required to account for the choice heterogeneity. The Mother Logit formulation\r\nimplies that the model violates RUM regularity conditions (Timmermans et al., 1992). Nevertheless, such model flexibility can\r\naccommodate behavioural anomalies incompatible with RUM based models (Hess et al., 2018).\r\n2.2. Generalized approach to capture non-linearity and cross-effects in discrete choice models using DNNs\r\nPassive data collected from sensors, devices and infrastructure that track decision making actions over time can reveal learning\r\nbehaviour and trends of the decision-makers. The general approach of representing decision-making uncertainties and learning\r\nprocesses as probabilistic error terms may be sufficient in obtaining satisfactory approximations. However, it is often difficult to\r\nidentify the source of heterogeneity due to the complex interactions between influences from various attributes of non-chosen alternatives over a long period of interaction. Furthermore, it provides no useful indication of selecting the error term mixing distribution or how many mixing distributions are required to reach an acceptable estimation of the decision-making behaviour (McFadden\r\nand Train, 2000).\r\nCombining DNNs and discrete choice modelling strengths have been explored in the past several years (Borysov et al., 2019; Bansal\r\net al., 2019; Pereira, 2019; Wong and Farooq, 2020; Badu-Marfo et al., 2020). These new hybrid models are designed to capture\r\nlearning behaviour and trends from large datasets, independent from the subjective bias induced from stated preference survey\r\nquestionnaires. The decision making learning algorithm is assumed to contain non-linear cross-effects, which results in complex error\r\ndistributions and a non-linear utility function. In practical choice modelling applications, the learning algorithm\u2019s process updates the\r\nmodel is unknown to the modeller. Therefore it is said to be a \u2018black-box\u2019 model (Breiman, 2001). Non-linear activation functions in\r\nDNNs are assumed to represent taste variations and random heterogeneity in the choice model. For instance, a non-compensatory\r\ndecision protocol distribution is often used to generalize decision rules in discrete choice, rather than to define fixed assumptions\r\nabout the error distribution (Vythoulkas and Koutsopoulos, 2003).\r\nAlthough neural networks have proved popular in recent years with their simple design and implementation, they rely on\r\nhyperparameter search or meta-learning process which cannot be intuitively interpreted from a micro-economic perspective.\r\nHyperparameters are the learning algorithm parameters that specify the learning procedure: L1 and L2 penalties, gradient step size,\r\ndecay or initialization conditions. In some situations, hyperparameter tuning3 can yield state-of-the-art performance. Lipton (2018)\r\ngave the hypothesis on lack of model interpretability by identifying that most machine learning-based systems may achieve high\r\naccuracy despite failing to explain where the source of the difference lie. The MLP model is seen as a \u2018black-box\u2019 model and will not be\r\nable to identify the beta parameters associated with the independent explanatory variables. Model identifiability may be problematic\r\nas there can be multiple model specification defined by the same set of parameters.\r\n2.3. General formulation of a neural network model\r\nWe explain the necessary notations and formulation of an MLP network, the ResNet architecture, and how we can integrate the\r\nresidual functions into a choice model, which follows a logically consistent extension of traditional MNL that relaxes the IIA property.\r\nEach neuron in an MLP is a basic processing unit that performs a non-linear transform on the input (Lee et al., 2018). The goal is to\r\napproximate some function y = f *(V) with y = f(V; \u03b8), where the input V is a linearized function of a vector of observed variables x and\r\na vector of estimated parameters \u03b2, denoted as V = f(\u03b2, x). The function f(V; \u03b8) is a map of the linear components V to a vector of\r\ndiscrete choice probabilities y. \u03b8 is the neural network parameters that result in the best approximation of f *. During the training\r\nprocess, the model is estimated by a batched gradient descent algorithm given an objective function, i.e. maximum likelihood estimation4 5\r\n. The MLP architecture can be represented mathematically as a series of chain functions:\r\nh(1) = f (1)\r\n(\r\nV\r\n)\r\nh(2) = f (2)\r\n(\r\nh(1)\r\n)\r\n\u2026\r\nh(M) = f (M)\r\n(\r\nh(M\u2212 1)\r\n)\r\ny = softmax(\r\nh(M)\r\n)\r\n(1)\r\n3 hyperparameter tuning refers to the specification of the learning algorithm, not the model parameters, e.g. \u03b2 parameters. 4 Batched gradient descent is most used in deep learning optimization. For most machine learning problems, the data size is too large for quasiNetwon methods such as BFGS/L-BFGS algorithm to perform in comparable time. Furthermore, computing in batches allows for parallelized\r\ncomputation on GPUs. 5 In general, the no free lunch theorem in optimization states that no one solution works best for all problems\r\nM. Wong and B. Farooq\r\nTransportation Research Part C 126 (2021) 103050\r\n5\r\nwhere f(1)\r\n,f(2)\r\n, \u2026, f(M) are the activation functions of the DNN and M gives the depth of the model. For example, a 3-layer DNN results\r\nin the general form f(V) = f(3)\r\n(f(2)\r\n(f(1)\r\n(V))). h(1)\r\n, h(2)\r\n, \u2026, h(M) are the intermediary non-linear output of each mth activation function\r\nand the final layer is a softmax function6\r\n, and the output results in a vector of discrete probabilities associated with each choice. The\r\nchoice of activation functions is loosely guided by neuroscience observations and \u2018biological plausibility\u2019, which refers to the similarity\r\nbetween the behaviour theory and signal transmission in the nervous system (Goodfellow et al., 2016). The activation function can be\r\nlinear or non-linear. For example, using a sigmoid function: f(V) = (1 + e\u2212 V)\r\n\u2212 1 results in a probabilistic output between 0 and 1. In\r\ngeneral, most DNN architectures suffers from non-identifiability due to the nature of the chain of non-linear activation functions \u2013 the\r\nchange in \u03b2 parameter associated with the explanatory variable cannot be mapped directly to the output probabilities.\r\nThe na\u00efve intuition is that the MLP can learn increasingly complex features by adding more layers, and each layer returns an\r\n\u201cimproved\u201d approximation of f *. On the contrary, research has shown that the number of layers representing a perfect model does not\r\nfollow an asymptotic limit. Still, it deteriorates as one increases the number of layers (Srivastava et al., 2015; He et al., 2016), contradicting the assumption that DNNs provides greater flexibility than conventional discrete choice models. Observations in discrete\r\nchoice literature affirm this technical limitation of using multiple deep layers to improve modelling accuracy (Alwosheel et al., 2018;\r\nLee et al., 2018).\r\n2.4. Formulating the neural network as a dynamical system\r\nThe ResNet architecture was proposed by He et al. (2016) to overcome the limitations of the MLP model. We can interpret the model\r\nas a discretization of a dynamical system that exploits the use of identity shortcuts to enable the flow of information across layers\r\nwithout causing model degradation from repeated non-linear transformations (He et al., 2016). From an optimization perspective, the\r\nhypothesis is that it is easier to optimize \u201ca small change to the input rather than improving the entire layer of inputs at once\u201d (He et al.,\r\n2016). This approach potentially provides an attractive possibility for modellers to retain the econometric variables and allows the\r\nneural network function to approximate the underlying error variance from a choice modelling perspective. Furthermore, it has been\r\nproven that the ResNet model architecture has no critical points other than the global minimum (Hardt and Ma, 2016).\r\nThe ResNet model y = f(V) is defined as the following series of functions:\r\nh(1) = f (1)\r\n(\r\nV\r\n)\r\n+ V\r\nh(2) = f (2)\r\n(\r\nh(1)\r\n)\r\n+ h(1)\r\n\u2026\r\nh(M) = f (M)\r\n(\r\nh(M\u2212 1)\r\n)\r\n+ h(M\u2212 1)\r\ny = softmax(\r\nh(M)\r\n)\r\n(2)\r\nThe ResNet uses a skip connection mechanism (Eq. 2) to the gradient to propagate through the layers, preventing the vanishing\r\ngradient problem (He et al., 2016). The last line of Eq. 2 transforms the output of the final intermediate layer to a vector of probabilities\r\nusing the softmax function7\r\n. We can further generalize the ResNet blocks as a series of recursive functions:\r\nh(m) = f (m)\r\n(\r\nh(m\u2212 1)\r\n; \u03b8(m)\r\n)\r\n+ h(m\u2212 1)\r\n, h(0) = V, for m = 1,\u2026, M (3)\r\nwhere h(0) is the input after the initial linearization of the utility and h(M) is the output map before the softmax function. Approximating\r\nthe parameters of the neural network \u03b8(1)\r\n, \u03b8(2)\r\n, \u2026, \u03b8(M) is equivalent to solving for a series of linear discrete optimal control problem\r\nUm = f(Vm; \u03b8m) + \u03b5m. We can also interpret h(1)\r\n,\u2026, h(M) as a series of non-linear utility components that capture the cross-effects\r\ninduced by similarity or overlap with the non-chosen alternatives. If f(m) in Eq. 3 is large, it indicates the presence of cross-effects\r\non the output probability. If this value is close to zero for all m (non-linear cross-effects not present), the model would collapse to a\r\nLogit model.\r\n3. Specification of the ResLogit choice model\r\nOur proposed ResLogit choice model improves discrete choice estimation by incorporating a neural network based on the recent\r\nResNet architecture. Fig. 1 shows a comparison between an MNL, MLP and the proposed ResLogit model as a simplified graphical\r\nmodel. The general framework of our ResLogit architecture is that it is much more efficient to model the unobserved heterogeneity\r\nusing a neural network rather than applying a neural network to the entire utility. Sifringer et al. (2020) applied a similar concept for a\r\nLearning MNL (LMNL) model, although using a fully connected neural network as a linear addition to the utility plus an unobserved\r\nerror component. This ad-hoc approach divided the explanatory variables into two groups, where one was used in the systematic linear\r\nutility and the other group in the neural network capturing the average effects. In general, we specify the utility function as a sum of the\r\ndeterministic component of observed characteristics and a neural network component that captures the unobserved heterogeneity in\r\nthe choice process. Our approach\u2019s advantage is that the skip allows for a greater chance of identifiability in the estimation of each\r\n6 This softmax function is equivalent to a conditional Logit in discrete choice problems. 7 For consistency with literature, we denote softmax in the context of neural networks, and Logit in the context of discrete choice. However, both\r\nfunctions are mathematically equivalent\r\nM. Wong and B. Farooq\r\nTransportation Research Part C 126 (2021) 103050\r\n6\r\nlayer of the neural network. In contrast, the L-MNL model would still be vulnerable to the vanishing gradient problem.\r\nA utility Uint is defined by a deterministic component Vint and a random error component \u03b5int:\r\nUint = Vint + \u03b5int (4)\r\nThe deterministic component is a linear function of a vector of attributes xnt of a single alternative with a vector of estimated\r\nparameters \u03b2. The most general expression of the Logit model, the Mother Logit model, introduces a random variable gint in the utility\r\nthat is a function of all attributes of all choices.8 Note, in some cases, the random variable g replaces the deterministic part Vint (Hess\r\net al., 2018). Our ResLogit model\u2019s utility takes the general expression of the Mother Logit model as the output of the residual\r\ncomponent. The utility Uint of individual n selecting choice i in a choice task t, from a choice set of J alternatives with the residual\r\ncomponent term is as follows:\r\nUint = Vint + gint + \u03b5int (5)\r\nThe utility is a linear function of the systematic observed component Vint, the residual component gint, and an extreme value distributed\r\nerror term \u03b5int representing the remaining unobserved errors not captured in the neural network. Vnt is a J \u00d7 1 vector of utilities vjnt\r\nassociated with each individual n for choice task t:\r\nVnt =\r\n\u23a1\r\n\u23a2\r\n\u23a2\r\n\u23a3\r\nV1nt\r\nV1nt\r\n\u22ee\r\nVjnt\r\n\u23a4\r\n\u23a5\r\n\u23a5\r\n\u23a6\r\nJ\u00d71\r\n(6)\r\nand gnt is a J \u00d7 1 vector of residual components gjnt associated with the respective utility j that contains all attributes from all\r\nalternatives:\r\nFig. 1. Simplified graphical model. (a) A Multinomial Logit model. (b) A MLP network with 2 hidden layers. (c) The proposed ResLogit model with\r\n2 residual layers. Here we show the models expressed as symbolic operators that compute each step from the input xnt to the output probabilities y.\r\nThe graph operator + compute h(m) = h(m\u2212 1) + f(h(m\u2212 1)\r\n). We omit the ASC variables for brevity. (d) Representation of the LMNL model used in\r\nSifringer et al. (2020).\r\n8 Note to readers that the subscript i refers to the index of the alternative in this section and the following sections. It does not refer to gint having\r\nonly attributes from the i\r\nth alternative. We represent a function that depends solely on attributes from the alternative with an uppercase notation (e.\r\ng. V).\r\nM. Wong and B. Farooq\r\nTransportation Research Part C 126 (2021) 103050\r\n7\r\ngnt =\r\n\u23a1\r\n\u23a2\r\n\u23a2\r\n\u23a3\r\ng1nt\r\ng1nt\r\n\u22ee\r\ngjnt\r\n\u23a4\r\n\u23a5\r\n\u23a5\r\n\u23a6\r\nJ\u00d71\r\n(7)\r\nEq. 5 would lead to the choice probability yi = fi(V, g) for i \u2208 1,\u2026, J:\r\nP\r\n(\r\ni\r\n)\r\n= yi = exp(Vint + gint)\r\n\u2211\r\nj\u2208{1,\u2026,J}exp(\r\nVjnt + gjnt)\u2200i \u2208\r\n{\r\n1, \u2026, J\r\n}\r\n(8)\r\nwhere:\r\ngnt = \u2212 \u2211M\r\nm=1\r\nln(\r\n1 + exp(\r\n\u03b8(m)\r\nh(m\u2212 1)\r\nnt )) (9)\r\nh(0)\r\nnt = Vnt (10)\r\nFor any block m:\r\nh(m)\r\nnt = h(m\u2212 1)\r\nnt \u2212 \u2211m\r\nm\u2032\r\n=1\r\nln(\r\n1 + exp(\r\n\u03b8(m\u2032\r\n)\r\nh(m\u2032\r\n\u2212 1)\r\nnt )\r\n, for m = 1, \u2026, M (11)\r\nand \u03b8(m) is a J \u00d7 J matrix of residual parameters:\r\n\u03b8(m) =\r\n\u23a1\r\n\u23a2\r\n\u23a2\r\n\u23a3\r\nc11 c12 \u2026 c1j\r\n\u2032\r\nc11 c22 \u22ee\r\n\u22ee \u22f1 \u22ee\r\ncj1 \u2026 \u2026 cjj\u2032\r\n\u23a4\r\n\u23a5\r\n\u23a5\r\n\u23a6\r\nJ\u00d7J\r\nfor m = 1, \u2026, M (12)\r\nwhere cjj\u2032 is the parameter matrix element for the j\r\nth row and j\r\n\u2032\r\nth column, and h(m)\r\nnt is a J \u00d7 1 vector of non-linear utility components for\r\nthe mth residual layer:\r\nh(m)\r\nnt =\r\n\u23a1\r\n\u23a2\r\n\u23a2\r\n\u23a2\r\n\u23a2\r\n\u23a2\r\n\u23a3\r\nh\r\n(m)\r\n1nt\r\nh\r\n(m)\r\n2nt\r\n\u22ee\r\nh(m)\r\njnt\r\n\u23a4\r\n\u23a5\r\n\u23a5\r\n\u23a5\r\n\u23a5\r\n\u23a5\r\n\u23a6\r\nJ\u00d71\r\nfor m = 1, \u2026, M (13)\r\nThe parameter matrices are defined such that the dimension of the residual output gnt matches the dimension of Vnt for an elementwise additive operation. We can have several intermediate neural network layers of varying sizes within each residual layer, which is\r\none of the conveniences of the neural network architecture. \u03b8(m) serves as the similarity or cross-effect factors to the utility function.\r\nThe chosen alternative\u2019s utility is increased or decreased by its degree of similarity with other non-chosen alternatives by this factor.\r\nThe MNL perspective corresponds to shifting the vector of utilities by gnt. If the cross-effect factors are zero, i.e. \u03b8(m) = 0 for all m, then\r\nthe utility surplus is shifted by 0 and falls back to an MNL model.\r\nAnother observation is that the choice probability is conditional on the expectation of the output of the residual terms:\r\nQ(m)\r\nnt = 1\r\n1 + exp(\r\n\u03b8(m)\r\nh(m\u2212 1)\r\nnt ), s.t. Q(m)\r\nnt \u2a7e0, for m = 1,\u2026, M (14)\r\nand if we assume that Q(m)\r\nnt = {Q(m)\r\njnt } for j \u2208 {1,\u2026, J} is a vector of probabilities, we can rewrite the ResLogit formulation in Eq. 8 as a\r\nconditional choice probability:\r\nP\r\n\u239b\r\n\u239c\u239c\u239d\r\ni\r\n\u239e\r\n\u239f\u239f\u23a0 = yi =\r\n(\u220f\r\nm\r\nQ(m)\r\nint )\r\nexp(\r\nVint)\r\n\u2211\r\nj\u2208{1,\u2026,J}\r\n(\u220f\r\nm\r\nQ(m)\r\njnt )\r\nexp(\r\nVjnt), \u2200i \u2208\r\n\u23a7\r\n\u23aa\u23aa\u23a8\r\n\u23aa\u23aa\u23a9\r\n1,\u2026, J\r\n\u23ab\r\n\u23aa\u23aa\u23ac\r\n\u23aa\u23aa\u23ad\r\n(15)\r\nThe residual component (Eq. 9) derives from entropy, or expected surplus function of the respective residual layers and the corresponding logsum term is the result of the log of the Logit probability denominator. Behaviour modelling uses entropy to measure the\r\nvariation or accessibility of a specific choice (Erlander, 2010). For example, Mattsson and Weibull (2002) characterized such\r\nformulation as maximization of the sum of the expected utility and a weighted entropy. Anas (1983) postulated that the entropy\r\nprinciple in choice models correspond to how much information-seeking behaviour is used to find the \u201cbest\u201d utility specification.\r\nM. Wong and B. Farooq\r\nTransportation Research Part C 126 (2021) 103050\r\n8\r\nFosgerau et al. (2017) and Mat\u02c7ejka and McKay (2015) also illustrated the affinity to generalized bounded rationality and the duality\r\nbetween discrete choice and rational inattention behaviour. Consequently, information cost acts as a barrier between prior beliefs and\r\nthe decision making actions, which results in choice heterogeneity. An agent optimizes his or her desired outcome by minimizing this\r\ninformation cost (Mat\u02c7ejka and McKay, 2015). Our ResLogit model aims to extend this concept by allowing for a data-driven surplus\r\nexpression in the utility function (Presented in Eq. 5) to emulate the decision-makers\u2019 learning process.\r\n3.1. Depth of the neural network\r\nIncreasing the depth of the neural network increases the number of additive residual terms in the utility function. The residual\r\nlayers represent the underlying unobserved behaviour distribution that is not captured by the explanatory variables. This mathematical formulation allows the model to reflect individual taste heterogeneities in the non-linear residual function. Unlike a typical\r\nMLP model or the recently developed Learning-MNL model (Sifringer et al., 2020), training a ResLogit model does not suffer from the\r\nvanishing gradient problem. This eliminates the singularities caused by model non-identifiability. This property\u2019s key implication on\r\nchoice modelling is that we can operationalize the learning behaviour as a function in the utility while retaining the same econometric\r\nparameters in the structural equation.\r\n3.2. Estimation approach\r\nThe estimation procedure is a data-driven first-order stochastic gradient descent SGD learning algorithm, and we evaluate the\r\nperformance on an out-of-sample validation set. In data-driven optimization, we are maximizing a performance measure (e.g. out-ofsample performance) by indirectly maximizing a different surrogate objective function (e.g. maximizing log-likelihood of the training\r\ndata). We typically assume that the out-of-sample dataset is independent and identically distributed from the training dataset. In\r\ncontrast, pure optimization of discrete choice models directly maximizes the likelihood objective function, which is a goal of itself. This\r\nmethod of estimating a large number of parameters has been proven efficient in machine learning. In some cases, a surrogate objective\r\nfunction approach may result in a faster and better solution (Goodfellow et al., 2016). Other pre-conditioning methods or extensions\r\ncan also be implemented into the surrogate objective function allowing it to reach multiple local optimum points and provide a\r\nregulating effect. For example, these pre-conditioning includes adding momentum, adaptive learning rate methods or gradient noise\r\nnormalization, see Ruder (2016) for an overview of such methods. Another important difference is that the final convergence criteria\r\nare based on the performance measure, not the surrogate objective function within data-driven optimization. This approach enables\r\nthe algorithm to terminate when overfitting begins to occur (early-stopping criteria). The estimation reaches convergence when the\r\nobjective function no longer improves.\r\nFor this reason, a data-driven approach is more suitable in estimating our ResLogit model since a pure optimization approach will\r\nrun into model non-identifiability issues due to a large number of estimated parameters.\r\n3.2.1. Objective function and parameter updates\r\nThe set of optimal parameters \u03b8 and \u03b2 are estimated by maximizing the log-likelihood, where the log-likelihood is as follows:\r\nLL(\r\n\u03b8, \u03b2\r\n)\r\n= \u2211N\r\nn=1\r\nlnP\r\n(\r\nin|xn; \u03b8, \u03b2\r\n)\r\n. (16)\r\nThe mini-batch SGD algorithm performs the following update rule on each iteration t:\r\n\u03b8t+1 = \u03b8t \u2212 \u03b7t\u2207\u03b8\ud835\udca5 \u212c(\u03b8, \u03b2), (17)\r\n\u03b2t+1 = \u03b2t \u2212 \u03b7t\u2207\u03b2\ud835\udca5 \u212c(\u03b8, \u03b2), (18)\r\nwhere:\r\n\u2207\u03b8\ud835\udca5 \u212c\r\n(\r\n\u03b8, \u03b2\r\n)\r\n= 1\r\nK\r\n\u2211\r\nn\r\n\u2032\r\n\u2208\u212c\r\n\u2207\u03b8LLn\u2032\r\n(\r\n\u03b8, \u03b2\r\n)\r\n, (19)\r\n\u2207\u03b2\ud835\udca5 \u212c\r\n(\r\n\u03b8, \u03b2\r\n)\r\n= 1\r\nK\r\n\u2211\r\nn\r\n\u2032\r\n\u2208\u212c\r\n\u2207\u03b2LLn\r\n\u2032\r\n(\r\n\u03b8, \u03b2\r\n)\r\n, (20)\r\nand K is the batch size, \u212c is a batch of observations sampled from xn, n\r\n\u2032\r\ndenotes the observation in the batch and \u03b7t is the learning rate.\r\nWe can regard \u2207\ud835\udca5 \u212c(\u03b8, \u03b2) as a noisy estimate of the true gradient \u2207LL(\u03b8, \u03b2). We sample from the training set and adjust the \u03b2 and \u03b8\r\nparameters to reduce the training error, then we monitor the error in the validation by sampling from the validation dataset. The goal\r\nof the optimization is to reduce the validation error while also reducing the difference between the training and validation error. This\r\ncan also be achieved by taking the model at the maximum log-likelihood of the validation dataset with an assumption that the estimation on the training dataset is asymptotic as the number of iterations on the samples N \u2192 \u221e. The derivatives of the estimated\r\nparameters is computed using backpropagation (Goodfellow et al., 2016). Given the ResLogit formulation and taking the\r\nM. Wong and B. Farooq\r\nTransportation Research Part C 126 (2021) 103050\r\n9\r\nbackpropagation from the output log-likelihood, the derivative of the log-likelihood with respect to \u03b2 is:\r\n\u2202LL\r\n\u2202\u03b2 = \u2202LL\r\n\u2202V\r\n\u2202V\r\n\u2202\u03b2 +\r\n\u2202LL\r\n\u2202h(m)\r\n\u2202h(m)\r\n\u2202\u03b2 +\r\n\u2202LL\r\n\u2202h(m\u2212 1)\r\n\u2202h(m\u2212 1)\r\n\u2202\u03b2 + \u2026 +\r\n\u2202LL\r\n\u2202h(1)\r\n\u2202h(1)\r\n\u2202\u03b2 (21)\r\nThe gradient formulation is shown in Eq. 21 that by the nature of the residual connections, each derivative of the residual layers is\r\nindependently computed. This prevents the phenomena known as vanishing gradient. If any of the gradients is computed to be zero, it\r\ndoes not affect the total backpropagated value and the \u03b2 parameters can still be updated. This allows the ResLogit to converge to an\r\noptimal MNL solution, even with non-identifiable residual layers. In contrast, with a fully connected MLP model, the gradient\r\nformulation is a result of a chain rule:\r\n\u2202LL\r\n\u2202\u03b2 = \u2202LL\r\n\u2202h(m) \u00d7 \u2202h(m)\r\n\u2202h(m\u2212 1) \u00d7 \u2026 \u00d7 \u2202h(1)\r\n\u2202V \u00d7 \u2202V\r\n\u2202\u03b2 (22)\r\nIn Eq. 22, if any of the intermediate derivatives are zero, then the total derivative is zero, and the model fails to learn and update \u03b2,\r\nresulting in model non-identifiability. The number of parameters used is relative to the number of alternatives in the choice set. Each\r\nelement in the matrix corresponds to the cross-effects of other alternatives on the chosen alternative. The diagonal elements in the\r\nmatrix are the cross-effects with itself, i.e. a scale factor adjustment. If this residual matrix is an identity matrix, that means that there\r\nare no cross-effects induced between alternatives (IIA holds), and the model collapses into a standard MNL model.\r\n4. Red/Blue bus theoretical example\r\nWe show an example of how a simple nesting structure can be obtained using the ResLogit formulation in a hypothetical scenario.\r\nLet us consider the red/blue bus problem. The red/blue bus problem is a classic example of IIA property violation in choice models. The\r\nproblem arises in the assumption that the error terms for the red and blue bus options are independent, but they are correlated and\r\nshare similar decision attributes in reality. This means that the change in utility for a red bus will influence the change in utility of the\r\nblue bus. To relax this assumption, choice modellers often use a Nested Logit model to relax the IIA assumption by adding a conditional\r\nprobability term or logsum term. The choice scenarios are summarized in Table 1.\r\n4.1. Scenario description\r\nIn the first scenario (Scenario 1), assuming that we have a vector of 2 choices in a choice task t. V : {Vcar, Vbus}, where each\r\nalternative has the same utility Vcar = 1, Vbus = 1 Under strict IID assumptions, the probability of choosing either bus or car is,\r\ntherefore, Pcar = Pbus = 0.5.\r\nIn the second scenario (Scenario 2), suppose that now we have a red bus (Vred bus) and blue bus (Vblue bus) option in place of Vbus,V =\r\n{Vcar,Vred bus,Vblue bus}. The utility of each alternative does not change, and all 3 alternatives have the same utility: Vcar = 1,Vred = 1,\r\nVblue = 1. Assuming the choice task is IID, the probabilities for the respective alternative should result in: Pcar = 0.5,Pred bus = 0.25,\r\nand Pblue bus = 0.25. The probability of car choice does not change when we add a new mode to the choice set. However, the actual\r\nprobabilities when estimated by an MNL model would result in: Pcar = 0.33,Pred bus = 0.33, and Pblue bus = 0.33, which does not seem\r\nplausible and violates IIA property conditions.\r\nIn the third scenario (Scenario 3), under our proposed ResLogit model, the correlation between the red and blue bus is corrected by\r\na residual vector g, with residual parameter matrix \u03b8(1)\r\n. Using a 1-layer ResLogit model and a residual vector function defined by g =\r\n\u2212 ln(1 + exp(\u03b8(1)\r\nV)), we simulate a choice scenario with alternatives car, red bus, blue bus.\r\nTable 1\r\nIllustration of red/blue bus choice scenario showing the effect of residual correction factors of a 1-layer model.\r\nChoice Vi gi exp(Vi + gi) P(i)\r\nScenario 1\r\ncar 1 \u2013 2.718 0.5\r\nbus 1 \u2013 2.718 0.5\r\nScenario 2\r\ncar 1 \u2013 2.718 0.33\r\nred bus 1 \u2013 2.718 0.33\r\nblue bus 1 \u2013 2.718 0.33\r\nScenario 3 (competing car/bus)\r\ncar 1 \u2212 0.127 2.394 0.468\r\nred bus 1 \u2212 0.693 1.359 0.265\r\nblue bus 1 \u2212 0.693 1.359 0.265\r\nScenario 3 (non-competing car/bus)\r\ncar 1 \u2212 0.693 1.359 0.482\r\nred bus 1 \u2212 1.313 0.731 0.259\r\nblue bus 1 \u2212 1.313 0.731 0.259\r\nM. Wong and B. Farooq\r\nTransportation Research Part C 126 (2021) 103050\r\n10\r\nWe assume at a value of 1 represents a positive cross-effect and a \u2212 1 value denotes a negative cross-effect and 0 value represents no\r\ncross-effects (IIA property holds). The negative value of cross-effects between the car and bus option may suggest that the alternatives\r\nare competing options (e.g. buses and cars sharing the same road segment). we assign a value of {1} to elements c\r\n(1)\r\n32 and c\r\n(1)\r\n23 and a value\r\nof { \u2212 1} to elements c\r\n(1)\r\n12 , c\r\n(1)\r\n21 , c\r\n(1)\r\n13 and c\r\n(1)\r\n31 :\r\n\u03b8(1) =\r\n\u23a1\r\n\u23a3 c11 c12 c13\r\nc21 c22 c23\r\nc31 c32 c33\r\n\u23a4\r\n\u23a6 =\r\n\u23a1\r\n\u23a3\r\n0 \u2212 1 \u2212 1\r\n\u2212 1 0 1\r\n\u2212 1 1 0\r\n\u23a4\r\n\u23a6. (23)\r\nGiven a 3 \u00d7 1 vector of utilities V = [ 1 1 1 ]\r\n\u22a4, the residual vector g is:\r\ng = \u2212 ln(\r\n1 + exp(\r\n\u03b8(1)\r\nV\r\n)), (24)\r\n= \u2212 ln\r\n\u239b\r\n\u239d1 + exp\r\n\u239b\r\n\u239d\r\n\u23a1\r\n\u23a3\r\n0 \u2212 1 \u2212 1\r\n\u2212 1 0 1\r\n\u2212 1 1 0\r\n\u23a4\r\n\u23a6 \u22c5\r\n\u23a1\r\n\u23a3\r\n1\r\n1\r\n1\r\n\u23a4\r\n\u23a6\r\n\u239e\r\n\u23a0\r\n\u239e\r\n\u23a0,\r\n(25)\r\n=\r\n\u23a1\r\n\u23a3\r\n\u2212 0.127\r\n\u2212 0.693\r\n\u2212 0.693\r\n\u23a4\r\n\u23a6,\r\n(26)\r\ngiving the choice probabilities as:\r\nP\r\n\u239b\r\n\u239c\u239d\r\ni\r\n\u239e\r\n\u239f\u23a0 = exp(Vi + gi)\r\n\u2211\r\nj\u2208C\r\nexp(\r\nVj + gj\r\n) for i \u2208 car,redbus, bluebus\r\nP(car) = 0.468; P(red bus) = 0.265; P(blue bus) = 0.265;\r\n(27)\r\nThe probabilities in Eq. 27 show that with an addition of the residual matrix to account for the cross-effects, we have moved the\r\nchoice probabilities of the car and red/blue bus options toward the true IIA conditions without changing the underlying utilities.\r\nNow, if we assume no cross-effects between the car and bus alternatives (both car and buses are not sharing the same road\r\nsegment), we update Eq. 23 with values of {0} for parameters c\r\n(1)\r\n12 , c\r\n(1)\r\n21 , c\r\n(1)\r\n13 and c\r\n(1)\r\n31 :\r\n\u03b8(1) =\r\n\u23a1\r\n\u23a3 c11 c12 c13\r\nc21 c22 c23\r\nc31 c32 c33\r\n\u23a4\r\n\u23a6 =\r\n\u23a1\r\n\u23a3\r\n0 0 0\r\n0 0 1\r\n0 1 0\r\n\u23a4\r\n\u23a6. (28)\r\nThe resulting residual vector would be:\r\ng =\r\n\u23a1\r\n\u23a3\r\n\u2212 0.693\r\n\u2212 1.313\r\n\u2212 1.313\r\n\u23a4\r\n\u23a6, (29)\r\ngiving the choice probabilities as:\r\nP\r\n\u239b\r\n\u239c\u239d\r\ni\r\n\u239e\r\n\u239f\u23a0 = exp(Vi + gi)\r\n\u2211\r\nj\u2208C\r\nexp(\r\nVj + gj\r\n), for i \u2208 car,redbus, bluebus\r\nP(car) = 0.482; P(red bus) = 0.259; P(blue bus) = 0.259;\r\n(30)\r\nIn principle, the nests between the car and the bus options are not pre-specified a priori by the modeller. The parameter matrix is\r\nestimated from data and defines the nesting structure or error term correlation of the choice alternatives. The first observation of the\r\nhypothetical example shown above is that with a logical assumption of positive (cbus,bus = 1) cross-effect residual parameter between\r\nthe two bus alternatives and zero (cbus,car = 0) cross-effect residual parameter between the car and bus alternatives would result in a\r\nnesting structure which reflects the relaxed IID assumption probabilities. The second observation stems from the correlations between\r\nerror terms of competing alternatives. If the residual parameters are negative, it accounts for competing alternatives (e.g. buses and\r\ncars share the same road segment from the origin to destination), resulting in a slightly different outcome than a non-compete scenario.\r\n5. Case study\r\nThis study evaluates our proposed ResLogit model\u2019s effects and performance in three criteria: model depth, model degradation, and\r\nM. Wong and B. Farooq\r\nTransportation Research Part C 126 (2021) 103050\r\n11\r\nmodel predictive performance compared to an MLP neural network. We also evaluate the residual effects on econometric parameters\r\nby comparing the beta and standard error values with a baseline MNL model without the residual layers.\r\nWe evaluate the ResLogit model\u2019s performance using individualized characteristics and attributes in a revealed preference (RP)\r\ntravel survey dataset using out-of-sample accuracy at the minimum validation loss point on the validation curve. We computed the\r\naccuracy using a 30% hold-out validation set from our dataset. We compared the model degradation effects between our ResLogit and a\r\nvanilla MLP model with identical model hyperparameters to address the adverse impact of model degradation from increasing layers.\r\nWe showed the effects of increasing layers in the ResLogit model and the MLP model on estimation accuracy and model identifiability.\r\n5.1. Data and model description\r\nWe used the 2016 Mtl Trajet RP dataset collected from the user\u2019s smartphone data on a mobile application (Yazdizadeh et al., 2019).\r\nA list of explanatory variables and the choice set used for this mode choice prediction analysis are shown in Table 2. The respondents\u2019\r\ntravel diary includes mode choice, activity choice, trip attributes (e.g. trip length, start/end time, location) and GPS trajectories. The\r\ntravel survey was conducted over four months, from September to December 2016. In total, there were 60,365 unique trips made\r\nduring the period. To evaluate out-of-sample performance, we divide the dataset into two sets using a 70:30 training/validation split\r\n(Ntraining = 42, 256 samples, Nvalidation = 18, 109 samples). We developed the model estimation algorithm using open-source deep\r\nlearning libraries in Python. The code for our experiments is available on our Github page.9\r\nWe iterated over the experiment by varying the depth of the ResLogit and MLP neural network using 2, 4, 8 and 16 hidden layers\r\n(M = {2, 4, 8, 16}). Note that our study only shows a relative comparison between the models with a similar number of layers and\r\nneural network hyperparameters. The objective of this experiment is to show the effectiveness of the ResLogit approach as a way of\r\nincorporating deep learning methods into discrete choice models over a conventional MLP neural network.\r\nThis experiment considers three specific objectives:\r\n1. Effects of the number of residual layers on the model \u03b2 parameters.\r\n2. Model validation accuracy and maximum log-likelihood estimation comparison.\r\n3. Comparison of estimated \u03b2 parameters between the ResLogit model and MNL model.\r\nThe model estimation process begins with a baseline MNL estimation. Next, the MLP models were estimated (4 models, one each for\r\n2, 4, 8 and 16 hidden layers), and labelled as MLP-2, MLP-4, MLP-8 and MLP-16, respectively. We performed the same training process\r\non the ResLogit models (RL-2, RL-4, RL-8, RL-16). For the learning algorithm, we used the mini-batch SGD learning algorithm with a\r\nmini-batch size of 64 (i.e. gradient is computed over a sample of 64 observations from the training dataset) to train our models. For the\r\nlearning algorithm, we applied an RMSprop optimization step (Goodfellow et al., 2016). The ResLogit model residual parameters are\r\ninitialized using an identity matrix. Once the models have been trained, we take the best-specified model at the minimum validation\r\nloss point and compute the prediction accuracy using the validation dataset\u2019s model parameter values.\r\n5.2. Analysis of model results\r\nFigs. 2 and 3 reports the validation results of the MNL and ResLogit models with a baseline comparison to a MNL model (red line). A\r\ncondensed version of the estimated \u03b2 parameters of the MNL and ResLogit models are presented in Table 3, which we showed the\r\ncomparison between our best estimated ResLogit structure (RL-16) and the MNL model. Fig. 4 shows the parameters of the first four\r\nresidual layers.\r\n5.2.1. Performance measure on out-of-sample data\r\nFig. 2 shows the validation curves of the model log-likelihood. The x-axis represents the iteration step, and the y-axis reports the\r\nlog-likelihood. The MNL curve indicates the baseline performance where no augmentation to the utility or model. The plot on the left\r\nshows the comparison between the MNL and MLP models. This result indicates that the MLP model performs worse than the MNL\r\nmodel. The only change between the MLP and ResLogit experiments is the model structure. Therefore the improvement is most likely\r\nonly attributed to the change in model structure, and not other hyperparameters10. MLP-2 also took twice as long to reach the\r\nmaximum log-likelihood (400 vs 200 iterations on the MNL model). The MLP models (MLP-4, MLP-8 and MLP-16) produced significantly noisier output in the backpropagation step in SGD, which causes the \u201cspikes\u201d seen on the left plot. There were also identifiability problems with MLP-4, MLP-8 and MLP-16 models. Since the MLP-4, MLP-8 and MLP-16 models were misspecified, they could\r\nnot reach the same performance log-likelihood compared to the MNL models. This result showed that adding neural network layers\r\ndoes not guarantee better performance and a simple MNL could potentially outperform a DNN, which is in line with our initial\r\nhypothesis.\r\n9 https://github.com/LiTrans/reslogit-example. 10 It is also plausible that an MLP will do better or equivalent to a Logit model and sometimes an MLP can perform worse than a Logit model (on\r\nthis particular class of problem, for example). This can be explained by the \u201dNo Free Lunch\u201d theorem (Kawaguchi et al., 2017): \u201dIf an algorithm\r\nperforms well on a certain class of problems, then it necessarily pays for that with degraded performance on the set of all remaining problems.\u201d\r\n(Wolpert and Macready, 1997, Theorem 1).\r\nM. Wong and B. Farooq\r\nTransportation Research Part C 126 (2021) 103050\r\n12\r\nWe observed that as we increase the depth of the ResLogit models (Fig. 2, right), the log-likelihood remains consistent and outperforms the baseline MNL. Although we are using the same number of parameters and the same learning algorithm, the ResLogit\r\nmethod generated correctly specified models while the MLP models were misspecified. Model specification test is handled by out-ofsample validation analysis and econometric interpretation of beta parameters (explained in the following sections). We note that we\r\ndid not implement any other forms of regularization for experiment consistency, e.g. L1, L2 regularizer or Dropout techniques. An\r\nalternative approach to model selection for more complex data where there are many unknown variables is to use a statistical measure\r\nsuch as the Akaike Information Criterion (AIC). The AIC statistic calculated for the MNL, MLP-16 and RL-16 models is 32566, 34902\r\nand 28086 respectively.\r\nFig. 3 shows the validation error curves for both models. The error is defined as (1 - mean prediction accuracy) where the mean\r\nprediction accuracy is:\r\n\u2112n\r\n(\r\ni, i\r\n*\r\n)\r\n=\r\n[ 1i = i\r\n*\r\n0i \u2215= i\r\n*\r\n]\r\ni, i\r\n* \u2208 \ud835\udc9fvalidation (31)\r\nTable 2\r\nDescriptive variables of the dataset.\r\nvariable description type mean std dev\r\nweekend trip on weekend dummy\r\nvariable\r\n0.205 0.001\r\nhour_8_10 trip between 8 am to 10 am dummy\r\nvariable\r\n0.163 0.0015\r\nhour_11_13 trip between 11am to 1 pm dummy\r\nvariable\r\n0.147 0.001\r\nhour_14_16 trip between 2 pm to 4 pm dummy\r\nvariable\r\n0.209 0.002\r\nhour_17_19 trip between 5 pm to 7 pm dummy\r\nvariable\r\n0.249 0.002\r\nhour_20_22 trip between 8 pm to 10 pm dummy\r\nvariable\r\n0.095 0.001\r\nhour_23_1 trip between 11 pm to 1 am dummy\r\nvariable\r\n0.03 6e\u2212 4\r\nhour_2_4 trip between 2 am to 4 am dummy\r\nvariable\r\n0.006 3e\u2212 4\r\nhour_5_7 trip between 5 am to 7 am dummy\r\nvariable\r\n0.101 0.005\r\nnum_coord number of trajectory links continuous 109.8 131.23\r\ntrip_dist trip distance (km) continuous 8.366 10.42\r\ntrip_duration trip duration (min) continuous 24.04 20.97\r\ntrip_avgspeed trip average speed (km/h) continuous 22.503 18.815\r\nactivity trip activity type:{1: education, 2: health, 3: leisure, 4: meal, 5: errands, 6: shopping 7: home, 8:\r\nwork, 9: meeting}\r\ncategorical\r\nchoice\r\nalternatives\r\n1: Auto, 2: Bike, 3: Public Transit, 4: Walk, 5:Auto + Transit,\r\n6: Other mode, 7: Other combination\r\nFig. 2. Validation log-likelihood results of the model estimation.\r\nM. Wong and B. Farooq\r\nTransportation Research Part C 126 (2021) 103050\r\n13\r\nmean prediction accuracy = 1\r\nNvalidation\r\n\u2211N\r\nn=1\r\n\u2112n\r\n(\r\ni, i\r\n*\r\n)\r\n(32)\r\nwhere i is the actual choice, i\r\n* is the predicted choice, \u2112n(i, i\r\n*) is the 0\u20131 loss function and \ud835\udc9fvalidation is the validation dataset.\r\nThe stability of convergence shows no strong overfitting bias during the estimation process. On the MLP curves on the left plot, the\r\nmodel with the smallest error is the one with the least number of hidden layers but only after iteration 400, with the MNL model\r\ncoming in as the second-lowest error. We can see that the error reaches a saturation point around 0.3 for MLP-2 with a negligible\r\ndecrease at MLP-4 to MLP-16. This makes sense because the non-linear structure of the multi-layered neural network will be susceptible to the vanishing gradient problem observed in this figure. The results are more profound when we compare the MLP with the\r\nFig. 3. Validation loss comparison between the MLP models and the ResLogit models.\r\nTable 3\r\nComparison of a subset of parameter estimates between MNL and ResLogit model.\r\nMNL ResLogit (16-layer)\r\nParameter (\u03b2mj) Choice parameter std. err. rob. std. err. parameter std. err. rob. std. err.\r\nweekend auto \u2212 0.057* 0.036 0.386 0.045* 0.006 1.157\r\nbike \u2212 0.990* 0.081 7.335 \u2212 0.448* 0.063 7.566\r\ntransit \u2212 0.751* 0.042 1.569 \u2212 0.090* 0.007 0.089\r\nhour_8_10 walk \u2212 0.841* 0.070 7.986 \u2212 1.459 0.013 0.063\r\nauto + transit \u2212 2.273* 0.121 15.005 1.162 0.032 0.230\r\nhour_11_13 bike \u2212 0.854* 0.073 47.886 \u2212 1.210* 0.071 15.565\r\nauto + transit \u2212 2.540* 0.217 48.866 1.618 0.039 0.359\r\nhour_17_19 auto 0.058* 0.029 0.186 \u2212 0.586 0.004 0.001\r\nhour_20_22 bike \u2212 1.271* 0.092 16.937 \u2212 0.943* 0.085 15.009\r\ntrip_dist auto 0.354 0.007 0.002 \u2212 0.113 0.001 0.000\r\ntransit 0.297 0.008 0.002 0.817 0.001 0.000\r\nwalk \u2212 2.197 0.028 0.387 \u2212 0.257 0.004 0.001\r\ntrip_time auto \u2212 0.627 0.005 0.000 \u2212 0.397 0.001 0.000\r\ntransit 0.870 0.005 0.000 0.303 0.001 0.000\r\nwalk 0.863 0.009 0.007 \u2212 0.752 0.002 0.000\r\ntrip_aspeed auto 0.988 0.005 0.001 \u2212 0.024 0.001 0.000\r\nwalk \u2212 1.738 0.014 0.058 \u2212 1.900 0.002 0.000\r\nact_edu auto \u2212 1.357* 0.080 10.697 \u2212 0.187 0.011 0.055\r\nwalk \u2212 0.067* 0.086 22.325 \u2212 0.871 0.029 0.558\r\nact_home auto \u2212 0.119* 0.026 0.151 0.340 0.003 0.001\r\nbike \u2212 1.048* 0.044 3.217 \u2212 0.705* 0.039 1.477\r\ntransit 0.109* 0.027 0.093 0.764 0.004 0.001\r\nact_work auto \u2212 0.055* 0.027 0.115 0.276 0.003 0.003\r\ntransit \u2212 0.011* 0.028 0.096 0.631 0.004 0.004\r\nauto + transit \u2212 1.853* 0.073 4.028 0.851 0.028 0.114\r\nact_meeting bike \u2212 2.776* 0.259 154.812 \u2212 1.803* 0.174 106.564\r\nlog-likelihood \u2212 16145 \u2212 13121\r\nsample size 42,255 42,255\r\n# of estimated parameters 138 922\r\nmax. validation accuracy 72.01% 76.73%\r\n* Not statistically significant at p-value < 0.05.\r\nM. Wong and B. Farooq\r\nTransportation Research Part C 126 (2021) 103050\r\n14\r\nResLogit model (Fig. 3, right). In the MLP plot, we observe that the learning gets trapped in a locally optimal point. The difference is\r\nminimal with two layers, which we expected, but a more pronounced difference between the MLP and ResLogit model when the\r\nnumber of layers increases. On the right plot of Fig. 3 the loss gets progressively smaller as we increase the number of residual layers,\r\nwhich is consistent and follows a logical pattern. Even with an RL-2, the error drops significantly faster, and the model achieved lower\r\nerror than the MNL model as soon as the estimation starts. This means that neural networks are best suited to capture the error\r\ndistribution rather than using it as a transformative operator on the explanatory variables.\r\n5.3. Model coefficient estimates\r\nTable 3 presents the coefficient estimates, standard errors and robust standard errors for the observed explanatory variables for the\r\nMNL and RL-16 model. The parameter estimates indicate the individuals\u2019 exhibited preferences for each attribute for each alternative.\r\nThe results show that individuals reacted towards a stronger preference for transit when the trip time is longer in the ResLogit model,\r\nrelative to the MNL model. Individuals also prefer a longer route for transit compared to auto according to the ResLogit model. In\r\ncontrast, the MNL estimates show that individuals prefer a longer route when taking auto over transit. There are specific indicators\r\nwhich are captured in ResLogit and not in the MNL models. For instance, on weekends, people in Montreal use their car more to do\r\nshopping, recreation, visit their parents in the suburbs, go to cottage, etc. Therefore, ResLogit is giving us a positive sign for car over the\r\nweekend compared to other modes. Another example is that during morning rush hour (8\u201310), people commute and there is a higher\r\nchance that they take auto + transit (due to the availability of a large amount of parking at stations) to reach their office. This fact is\r\nFig. 4. First 4 layers of weight matrices from the ResLogit model.\r\nM. Wong and B. Farooq\r\nTransportation Research Part C 126 (2021) 103050\r\n15\r\ncaptured only by ResLogit.\r\nStandard errors can be calculated through the Fisher Information Matrix, requiring only the Hessian of the log-likelihood which\r\nassumes a correctly specified model. Additionally, the correct specification assumption can be relaxed by computing the robust\r\nsandwich estimator. We calculate the standard errors as a function of the negative inverse of the Hessian matrix \u210b, which gives the\r\nvariance-covariance matrix of \u03b2, assuming those estimates are normally distributed. This value gives the Cramer-Rao bound:\r\n\u03a3\u0302CR\r\n\u03b2 = \u2212 \u210b\u0302 \u2212 1\r\n(33)\r\nThe Hessian matrix is the second-order derivative of the log-likelihood with respect to the model parameters. Then, taking the diagonal\r\nof the square root of that variance-covariance matrix normalized by the size of the dataset, we obtain the standard errors. The robust\r\nstandard error \u03a3\u0302Rob.\r\n\u03b2 is calculated by:\r\n\u03a3\u0302Rob.\r\n\u03b2 =\r\n(\r\n\u2212 \u210b\u0302 \u2212 1)\r\nB\u0302\r\n(\r\n\u2212 \u210b\u0302 \u2212 1)\r\n(34)\r\nwhere B\u0302 = \u2211N\r\nn=1\r\n(\r\n\u2202LLn\r\n\u2202\u03b2\r\n)(\u2202LLn\r\n\u2202\u03b2\r\n)\u22a4\r\nIn terms of the coefficient significance value, the ResLogit parameters have more parameters with a\r\nnominal p-value < 0.05 compared to the MNL model.\r\nThe standard error and robust standard error estimates show that the ResLogit estimates are more reliable than the MNL model. For\r\nthe extreme cases, the parameter estimates for trip distance for walking showed the smallest value compared to other modes for both\r\nmodels as expected, indicating that the results are consistent. The robust standard errors also show that some parameters are not\r\nsignificant, for instance, meeting activity-bike has a high standard error when accounting for model misspecification. This is logical as\r\ntravelling by bicycle is not usually common. The estimates for hour (20\u201322)-bike also indicate that this parameter is not a significant\r\nparameter, we can say that the hours between 8 and 10 pm does not impact the preference of bike mode.\r\nWe caution the readers that we can give no general guarantees to the precision of the standard errors or the asymptotic behaviour of\r\nthe model fit for heavily biased models (Goeman et al., 2018), such as L1 or L2 regularization used in neural networks and other\r\nmachine learning methods. Our ResLogit formulation reduces this bias in the model through the addition of residual layers to account\r\nfor the systematic errors. Therefore, the robust standard errors that we report are reliable, but only provide an approximation of model\r\nspecification correctness and the variance of the estimates.\r\n5.4. Analyzing cross-effects from the residual matrices\r\nThe cross-effects of non-chosen alternatives are reflected in Fig. 4. The figure shows the parameters of the first four residual layers\r\nof RL-16. The matrices\u2019 values correspond to the level of dependency between the utility of one alternative with the utility function of\r\nthe second alternative, and vice versa. As explained in Section 4, this matrix defines the underlying error term correlations between the\r\nchoice alternatives. For example, the positive value of transit-bike in Fig. 4 (a) is 1.55. This means that the attributes of transit mode\r\npositively influence individuals who choose bike mode, increasing the utility of transit influences the increase in mode share for the\r\nbike. However, the reverse may not be identical. The value for bike-transit in Fig. 4 (a) is \u2212 0.26, indicating that increasing the utility of\r\nbike (e.g. more bike infrastructure), decreases the mode share for transit. We may relate this observation to the shared infrastructure\r\nbetween auto and bike. The non-zero values indicate the existence of non-linear cross-effects in the stated choices. This analysis\r\nprovides an estimate of the cross-effect influence between modes of travel. Nonetheless, this experiment has shown how the ResLogit\r\nformulation uses the residual function to enhance model performance.\r\n5.5. Elasticity analysis\r\nThe point aggregate elasticity of Pn(i) with respect to input xn is given by the following equation:\r\nExn\r\n(\r\ni\r\n)\r\n= dPn(i)\r\ndxn\r\nxn\r\nP(i) (35)\r\nThe elasticity measures the impact of increasing or decreasing a variable on the demand of the respective choice. In this case we use\r\ntrip_dist as the variable and we measure the impact of market share on the auto, bike, transit and walk choices. Similarly we compute the\r\narc elasticities of Pn(i) with respect to \u0302xn when we change the trip_dist by \u0394xn where \u0302xn = xn + \u0394xn. Table 4 shows the point elasticities\r\nobtained from the MNL, MLP and ResLogit model (16 layers). The ResLogit model show expected signs similar to the MNL model. Walk\r\nmode show a smaller increase in trip distance than the MNL model, while Transit mode shows a more significant impact from trip\r\ndistance in the ResLogit model compared to the MNL model. For the MLP model, transit mode show a negative sign compared to the\r\nMNL model. Surprisingly, the ResLogit model shows a different sign in Auto mode. Indeed, for Auto mode, one should expect negative\r\nelasticity.\r\nIf we analyze the two models\u2019 elasticities (presented in Fig. 5) assuming different scenarios where we increase or decrease the\r\noverall trip distance, for instance, willingness to change modes to travel a longer or shorter distance or construction of new transit\r\nnetworks. We can see that the elasticities from the ResLogit predict a non-linear change relation between trip distance and the\r\nrespective mode choice. This shows a clear distinction from the MLP model, where the relationship between trip distance and mode\r\nM. Wong and B. Farooq\r\nTransportation Research Part C 126 (2021) 103050\r\n16\r\nshows a relatively linear curve. We expect that elasticity is heterogeneous and it will vary across different scenarios, given different\r\nunobserved trade-offs between mode choices, For auto mode, The ResLogit model predicts that with a decrease in trip distance by 50%,\r\nelasticity is positive (and negative otherwise), while increasing the trip distance will result in greater sensitivity to trip distance. Bike\r\nmode shows a positive elasticity when we increase the trip distance by 50% but a negative elasticity when we decrease the trip distance\r\nby about \u2212 50%. We can infer from this result that travellers are willing to switch from bikes to other modes or from other modes to\r\nbikes, considering other unobserved factors not captured in the data. This sign switching phenomenon is interesting because it indicates a heterogeneous population that will react differently while also considering other alternatives. This consideration of non-chosen\r\nalternatives shows that the ResLogit model behaves in line with the behavioural theory of the Mother Logit model example where\r\nattributes from non-chosen alternatives enter the utility of the chosen alternative.\r\n5.6. Significance of model depth and utility formulation\r\nThe general notion is that increasing the complexity and non-linearity in the model should result in greater model fit, given the\r\nhigher degree of freedom induced by the neural network. However, the MLP network model suffers from the vanishing gradient\r\nproblem shown by increasing the number of layers. There is a bottleneck effect with depth M\u2a7e4, and the validation log-likelihood and\r\nloss no longer improved. In contrast, we do not see this detrimental effect in the ResLogit model, even at a depth of 16 layers. This study\r\nhighlights how machine learning models may sometimes be worse off than a simple discrete choice model without understanding the\r\nneural network formulation structure.\r\n5.6.1. Behaviour interpretation\r\nAs explained in Section 2.2, a decision-maker\u2019s learning process may be developed over time through experiences, and the agent\r\nupdates his or her underlying distribution. The ResLogit model captures this effect while retaining the value function of the observed\r\ncomponent of the utility. We can use this approach of capturing uncertainties to account for heterogeneity in the choice process arising\r\nfrom inconsistency within travel mode choice.\r\nBesides the differences in optimal performance, it is also of practical interest to study the actual \u03b2 parameter solution vectors and\r\nobserve how they differ from a standard MNL model without accounting for learning behaviour. Table 3 shows the differences in \u03b2\r\nparameter estimates between the benchmark MNL and RL-16. These exact set of significant variables accounted for can be inferred\r\nfrom each reported metric\u2019s standard error. A conceptual step in discrete choice analysis is the ability to provide the basis of estimation\r\nof \u03b2 (and standard error) and economic indications using data on observed choices and attributes. Here, our ResLogit approach follows\r\nthe same approach as discrete choice methods. The unobserved attributes, expressed in \u03b5 in MNL models, captured the error contribution to the utility.\r\nWe observe that the ResLogit counterpart differs from the MNL model in most metrics. However, the ResLogit model\u2019s ability to\r\n\u201cexplain away\u201d uncertainty yields greater parameter significance as reported by the lower standard error. The formulation of the\r\nResLogit, which adds the g term, captures the cross-effects of the different mode choice alternatives to ensure that the decision is free\r\nfrom unobserved errors and endogeneity. Under regularity conditions, this residual component captures the unobserved error using a\r\nlearning algorithm, similar to how in real-life, a traveller explores new route options or stick to habitual choices. In general, the\r\nResLogit framework allowed for the error term to be formulated within the utility.\r\n5.6.2. Sensitivity analysis\r\nIt is important to examine the differences in \u03b2 parameter responses when changing the neural network size. Our emphasis of this\r\nanalysis is on the \u03b2 value significance and non-linear responsiveness when more residual layers are added to the choice model.\r\nTable 5 shows a sensitivity analysis regarding the \u03b2 parameters of trip time over time of departure. The table shows the variation\r\nbetween trip time and time of departure beta parameters for each model. The values represent the degree of variability of each time of\r\ndeparture dummy variable on the utility of each mode alternative. We take the ratio of (\u03b2trip timextrip time)/(\u03b2departure dummyxdeparture dummy).\r\nThis gives us the sensitivity of travel time over different departure time segments. If the parameters for \u03b2trip time are not influenced by\r\nvariation in departure time, then the values would have a small standard deviation across departure time, and the standard deviation\r\nwould give an indicator of uniformity of the trip time-sensitivity across different departure times. If the standard deviation is small, it\r\nwould indicate that the trip time heterogeneity is captured in the residual component. The \u03b2trip time represents the value that is closer to\r\nthe true mean. The attribute effects are shown in Table 5 represent the mean preference on each individual\u2019s utility, after controlling\r\nfor taste variability. This result indicates the effects of increasing residual layers on the stability of the econometric parameters.\r\nTable 4\r\nPoint elasticities.\r\nMNL MLP ResLogit\r\nChoice trip_dist trip_dist trip_dist\r\nAuto 0.178 0.133 \u2212 0.103\r\nBike \u2212 1.031 \u2212 0.128 \u2212 0.980\r\nTransit 0.232 \u2212 0.206 0.669\r\nWalk \u2212 1.54 \u2212 0.207 \u2212 0.769\r\nM. Wong and B. Farooq\r\nTransportation Research Part C 126 (2021) 103050\r\n17\r\nAs expected in the MNL model, the time of departure dummy variable influences the utility and choice of mode. This is a consistent\r\nresult, as we cannot represent the variation over the departure time as a single linear factor in the utility function. Modifying the MNL\r\nmodel by incorporating the residual layers would reduce the variability and sensitivity to time of departure. The average standard\r\ndeviation of trip time versus time of departure coefficient decreases as we increase the number of layers is shown in the table. This\r\nshows how the implied heterogeneity in the utility function can be explained away through the neural network component, retaining\r\nthe properties of the observed utility component. Note that this estimation does not allow us to identify the relationship between the\r\nheterogeneity of departure time and the preference of different travel modes. One can use economic indicators to estimate this effect.\r\nFig. 5. Elasticity versus % increase or decrease in trip distance, comparison between models.\r\nM. Wong and B. Farooq\r\nTransportation Research Part C 126 (2021) 103050\r\n18\r\nThe values reported for RL-2 to RL-16 may not be entirely stable, and further investigation is needed into how the model responds to\r\nchanges in hyperparameters and regularization. However, we can conclude that this experiment shows the capability of our proposed\r\nResLogit approach, particularly in: (a) allowing for a specific analysis of the underlying distribution and (b) exploring the attributes\r\nthat represent the most significant degree of heterogeneity in the model\u2013that may present an interesting subject for future research.\r\n6. Conclusion\r\nThis paper has presented a data-driven deep learning-based choice model that integrates a residual neural network architecture\r\ninto a Logit model structure. This paper\u2019s methodological contribution is a new model that captures the learning process using neural\r\nnetwork model structure for accounting for cross-effects in the utility error term. We proposed an approach that combines a residual\r\nneural network with a Logit model. This study\u2019s first objective resolves the shortcomings in the integration of machine learning\r\ntechniques and neural networks in discrete choice modelling. The second objective addressed the systematic error of biased model\r\nTable 5\r\nSensitivity analysis of different travel modes over time of departure. Values show the difference in trip time parameter estimates across hourly\r\nsegments.\r\nModel trip time/time of departure variability\r\nMNL Auto Bike PT Walk\r\nhour_8_10 3.07 \u2212 0.26 26.36 \u2212 1.03\r\nhour_11_13 \u2212 3.34 \u2212 0.24 \u2212 12.08 \u2212 5.43\r\nhour_14_16 \u2212 2.07 \u2212 0.33 5.88 \u2212 2.61\r\nhour_17_19 \u2212 10.81 \u2212 0.45 3.26 \u2212 1.75\r\nhour_20_22 2.42 \u2212 0.16 \u2212 3.49 \u2212 1.31\r\nhour_23_1 0.76 \u2212 0.14 \u2212 1.26 \u2212 0.54\r\nhour_2_4 1.88 \u2212 0.09 \u2212 0.52 \u2212 0.43\r\nhour_5_7 4.86 \u2212 0.16 \u2212 14.26 \u2212 0.92\r\nstddev 4.66 0.11 11.74 1.54\r\nRL-2\r\nhour_8_10 \u2212 0.18 3.63 15.37 \u2212 0.60\r\nhour_11_13 \u2212 0.16 1.73 \u2212 5.99 \u2212 1.33\r\nhour_14_16 \u2212 0.17 2.19 \u2212 14.66 \u2212 0.78\r\nhour_17_19 \u2212 0.23 3.76 9.25 \u2212 0.54\r\nhour_20_22 \u2212 0.19 1.77 \u2212 6.62 \u2212 0.83\r\nhour_23_1 \u2212 0.29 1.65 \u2212 2.07 \u2212 0.64\r\nhour_2_4 \u2212 0.17 1.68 \u2212 0.89 \u2212 0.94\r\nhour_5_7 \u2212 0.17 2.29 45.38 \u2212 0.72\r\nstddev 0.04 0.81 17.62 0.23\r\nRL-4\r\nhour_8_10 0.08 0.19 0.84 \u2212 1.24\r\nhour_11_13 0.06 0.23 1.01 \u2212 1.80\r\nhour_14_16 0.08 0.22 1.07 \u2212 1.47\r\nhour_17_19 0.10 0.24 1.08 \u2212 1.58\r\nhour_20_22 0.08 0.19 0.97 \u2212 1.49\r\nhour_23_1 0.09 0.16 0.94 \u2212 1.09\r\nhour_2_4 0.07 0.20 1.88 \u2212 1.50\r\nhour_5_7 0.08 0.22 0.88 \u2212 1.66\r\nstddev 0.01 0.03 0.31 0.21\r\nRL-8\r\nhour_8_10 \u2212 0.26 \u2212 1.35 0.39 \u2212 1.39\r\nhour_11_13 \u2212 0.26 \u2212 2.89 1.42 \u2212 1.15\r\nhour_14_16 \u2212 0.24 \u2212 1.59 0.48 \u2212 1.36\r\nhour_17_19 \u2212 0.27 \u2212 1.58 0.41 \u2212 1.61\r\nhour_20_22 \u2212 0.25 \u2212 2.01 0.45 \u2212 1.85\r\nhour_23_1 \u2212 0.37 \u2212 1.46 0.34 \u2212 1.12\r\nhour_2_4 \u2212 0.26 3.87 \u2212 2.94 \u2212 0.75\r\nhour_5_7 \u2212 0.25 \u2212 2.14 0.38 \u2212 1.53\r\nstddev 0.04 1.95 1.20 0.32\r\nRL-16\r\nhour_8_10 0.75 \u2212 0.93 0.40 0.52\r\nhour_11_13 0.69 \u2212 0.67 0.49 0.42\r\nhour_14_16 0.71 \u2212 0.81 0.43 0.46\r\nhour_17_19 0.68 \u2212 1.22 0.40 0.48\r\nhour_20_22 0.70 \u2212 0.86 0.39 0.50\r\nhour_23_1 0.62 \u2212 0.87 0.43 0.55\r\nhour_2_4 0.51 \u2212 0.56 1.04 0.48\r\nhour_5_7 0.69 \u2212 0.91 0.42 0.50\r\nstddev 0.07 0.18 0.21 0.04\r\nM. Wong and B. Farooq\r\nTransportation Research Part C 126 (2021) 103050\r\n19\r\nestimates in DNNs due to its lack of economic interpretability.\r\nUnlike earlier studies that only examined the performance of machine learning algorithms and their comparisons with discrete\r\nchoice models in out-of-sample predictions, this paper studies the impact of a residual function in the choice utility as a data-driven\r\nvariant of the Mother Logit model. The ResLogit model proposed in this paper frames the Mother Logit model\u2019s expansion function like\r\na neural network and the parameters within the neural network are estimated through a mini-batch stochastic gradient descent algorithm, maximizing over the out-of-sample validation set. This data-driven approach also addresses model non-identifiability issues\r\nwhen estimating a large number of unknown parameters. A new direction to a more flexible and general model is presented using the\r\nconcept of residual modelling \u2013 mapping the error term correlation to a residual function instead of using traditional neural networks.\r\nThe skipped connection structure allows each residual layer to be estimated independently without model identification problems due\r\nto exploding/vanishing gradient during backpropagation.\r\nA classic red/blue bus IIA violation example is used, and we demonstrated our methodology on a large scale travel behaviour\r\ndataset. We examined the performance comparison with an MNL and MLP neural network across a different number of layers. The\r\nresults showed that with a ResLogit model, it optimized quickly and efficiently, without degradation in model performance as the\r\nnumber of layers increased. In the context of model identifiability, the ResLogit model yielded a smaller standard error for each\r\neconometric model parameters than the baseline MNL model. We also demonstrated the sensitivity of trip time and time of departure\r\nvariability over different model characteristics. We observed that incorporating residual layers reduced model sensitivity to crosseffects and choice heterogeneity.\r\nOur proposed ResLogit model improved discrete choice models\u2019 capabilities in terms of performance without sacrificing model\r\ninterpretability. We noted that our experiment results do not consider hyperparameter tuning or regularization steps, which may affect\r\nthe reliability of our model validation results. This proof-of-concept illustrates how choice modellers can leverage on deep learning\r\nmethodologies and learning algorithms to enhance the current set of tools and models for discrete choice analysis. Our future work will\r\nestablish additional models and extensions to our proposed ResLogit methodology.\r\nMore work has to be done on the interpretability of the model, and how to define clear guidelines so researchers without advanced\r\nknowledge of machine learning can use these new modelling techniques. Also, more comparative studies can be done between\r\ndifferent learning algorithms for Logit models. Further investigation is also required into the meta-learning side of deep learning in\r\ndiscrete choice modelling. For example, we do not know the optimal hyperparameter configuration or efficiently identify a good set of\r\nhyperparameters without a tedious iterative search.\r\nCRediT authorship contribution statement\r\nMelvin Wong: Conceptualization, Methodology, Investigation, Validation, Writing - original draft, Writing - review & editing.\r\nBilal Farooq: Conceptualization, Methodology, Validation, Formal analysis, Writing - original draft, Writing - review & editing,\r\nSupervision, Funding acquisition.\r\nReferences\r\nAlwosheel, A., van Cranenburgh, S., Chorus, C.G., 2018. Is your dataset big enough? Sample size requirements when using artificial neural networks for discrete\r\nchoice analysis. J. Choice Model. 28, 167\u2013182.\r\nAnas, A., 1983. Discrete choice theory, information theory and the multinomial logit and gravity models. Transp. Res. Part B: Methodol. 17, 13\u201323.\r\nBadu-Marfo, G., Farooq, B., Paterson, Z., 2020. Composite travel generative adversarial networks for tabular and sequential population synthesis. arXiv preprint arXiv:\r\n2004.06838.\r\nBansal, P., Krueger, R., Bierlaire, M., Daziano, R.A., Rashidi, T.H., 2019. Bayesian estimation of mixed multinomial logit models: Advances and simulation-based\r\nevaluations. arXiv preprint arXiv: 1904.03647.\r\nBansal, P., Krueger, R., Bierlaire, M., Daziano, R.A., Rashidi, T.H., 2020. Bayesian estimation of mixed multinomial logit models: Advances and simulation-based\r\nevaluations. Transp. Res. Part B: Methodol. 131, 124\u2013142.\r\nBen-Akiva, M., Boccara, B., 1995. Discrete choice models with latent choice sets. Int. J. Res. Market. 12, 9\u201324.\r\nBen-Akiva, M.E., Lerman, S.R., 1985. Discrete choice analysis: theory and application to travel demand. MIT Press, Cambridge MA.\r\nBengio, Y., Lee, D.H., Bornschein, J., Mesnard, T., Lin, Z., 2015. Towards biologically plausible deep learning. arXiv preprint arXiv: 1502.04156.\r\nBorysov, S.S., Rich, J., Pereira, F.C., 2019. How to generate micro-agents? A deep generative modeling approach to population synthesis. Transp. Res. Part C: Emerg.\r\nTechnol. 106, 73\u201397.\r\nBrathwaite, T., Vij, A., Walker, J.L., 2017. Machine learning meets microeconomics: The case of decision trees and discrete choice. arXiv preprint arXiv: 1711.04826.\r\nBreiman, L., 2001. Statistical modeling: The two cultures. Statist. Sci. 16, 199\u2013231.\r\nCantarella, G.E., de Luca, S., 2005. Multilayer feedforward networks for transportation mode choice analysis: An analysis and a comparison with random utility\r\nmodels. Transp. Res. Part C: Emerg. Technol. 13, 121\u2013155.\r\nChorus, C.G., 2010. A new model of random regret minimization. Eur. J. Transp. Infrastruct. Res. 10.\r\nDaganzo, C.F., Bouthelier, F., Sheffi, Y., 1977. Multinomial probit and qualitative choice: A computationally efficient algorithm. Transp. Sci. 11, 338\u2013358.\r\nErlander, S.B., 2010. Cost-minimizing choice behavior in transportation planning: a theoretical framework for logit models. Springer Science & Business Media.\r\nFosgerau, M., Melo, E., Palma, A.D., Shum, M., 2017. Discrete choice and rational inattention: A general equivalence result. Available at SSRN 2889048.\r\nFriston, K.J., Stephan, K.E., 2007. Free-energy and the brain. Synthese 159, 417\u2013458.\r\nGlorot, X., Bordes, A., Bengio, Y., 2011. Deep sparse rectifier neural networks. In: Proceedings of the 14th International Conference on Artificial Intelligence and\r\nStatistics, pp. 315\u2013323.\r\nGoeman, J., Meijer, R., Chaturvedi, N., 2018. L1 and l2 penalized regression models. Vignette R Package Penalized.\r\nGoodfellow, I., Bengio, Y., Courville, A., 2016. Deep Learning. MIT Press. http://www.deeplearningbook.org.\r\nHagenauer, J., Helbich, M., 2017. A comparative study of machine learning classifiers for modeling travel mode choice. Expert Syst. Appl. 78, 273\u2013282.\r\nHardt, M., Ma, T., 2016. Identity matters in deep learning. arXiv preprint arXiv: 1611.04231.\r\nHe, K., Zhang, X., Ren, S., Sun, J., 2016. Deep residual learning for image recognition. In: Proceedings of the 29th IEEE conference on computer vision and pattern\r\nrecognition, pp. 770\u2013778.\r\nHensher, D.A., Greene, W.H., 2003. The mixed logit model: the state of practice. Transportation 30, 133\u2013176.\r\nM. Wong and B. Farooq\r\nTransportation Research Part C 126 (2021) 103050\r\n20\r\nHensher, D.A., Ton, T.T., 2000. A comparison of the predictive potential of artificial neural networks and nested logit models for commuter mode choice. Transp. Res.\r\nPart E: Logist. Transp. Rev. 36, 155\u2013172.\r\nHess, S., Daly, A., Batley, R., 2018. Revisiting consistency with random utility maximisation: theory and implications for practical work. Theor. Decis. 84, 181\u2013204.\r\nHillel, T., Bierlaire, M., Jin, Y., 2019. A systematic review of machine learning methodologies for modelling passenger mode choice. Technical Report TRANSP-OR\r\n191025. EPFL.\r\nKarlaftis, M.G., Vlahogianni, E.I., 2011. Statistical methods versus neural networks in transportation research: Differences, similarities and some insights. Transp. Res.\r\nPart C: Emerg. Technol. 19, 387\u2013399.\r\nKawaguchi, K., Kaelbling, L.P., Bengio, Y., 2017. Generalization in deep learning. arXiv preprint arXiv: 1710.05468.\r\nKingma, D.P., Ba, J., 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv: 1412.6980.\r\nLee, D., Derrible, S., Pereira, F.C., 2018. Comparison of four types of artificial neural network and a multinomial logit model for travel mode choice modeling. Transp.\r\nRes. Rec. 2672, 101\u2013112.\r\nLipton, Z.C., 2018. The mythos of model interpretability. Queue 16, 31\u201357.\r\nMai, T., Bastin, F., Frejinger, E., 2017. On the similarities between random regret minimization and mother logit: The case of recursive route choice models. J. Choice\r\nModel. 23, 21\u201333.\r\nMattsson, L.G., Weibull, J.W., 2002. Probabilistic choice and procedurally bounded rationality. Games Econ. Behav. 41, 61\u201378.\r\nMat\u02c7ejka, F., McKay, A., 2015. Rational inattention to discrete choices: A new foundation for the multinomial logit model. Am. Econ. Rev. 105, 272\u2013298.\r\nMcFaddden, D., 1978. Modeling the choice of residential location. Spatial Interact. Theory Plan. Models 75\u201396.\r\nMcFadden, D., 1973. Conditional logit analysis of qualitative choice behavior. Front. Econometr. 105\u2013142.\r\nMcFadden, D., 1975. On independence, structure, and simultaneity in transportation demand analysis. Technical Report No. 7511. Urban Travel Demand Forecasting\r\nProject. Institute of Transportation and Traffic Engineering, University of California, Berkeley.\r\nMcFadden, D., Train, K., 2000. Mixed MNL models for discrete response. J. Appl. Econometr. 15, 447\u2013470.\r\nMcFadden, D., Tye, W.B., Train, K., 1977. An application of diagnostic tests for the independence from irrelevant alternatives property of the multinomial logit model.\r\nInstitute of Transportation Studies, University of California Berkeley.\r\nOmrani, H., Charif, O., Gerber, P., Awasthi, A., Trigano, P., 2013. Prediction of individual travel mode with evidential neural network model. Transp. Res. Rec. 2399,\r\n1\u20138.\r\nPereira, F.C., 2019. Rethinking travel behavior modeling representations through embeddings. arXiv preprint arXiv:1909.00154.\r\nRuder, S., 2016. An overview of gradient descent optimization algorithms. arXiv preprint arXiv:1609.04747.\r\nSchuessler, N., Axhausen, K.W., 2007. Recent developments regarding similarities in transport modelling. Swiss Transport Research Conference.\r\nSifringer, B., Lurkin, V., Alahi, A., 2020. Enhancing discrete choice models with representation learning. Transp. Res. Part B: Methodol. 140, 236\u2013261.\r\nSrivastava, R.K., Greff, K., Schmidhuber, J., 2015. Training very deep networks, in: Advances in neural information processing systems, vol. 28, pp. 2377\u20132385.\r\nTimmermans, H., Borgers, A., van der Waerden, P., 1992. Mother logit analysis of substitution effects in consumer shopping destination choice. J. Bus. Res. 24,\r\n177\u2013189.\r\nTversky, A., Kahneman, D., 1981. The framing of decisions and the psychology of choice. Science 211, 453\u2013458.\r\nVythoulkas, P.C., Koutsopoulos, H.N., 2003. Modeling discrete choice behavior using concepts from fuzzy set theory, approximate reasoning and neural networks.\r\nTransp. Res. Part C: Emerg. Technol. 11, 51\u201373.\r\nWang, F., Ross, C.L., 2018. Machine learning travel mode choices: Comparing the performance of an extreme gradient boosting model with a multinomial logit model.\r\nTransp. Res. Rec. 2672, 35\u201345.\r\nWang, S., Zhao, J., 2019. Multitask learning deep neural network to combine revealed and stated preference data. arXiv preprint arXiv:1901.00227.\r\nWitten, I.H., Frank, E., Hall, M.A., Pal, C.J., 2016. Data Mining: Practical machine learning tools and techniques, fourth ed. Morgan Kaufmann, Cambridge, MA.\r\nWolpert, D.H., Macready, W.G., 1997. No free lunch theorems for optimization. IEEE Trans. Evolution. Comput. 1, 67\u201382.\r\nWong, M., Farooq, B., 2020. A bi-partite generative model framework for analyzing and simulating large scale multiple discrete-continuous travel behaviour data.\r\nTransp. Res. Part C: Emerg. Technol. 110, 247\u2013268.\r\nWong, M., Farooq, B., Bilodeau, G.A., 2018. Discriminative conditional restricted boltzmann machine for discrete choice and latent variable modelling. J. Choice\r\nModel. 29, 152\u2013168.\r\nYazdizadeh, A., Patterson, Z., Farooq, B., 2019. Ensemble convolutional neural networks for mode inference in smartphone travel survey. IEEE Trans. Intell. Transp.\r\nSyst. 21, 2232\u20132239.\r\nM. Wong and B. Farooq",
    "code_snippet": "#!/usr/bin/env python\r\n# coding: utf-8\r\n\r\n# ## Introduction to modelling with ResLogit\r\n# \r\n# [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/artefactory/choice-learn/blob/main/notebooks/models/reslogit.ipynb)\r\n# \r\n# We use the Swissmetro dataset to demonstrate how to use the ResLogit model [1]. \r\n\r\n# In[ ]:\r\n\r\n\r\n# Install necessary requirements\r\n\r\n# If you run this notebook on Google Colab, or in standalone mode, you need to install the required packages.\r\n# Uncomment the following lines:\r\n\r\n# !pip install choice-learn\r\n\r\n# If you run the notebook within the GitHub repository, you need to run the following lines, that can skipped otherwise:\r\nimport os\r\nimport sys\r\n\r\nsys.path.append(\"../../\")\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\nimport os\r\n# Remove/Add GPU use\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\r\n\r\nimport timeit\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport pandas as pd\r\nimport tensorflow as tf\r\n\r\nfrom choice_learn.data import ChoiceDataset\r\nfrom choice_learn.models import ResLogit\r\nfrom choice_learn.datasets import load_swissmetro\r\n\r\n\r\n# First, we create a ChoiceDataset from the dataframe.\r\n\r\n# In[ ]:\r\n\r\n\r\ndataset = load_swissmetro(as_frame=False)\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\ndataset.summary()\r\nprint(f\"\\n\\n{type(dataset)=}\")\r\nprint(f\"\\n{np.shape(dataset.items_features_by_choice)=}\")\r\nprint(f\"{np.shape(dataset.shared_features_by_choice)=}\")\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\nn_items = np.shape(dataset.items_features_by_choice)[2]\r\nn_items_features = np.shape(dataset.items_features_by_choice)[3]\r\nn_shared_features = np.shape(dataset.shared_features_by_choice)[2]\r\nn_vars = n_items_features + n_shared_features\r\nn_choices = len(np.unique(dataset.choices))\r\n\r\nprint(f\"{n_items=}\\n{n_items_features=}\\n{n_shared_features=}\\n{n_vars, n_choices=}\\n\\n\")\r\n\r\n\r\n# We split the dataset into train and test subsets.\r\n\r\n# In[ ]:\r\n\r\n\r\nn_samples = len(dataset.choices)\r\n# Slicing index for train and valid split\r\nslice = np.floor(0.7 * n_samples).astype(int)\r\ntrain_indexes = np.arange(0, slice)\r\ntest_indexes = np.arange(slice, n_samples)\r\n\r\ntrain_dataset = dataset[train_indexes]\r\ntest_dataset = dataset[test_indexes]\r\n\r\n\r\n# Now we can fit several ResLogit models with different numbers of residual layers. We will use the same learning rate and number of epochs for all models. We add itemwise intercept to all the models.\r\n\r\n# In[ ]:\r\n\r\n\r\nmodel_args = {\r\n    \"intercept\": \"item\",\r\n    \"optimizer\": \"SGD\",\r\n    \"lr\": 1e-6,\r\n    \"epochs\": 100,\r\n}\r\nprint(f\"{model_args=}\")\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\nlist_n_layers = [k for k in range(1, 17)]\r\nmetrics = pd.DataFrame(columns=[\"n_layers\", \"fit_losses\", \"train_loss\", \"test_loss\", \"initial_trainable_weights\", \"final_trainable_weights\", \"execution_time\"])\r\n\r\nfor n_layers in list_n_layers:\r\n    print(\"\\n------------------------------------\"\r\n          \"------------------------------------\"\r\n          f\"\\n{n_layers=}\")\r\n\r\n    start_time = timeit.default_timer()\r\n    model = ResLogit(n_layers=n_layers, **model_args)\r\n    model.instantiate(n_items=n_items, n_shared_features=n_shared_features, n_items_features=n_items_features)\r\n\r\n    initial_trainable_weights = [model.trainable_weights[i].numpy() for i in range(len(model.trainable_weights))]\r\n\r\n    fit_losses = model.fit(choice_dataset=train_dataset, val_dataset=test_dataset)\r\n\r\n    end_time = timeit.default_timer()\r\n    execution_time = end_time - start_time\r\n    print(f\"Execution time with {n_layers} residual layers: {execution_time} seconds\")\r\n\r\n    final_trainable_weights = [model.trainable_weights[i].numpy() for i in range(len(model.trainable_weights))]\r\n\r\n    new_metric_row = pd.DataFrame({\r\n        \"n_layers\": [n_layers],\r\n        \"fit_losses\": [fit_losses],\r\n        \"train_loss\": [model.evaluate(train_dataset)],\r\n        \"test_loss\": [model.evaluate(test_dataset)],\r\n        \"initial_trainable_weights\": [initial_trainable_weights],\r\n        \"final_trainable_weights\": [final_trainable_weights],\r\n        \"execution_time\": [execution_time]\r\n    })\r\n    metrics = pd.concat([metrics, new_metric_row], ignore_index=True)\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\nmetrics.head()\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\nfor index, row in metrics.iterrows():\r\n    plt.plot(row[\"fit_losses\"][\"train_loss\"], label=f\"n_layers={row['n_layers']}\")\r\n\r\nplt.xlabel(\"Epochs\")\r\nplt.ylabel(\"Training loss through the epochs\")\r\nplt.title(\"ResLogit model with different number of residual layers\")\r\nplt.legend()\r\nplt.show()\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\ntrain_losses = [row[\"train_loss\"] for index, row in metrics.iterrows()]\r\ntest_losses = [row[\"test_loss\"] for index, row in metrics.iterrows()]\r\n\r\nplt.plot(list_n_layers, train_losses, label=\"Train loss after the last epoch\")\r\nplt.plot(list_n_layers, test_losses, label=\"Test loss\")\r\n\r\nplt.xlabel(\"Number of residual layers\")\r\nplt.ylabel(\"Loss\")\r\nplt.title(\"ResLogit model with different number of residual layers\")\r\nplt.legend()\r\nplt.show()\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\nexecution_times = [row[\"execution_time\"] for index, row in metrics.iterrows()]\r\n\r\nplt.plot(list_n_layers, execution_times)\r\n\r\nplt.xlabel(\"Number of residual layers\")\r\nplt.ylabel(\"Execution time (s)\")\r\nplt.title(\"ResLogit model with different number of residual layers\")\r\nplt.legend()\r\nplt.show()\r\n\r\n\r\n# ### References\r\n# [1] ResLogit: A residual neural network logit model for data-driven choice modelling, Wong, M.; Farooq, B. (2021), Transportation Research Part C: Emerging Technologies 126\\\r\n# (URL: https://doi.org/10.1016/j.trc.2021.103050)\r\n\r\n# In[ ]:"
}